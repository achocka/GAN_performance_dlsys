{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "#import PIL\n",
    "import glob\n",
    "\n",
    "#import imageio\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from IPython import display\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "img_width = 32\n",
    "img_height = 32\n",
    "img_channels = 3\n",
    "num_classes = 10\n",
    "noise_dim = 100\n",
    "clip_value = 0.01\n",
    "train_ratio = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.0005\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Inception Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "from torchvision.models.inception import inception_v3\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def inception_score(imgs, cuda=True, batch_size=128, resize=False, splits=1):\n",
    "    \"\"\"Computes the inception score of the generated images imgs\n",
    "    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
    "    cuda -- whether or not to run on GPU\n",
    "    batch_size -- batch size for feeding into Inception v3\n",
    "    splits -- number of splits\n",
    "    \"\"\"\n",
    "    N = len(imgs)\n",
    "\n",
    "    assert batch_size > 0\n",
    "    assert N > batch_size\n",
    "\n",
    "    # Set up dtype\n",
    "    if cuda:\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    # Set up dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
    "\n",
    "    # Load inception model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n",
    "    inception_model.eval();\n",
    "    up = nn.Upsample(size=(299, 299), mode='bilinear').type(dtype)\n",
    "    def get_pred(x):\n",
    "        if resize:\n",
    "            x = up(x)\n",
    "        x = inception_model(x)\n",
    "        return F.softmax(x,dim=1).data.cpu().numpy()\n",
    "\n",
    "    # Get predictions\n",
    "    preds = np.zeros((N, 1000))\n",
    "\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        batch = batch.type(dtype)\n",
    "        batchv = Variable(batch)\n",
    "        batch_size_i = batch.size()[0]\n",
    "\n",
    "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batchv)\n",
    "\n",
    "    # Now compute the mean kl-div\n",
    "    split_scores = []\n",
    "\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    class IgnoreLabelDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, orig):\n",
    "            self.orig = orig\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return self.orig[index][0]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.orig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = '~/project/test3_last/img_gen/'\n",
    "transform=transforms.Compose([ transforms.Resize(64),\n",
    "                               transforms.CenterCrop(64),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root=data_path, transform=transform)\n",
    "trainset = datasets.CIFAR10(root='~/project/data/', train=True, download=True, transform = transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Inception Score...\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Inception Score...\")\n",
    "\n",
    "_mean, _std = inception_score(IgnoreLabelDataset(dataset), cuda=True, batch_size=64, resize=True, splits=10)\n",
    "print(\"Calculating Inception Score...\")\n",
    "#_mean_real, _std_real = inception_score(IgnoreLabelDataset(trainset), cuda=True, batch_size=64, resize=True, splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception Score Mean of GAN:  2.2770313106370805\n",
      "Inception Score Standard Deviation of GAN:  0.07475005643341849\n"
     ]
    }
   ],
   "source": [
    "print(\"Inception Score Mean of GAN: \", _mean)\n",
    "print(\"Inception Score Standard Deviation of GAN: \", _std)\n",
    "\n",
    "#print(\"Inception Score Mean of CIFAR-10: \", _mean_real)\n",
    "#print(\"Inception Score Standard Deviation of CIFAR-10: \", _std_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate FID Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as linalgo\n",
    "\n",
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    \"\"\"Numpy implementation of the Frechet Distance.\n",
    "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
    "    and X_2 ~ N(mu_2, C_2) is\n",
    "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
    "    \"\"\"\n",
    "\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    \n",
    "    covmean, _ = linalgo.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalgo.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    \n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1) +\n",
    "            np.trace(sigma2) - 2 * tr_covmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "class InceptionV3(nn.Module):\n",
    "    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n",
    "\n",
    "    # Index of default block of inception to return,\n",
    "    # corresponds to output of final average pooling\n",
    "    DEFAULT_BLOCK_INDEX = 3\n",
    "\n",
    "    # Maps feature dimensionality to their output blocks indices\n",
    "    BLOCK_INDEX_BY_DIM = {\n",
    "        64: 0,   # First max pooling features\n",
    "        192: 1,  # Second max pooling featurs\n",
    "        768: 2,  # Pre-aux classifier features\n",
    "        2048: 3  # Final average pooling features\n",
    "    }\n",
    "\n",
    "    def __init__(self,\n",
    "                 output_blocks=[DEFAULT_BLOCK_INDEX],\n",
    "                 resize_input=True,\n",
    "                 normalize_input=True,\n",
    "                 requires_grad=False):\n",
    "        \n",
    "        super(InceptionV3, self).__init__()\n",
    "\n",
    "        self.resize_input = resize_input\n",
    "        self.normalize_input = normalize_input\n",
    "        self.output_blocks = sorted(output_blocks)\n",
    "        self.last_needed_block = max(output_blocks)\n",
    "\n",
    "        assert self.last_needed_block <= 3, \\\n",
    "            'Last possible output block index is 3'\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "\n",
    "        \n",
    "        inception = models.inception_v3(pretrained=True)\n",
    "\n",
    "        # Block 0: input to maxpool1\n",
    "        block0 = [\n",
    "            inception.Conv2d_1a_3x3,\n",
    "            inception.Conv2d_2a_3x3,\n",
    "            inception.Conv2d_2b_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        ]\n",
    "        self.blocks.append(nn.Sequential(*block0))\n",
    "\n",
    "        # Block 1: maxpool1 to maxpool2\n",
    "        if self.last_needed_block >= 1:\n",
    "            block1 = [\n",
    "                inception.Conv2d_3b_1x1,\n",
    "                inception.Conv2d_4a_3x3,\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block1))\n",
    "\n",
    "        # Block 2: maxpool2 to aux classifier\n",
    "        if self.last_needed_block >= 2:\n",
    "            block2 = [\n",
    "                inception.Mixed_5b,\n",
    "                inception.Mixed_5c,\n",
    "                inception.Mixed_5d,\n",
    "                inception.Mixed_6a,\n",
    "                inception.Mixed_6b,\n",
    "                inception.Mixed_6c,\n",
    "                inception.Mixed_6d,\n",
    "                inception.Mixed_6e,\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block2))\n",
    "\n",
    "        # Block 3: aux classifier to final avgpool\n",
    "        if self.last_needed_block >= 3:\n",
    "            block3 = [\n",
    "                inception.Mixed_7a,\n",
    "                inception.Mixed_7b,\n",
    "                inception.Mixed_7c,\n",
    "                nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block3))\n",
    "\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \"\"\"Get Inception feature maps\n",
    "        Parameters\n",
    "        ----------\n",
    "        inp : torch.autograd.Variable\n",
    "            Input tensor of shape Bx3xHxW. Values are expected to be in\n",
    "            range (0, 1)\n",
    "        Returns\n",
    "        -------\n",
    "        List of torch.autograd.Variable, corresponding to the selected output\n",
    "        block, sorted ascending by index\n",
    "        \"\"\"\n",
    "        outp = []\n",
    "        x = inp\n",
    "\n",
    "        if self.resize_input:\n",
    "            x = F.interpolate(x,\n",
    "                              size=(299, 299),\n",
    "                              mode='bilinear',\n",
    "                              align_corners=False)\n",
    "\n",
    "        if self.normalize_input:\n",
    "            x = 2 * x - 1  # Scale from range (0, 1) to range (-1, 1)\n",
    "\n",
    "        for idx, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            if idx in self.output_blocks:\n",
    "                outp.append(x)\n",
    "\n",
    "            if idx == self.last_needed_block:\n",
    "                break\n",
    "\n",
    "        return outp\n",
    "    \n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
    "model = InceptionV3([block_idx])\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31103828 0.29928794 0.2829469  ... 0.36840268 0.34556995 0.36019655] [[ 0.03760421 -0.00064592  0.00444968 ...  0.00048851  0.00363369\n",
      "   0.00642787]\n",
      " [-0.00064592  0.04381326  0.00296016 ...  0.0071965   0.00821935\n",
      "   0.00625975]\n",
      " [ 0.00444968  0.00296016  0.04230948 ...  0.00962975  0.0071571\n",
      "  -0.00178448]\n",
      " ...\n",
      " [ 0.00048851  0.0071965   0.00962975 ...  0.08206231  0.01243663\n",
      "   0.00228276]\n",
      " [ 0.00363369  0.00821935  0.0071571  ...  0.01243663  0.07701919\n",
      "   0.00472482]\n",
      " [ 0.00642787  0.00625975 -0.00178448 ...  0.00228276  0.00472482\n",
      "   0.0797516 ]]\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, drop_last=True)\n",
    "pred_arr = np.empty((50000, 2048))\n",
    "\n",
    "start_idx=0\n",
    "for index, (images_mini_batch, labels) in enumerate(trainloader) :\n",
    "        batch = images_mini_batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch)[0]\n",
    "\n",
    "        # If model output is not scalar, apply global spatial average pooling.\n",
    "        # This happens if you choose a dimensionality not equal 2048.\n",
    "        if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "            pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "\n",
    "        pred = pred.squeeze(3).squeeze(2).cpu().numpy()\n",
    "\n",
    "        pred_arr[start_idx:start_idx + pred.shape[0]] = pred\n",
    "\n",
    "        start_idx = start_idx + pred.shape[0]\n",
    "\n",
    "mu = np.mean(pred_arr, axis=0)\n",
    "sigma = np.cov(pred_arr, rowvar=False)\n",
    "print(mu,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.309703   0.2962508  0.28164412 ... 0.3665724  0.34283723 0.35606982] [[ 0.02544843 -0.00070305  0.00262264 ... -0.00040529 -0.00119207\n",
      "   0.00395966]\n",
      " [-0.00070305  0.03287232  0.00121857 ...  0.00486911  0.00621496\n",
      "   0.00512275]\n",
      " [ 0.00262264  0.00121857  0.03381881 ...  0.00722263  0.00449653\n",
      "   0.00308527]\n",
      " ...\n",
      " [-0.00040529  0.00486911  0.00722263 ...  0.07271438  0.00884257\n",
      "   0.00588787]\n",
      " [-0.00119207  0.00621496  0.00449653 ...  0.00884257  0.06009314\n",
      "   0.00507112]\n",
      " [ 0.00395966  0.00512275  0.00308527 ...  0.00588787  0.00507112\n",
      "   0.06465445]]\n"
     ]
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "pred_arr = np.empty((10000, 2048))\n",
    "\n",
    "start_idx=0\n",
    "for index, (images_mini_batch, labels) in enumerate(trainloader) :\n",
    "        batch = images_mini_batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch)[0]\n",
    "\n",
    "        # If model output is not scalar, apply global spatial average pooling.\n",
    "        # This happens if you choose a dimensionality not equal 2048.\n",
    "        if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "            pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "\n",
    "        pred = pred.squeeze(3).squeeze(2).cpu().numpy()\n",
    "\n",
    "        pred_arr[start_idx:start_idx + pred.shape[0]] = pred\n",
    "\n",
    "        start_idx = start_idx + pred.shape[0]\n",
    "\n",
    "mu1 = np.mean(pred_arr, axis=0)\n",
    "sigma1 = np.cov(pred_arr, rowvar=False)\n",
    "print(mu1,sigma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID Score: 11.03072341547741\n"
     ]
    }
   ],
   "source": [
    "fid = calculate_frechet_distance(mu1,sigma1,mu,sigma)\n",
    "\n",
    "print(\"FID Score:\", fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
