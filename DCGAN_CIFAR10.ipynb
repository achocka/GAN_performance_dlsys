{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'test3_last'\n",
    "\n",
    "if not os.path.exists(prefix):\n",
    "    os.makedirs(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modal\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(100 + 10, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024 + 10, 128 * 8 * 8)\n",
    "        self.bn2 = nn.BatchNorm1d(128 * 8 * 8)\n",
    "        self.cvt1 = nn.ConvTranspose2d(128 + 10, 64, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.cvt2 = nn.ConvTranspose2d(64 + 10, 3, 4, 2, 1)\n",
    "    def forward(self, z, label):\n",
    "        x = F.relu(self.bn1(self.fc1(torch.cat([z, label], 1))))\n",
    "        x = F.relu(self.bn2(self.fc2(torch.cat([x, label], 1))))\n",
    "        label = label.view(-1, 10, 1, 1)\n",
    "        x = F.relu(self.bn3(self.cvt1(torch.cat([x.view(-1, 128, 8, 8), label.expand(x.size(0), 10, 8, 8)], 1))))\n",
    "        return F.sigmoid(self.cvt2(torch.cat([x, label.expand(x.size(0), 10, 16, 16)], 1)))\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.cv1 = nn.Conv2d(3 + 10, 64, 4, 2, 1)\n",
    "        self.cv2 = nn.Conv2d(64 + 10, 128, 4, 2, 1)\n",
    "        self.bm1 = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8 + 10, 1024)\n",
    "        self.bm2 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024 + 10, 1)\n",
    "    def forward(self, x, label):\n",
    "        label_expand = label.view(-1, 10, 1, 1)\n",
    "        x = F.leaky_relu(self.cv1(torch.cat([x, label_expand.expand(x.size(0), 10, 32, 32)], 1)))\n",
    "        x = F.leaky_relu(self.bm1(self.cv2(torch.cat([x, label_expand.expand(x.size(0), 10, 16, 16)], 1))))\n",
    "        x = F.leaky_relu(self.bm2(self.fc1(torch.cat([x.view(-1, 128 * 8 * 8), label], 1))))\n",
    "        return F.sigmoid(self.fc2(torch.cat([x, label], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:61: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    }
   ],
   "source": [
    "# Implement modal\n",
    "\n",
    "d_lr = 1e-3\n",
    "g_lr = 1e-4\n",
    "cuda = False\n",
    "\n",
    "G, D = Generator(), Discriminator()\n",
    "if cuda:\n",
    "    G, D = G.cuda(), D.cuda()\n",
    "G_optim, D_optim = optim.Adam(G.parameters(), lr = g_lr), optim.Adam(D.parameters(), lr = d_lr)\n",
    "\n",
    "# Load data\n",
    "\n",
    "\n",
    "cifar10 = datasets.CIFAR10('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "images = torch.stack([cifar10[i][0] for i in range(len(cifar10))])\n",
    "orig_labels = torch.LongTensor([cifar10[i][1] for i in range(len(cifar10))])\n",
    "labels = torch.zeros(images.size(0), 10).scatter_(1, orig_labels.view(-1, 1), 1)\n",
    "if cuda:\n",
    "    images, orig_labels, labels = images.cuda(), orig_labels.cuda(), labels.cuda()\n",
    "\n",
    "# Load and save modal\n",
    "def load_state():\n",
    "    if os.path.exists(prefix + '/checkpoint/G.data'):\n",
    "        G.load_state_dict(torch.load(prefix + '/checkpoint/G.data'))\n",
    "    if os.path.exists(prefix + '/checkpoint/D.data'):\n",
    "        D.load_state_dict(torch.load(prefix + '/checkpoint/D.data'))\n",
    "    if os.path.exists(prefix + '/checkpoint/G_optim.data'):\n",
    "        G_optim.load_state_dict(torch.load(prefix + '/checkpoint/G_optim.data'))\n",
    "    if os.path.exists(prefix + '/checkpoint/D_optim.data'):\n",
    "        D_optim.load_state_dict(torch.load(prefix + '/checkpoint/D_optim.data'))\n",
    "    begin_epoch = 0\n",
    "    if os.path.exists(prefix + '/checkpoint/epoch.data'):\n",
    "        begin_epoch = torch.load(prefix + '/checkpoint/epoch.data')\n",
    "    return begin_epoch\n",
    "\n",
    "def save_state(epoch):\n",
    "    if not os.path.exists(prefix + '/checkpoint'):\n",
    "        os.makedirs(prefix + '/checkpoint')\n",
    "    torch.save(G.state_dict(), prefix + '/checkpoint/G.data')\n",
    "    torch.save(D.state_dict(), prefix + '/checkpoint/D.data')\n",
    "    torch.save(G_optim.state_dict(), prefix + '/checkpoint/G_optim.data')\n",
    "    torch.save(D_optim.state_dict(), prefix + '/checkpoint/D_optim.data')\n",
    "    torch.save(epoch, prefix + '/checkpoint/epoch.data')\n",
    "\n",
    "# Test\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "def plt_images(images, rows, cols):\n",
    "    fig = plt.figure(figsize=(cols,rows))\n",
    "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.05, hspace=0.05)\n",
    "    for i, x in enumerate(images[:cols * rows]):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(np.rollaxis(x, 0, 3), norm=colors.NoNorm())\n",
    "    return fig\n",
    "\n",
    "plt_labels = Variable(torch.zeros(100, 10).scatter_(1, torch.LongTensor([[i]*10 for i in range(10)]).view(-1, 1), 1), volatile = True)\n",
    "plt_z = Variable(torch.randn(100, 100), volatile = True)\n",
    "if cuda:\n",
    "    plt_labels, plt_z = plt_labels.cuda(), plt_z.cuda()\n",
    "\n",
    "def plt_gen_with_random_noise(index):\n",
    "    z = Variable(torch.randn(100, 100), volatile = True)\n",
    "    if cuda:\n",
    "        z = z.cuda()\n",
    "    fig = plt_images(G(z, plt_labels).data.cpu().numpy(), 10, 10)\n",
    "    if not os.path.exists(prefix + '/plt_random'):\n",
    "        os.makedirs(prefix + '/plt_random')\n",
    "    fig.savefig(prefix + '/plt_random/%s.png' % str(index).zfill(5))\n",
    "    plt.close(fig)\n",
    "\n",
    "def plt_gen_with_fixed_noise(index):\n",
    "    fig = plt_images(G(plt_z, plt_labels).data.cpu().numpy(), 10, 10)\n",
    "    if not os.path.exists(prefix + '/plt_fixed'):\n",
    "        os.makedirs(prefix + '/plt_fixed')\n",
    "    fig.savefig(prefix + '/plt_fixed/%s.png' % str(index).zfill(5))\n",
    "    plt.close(fig)\n",
    "    \n",
    "def plt_single_gen_with_fixed_noise(img_num, class_gen):\n",
    "    plt_labels_sing = Variable(torch.zeros(100, 10).scatter_(1, torch.LongTensor([[class_gen]*10 for i in range(10)]).view(-1, 1), 1), volatile = True)\n",
    "    plt_z_sing = Variable(torch.randn(100, 100), volatile = True)\n",
    "    fig = plt_images(G(plt_z_sing, plt_labels_sing).data.cpu().numpy(), 1, 1)\n",
    "    if not os.path.exists(prefix + '/img_gen'):\n",
    "        os.makedirs(prefix + '/img_gen')\n",
    "    fig.savefig(prefix + '/img_gen/%s_%s.png' % ((str(class_gen).zfill(3)), str(img_num).zfill(5)) )\n",
    "    plt.close(fig)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "n_tsne_sample = 1000\n",
    "\n",
    "def plt_tsne(index):\n",
    "    indices = torch.from_numpy(np.random.randint(0, images.size(0), n_tsne_sample))\n",
    "    if cuda:\n",
    "        indices = indices.cuda()\n",
    "    label, z = Variable(labels[indices], volatile = True), Variable(torch.randn(n_tsne_sample, 100), volatile = True)\n",
    "    if cuda:\n",
    "        z = z.cuda()\n",
    "    source, target = images[indices].cpu().view(n_tsne_sample, 3 * 32 * 32).numpy(), G(z, label).data.cpu().view(n_tsne_sample, 3 * 32 * 32).numpy()\n",
    "    model = TSNE(n_components=2)\n",
    "    output = model.fit_transform(np.vstack([source, target]))\n",
    "    source, target = output[:source.shape[0], :], output[source.shape[0]:, :]\n",
    "    label = orig_labels[indices].cpu().numpy()\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.05, hspace=0.05)\n",
    "    src = fig.add_subplot(1, 2, 1)\n",
    "    tar = fig.add_subplot(1, 2, 2)\n",
    "    src.scatter(source[:, 0], source[:, 1], s=15, c=label, cmap='plasma', edgecolors='none', marker='o')\n",
    "    tar.scatter(target[:, 0], target[:, 1], s=15, c=label, cmap='plasma', edgecolors='none', marker='o')\n",
    "    src.axis('off')\n",
    "    tar.axis('off')\n",
    "    if not os.path.exists(prefix + '/plt_tsne'):\n",
    "        os.makedirs(prefix + '/plt_tsne')\n",
    "    plt.savefig(prefix + '/plt_tsne/%s.png' % str(index).zfill(5))\n",
    "    plt.close(fig)\n",
    "\n",
    "def test(index):\n",
    "    plt_gen_with_random_noise(index)\n",
    "    plt_gen_with_fixed_noise(index)\n",
    "    plt_tsne(index)\n",
    "\n",
    "# Train\n",
    "\n",
    "n_epoch = 20000\n",
    "batch_size = 128\n",
    "log_interval = 1\n",
    "plot_interval = 100\n",
    "save_interval = 100\n",
    "\n",
    "def train():\n",
    "    G.train()\n",
    "    D.train()\n",
    "    zeros = Variable(torch.zeros(batch_size, 1))\n",
    "    ones = Variable(torch.ones(batch_size, 1))\n",
    "    if cuda:\n",
    "        zeros, ones = zeros.cuda(), ones.cuda()\n",
    "    with open(prefix + '/log.txt', 'a') as log:\n",
    "        for i in range(load_state(), n_epoch):\n",
    "            for _ in range(3):\n",
    "                G.zero_grad()\n",
    "                D.zero_grad()\n",
    "                indices = torch.from_numpy(np.random.randint(0, images.size(0), batch_size))\n",
    "                if cuda:\n",
    "                    indices = indices.cuda()\n",
    "                realx, label, z = Variable(images[indices]), Variable(labels[indices]), Variable(torch.randn(batch_size, 100))\n",
    "                if cuda:\n",
    "                    z = z.cuda()\n",
    "                fakex = G(z, label)\n",
    "                realy, fakey = D(realx, label), D(fakex, label)\n",
    "                D_loss = F.binary_cross_entropy(realy, ones) + F.binary_cross_entropy(fakey, zeros)\n",
    "                D_loss.backward()\n",
    "                D_optim.step()\n",
    "            G.zero_grad()\n",
    "            D.zero_grad()\n",
    "            label = Variable(torch.zeros(batch_size, 10).scatter_(1, torch.from_numpy(np.random.randint(0, 10, batch_size)).view(-1, 1), 1))\n",
    "            z = Variable(torch.randn(batch_size, 100))\n",
    "            if cuda:\n",
    "                label, z = label.cuda(), z.cuda()\n",
    "            G_loss = F.binary_cross_entropy(D(G(z, label), label), ones)\n",
    "            G_loss.backward()\n",
    "            G_optim.step()\n",
    "            if i % log_interval == 0:\n",
    "                info = 'Epoch: %d; D_loss: %s; G_loss: %s' % (i, D_loss.data, G_loss.data)\n",
    "                print(info)\n",
    "                log.write(info + '\\n')\n",
    "            if i % plot_interval == 0:\n",
    "                G.eval()\n",
    "                D.eval()\n",
    "                test(i // plot_interval)\n",
    "                G.train()\n",
    "                D.train()\n",
    "            if i % save_interval == 0:\n",
    "                save_state(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9800; D_loss: tensor(0.1448); G_loss: tensor(2.5114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9801; D_loss: tensor(0.0055); G_loss: tensor(15.0599)\n",
      "Epoch: 9802; D_loss: tensor(0.0035); G_loss: tensor(15.1175)\n",
      "Epoch: 9803; D_loss: tensor(0.1232); G_loss: tensor(17.8667)\n",
      "Epoch: 9804; D_loss: tensor(0.0198); G_loss: tensor(11.7616)\n",
      "Epoch: 9805; D_loss: tensor(0.0052); G_loss: tensor(13.7131)\n",
      "Epoch: 9806; D_loss: tensor(0.0008); G_loss: tensor(10.3118)\n",
      "Epoch: 9807; D_loss: tensor(0.0026); G_loss: tensor(11.3021)\n",
      "Epoch: 9808; D_loss: tensor(0.0074); G_loss: tensor(10.9066)\n",
      "Epoch: 9809; D_loss: tensor(0.0143); G_loss: tensor(11.7012)\n",
      "Epoch: 9810; D_loss: tensor(0.0294); G_loss: tensor(13.3546)\n",
      "Epoch: 9811; D_loss: tensor(0.0356); G_loss: tensor(14.2408)\n",
      "Epoch: 9812; D_loss: tensor(0.0020); G_loss: tensor(8.2640)\n",
      "Epoch: 9813; D_loss: tensor(0.0016); G_loss: tensor(8.0504)\n",
      "Epoch: 9814; D_loss: tensor(0.0207); G_loss: tensor(6.7555)\n",
      "Epoch: 9815; D_loss: tensor(0.0270); G_loss: tensor(12.9967)\n",
      "Epoch: 9816; D_loss: tensor(0.0008); G_loss: tensor(11.0058)\n",
      "Epoch: 9817; D_loss: tensor(0.0695); G_loss: tensor(12.0879)\n",
      "Epoch: 9818; D_loss: tensor(0.0258); G_loss: tensor(8.3016)\n",
      "Epoch: 9819; D_loss: tensor(0.0954); G_loss: tensor(7.6660)\n",
      "Epoch: 9820; D_loss: tensor(0.0182); G_loss: tensor(12.0506)\n",
      "Epoch: 9821; D_loss: tensor(0.1325); G_loss: tensor(14.1879)\n",
      "Epoch: 9822; D_loss: tensor(0.0094); G_loss: tensor(9.3937)\n",
      "Epoch: 9823; D_loss: tensor(0.0154); G_loss: tensor(8.2158)\n",
      "Epoch: 9824; D_loss: tensor(0.0135); G_loss: tensor(8.5901)\n",
      "Epoch: 9825; D_loss: tensor(0.0020); G_loss: tensor(9.3569)\n",
      "Epoch: 9826; D_loss: tensor(0.0036); G_loss: tensor(9.1733)\n",
      "Epoch: 9827; D_loss: tensor(0.0258); G_loss: tensor(12.6143)\n",
      "Epoch: 9828; D_loss: tensor(0.0226); G_loss: tensor(10.0424)\n",
      "Epoch: 9829; D_loss: tensor(0.0161); G_loss: tensor(7.5162)\n",
      "Epoch: 9830; D_loss: tensor(0.0080); G_loss: tensor(6.3754)\n",
      "Epoch: 9831; D_loss: tensor(0.0078); G_loss: tensor(5.9542)\n",
      "Epoch: 9832; D_loss: tensor(0.0051); G_loss: tensor(8.2986)\n",
      "Epoch: 9833; D_loss: tensor(0.0118); G_loss: tensor(8.3061)\n",
      "Epoch: 9834; D_loss: tensor(0.0097); G_loss: tensor(8.9992)\n",
      "Epoch: 9835; D_loss: tensor(0.0066); G_loss: tensor(8.4506)\n",
      "Epoch: 9836; D_loss: tensor(0.0041); G_loss: tensor(8.6104)\n",
      "Epoch: 9837; D_loss: tensor(0.0195); G_loss: tensor(10.0377)\n",
      "Epoch: 9838; D_loss: tensor(0.5512); G_loss: tensor(5.9682)\n",
      "Epoch: 9839; D_loss: tensor(0.1058); G_loss: tensor(3.9675)\n",
      "Epoch: 9840; D_loss: tensor(0.0125); G_loss: tensor(12.5590)\n",
      "Epoch: 9841; D_loss: tensor(0.0905); G_loss: tensor(16.6667)\n",
      "Epoch: 9842; D_loss: tensor(0.0109); G_loss: tensor(11.1186)\n",
      "Epoch: 9843; D_loss: tensor(0.0044); G_loss: tensor(3.2352)\n",
      "Epoch: 9844; D_loss: tensor(0.3047); G_loss: tensor(9.3726)\n",
      "Epoch: 9845; D_loss: tensor(0.5740); G_loss: tensor(10.9994)\n",
      "Epoch: 9846; D_loss: tensor(0.0027); G_loss: tensor(6.3090)\n",
      "Epoch: 9847; D_loss: tensor(0.1163); G_loss: tensor(10.4640)\n",
      "Epoch: 9848; D_loss: tensor(0.0839); G_loss: tensor(13.0686)\n",
      "Epoch: 9849; D_loss: tensor(0.1755); G_loss: tensor(11.8972)\n",
      "Epoch: 9850; D_loss: tensor(0.0240); G_loss: tensor(10.0980)\n",
      "Epoch: 9851; D_loss: tensor(0.0169); G_loss: tensor(5.6614)\n",
      "Epoch: 9852; D_loss: tensor(0.0754); G_loss: tensor(7.6246)\n",
      "Epoch: 9853; D_loss: tensor(0.0416); G_loss: tensor(9.5493)\n",
      "Epoch: 9854; D_loss: tensor(0.1156); G_loss: tensor(9.6046)\n",
      "Epoch: 9855; D_loss: tensor(0.0146); G_loss: tensor(8.7076)\n",
      "Epoch: 9856; D_loss: tensor(0.0169); G_loss: tensor(9.4658)\n",
      "Epoch: 9857; D_loss: tensor(0.0117); G_loss: tensor(9.3629)\n",
      "Epoch: 9858; D_loss: tensor(0.0106); G_loss: tensor(12.1399)\n",
      "Epoch: 9859; D_loss: tensor(0.0015); G_loss: tensor(9.0184)\n",
      "Epoch: 9860; D_loss: tensor(0.0096); G_loss: tensor(11.8346)\n",
      "Epoch: 9861; D_loss: tensor(0.0104); G_loss: tensor(8.1634)\n",
      "Epoch: 9862; D_loss: tensor(0.0104); G_loss: tensor(10.0526)\n",
      "Epoch: 9863; D_loss: tensor(0.0521); G_loss: tensor(8.7338)\n",
      "Epoch: 9864; D_loss: tensor(0.0139); G_loss: tensor(9.0819)\n",
      "Epoch: 9865; D_loss: tensor(0.0091); G_loss: tensor(6.1105)\n",
      "Epoch: 9866; D_loss: tensor(0.0086); G_loss: tensor(9.2543)\n",
      "Epoch: 9867; D_loss: tensor(0.0228); G_loss: tensor(8.6251)\n",
      "Epoch: 9868; D_loss: tensor(0.0025); G_loss: tensor(8.0943)\n",
      "Epoch: 9869; D_loss: tensor(0.0556); G_loss: tensor(6.1246)\n",
      "Epoch: 9870; D_loss: tensor(0.0104); G_loss: tensor(7.9685)\n",
      "Epoch: 9871; D_loss: tensor(0.0269); G_loss: tensor(9.7480)\n",
      "Epoch: 9872; D_loss: tensor(0.0183); G_loss: tensor(8.2087)\n",
      "Epoch: 9873; D_loss: tensor(0.0142); G_loss: tensor(6.5502)\n",
      "Epoch: 9874; D_loss: tensor(0.0150); G_loss: tensor(8.5234)\n",
      "Epoch: 9875; D_loss: tensor(0.0037); G_loss: tensor(9.0181)\n",
      "Epoch: 9876; D_loss: tensor(0.0119); G_loss: tensor(8.8038)\n",
      "Epoch: 9877; D_loss: tensor(0.0041); G_loss: tensor(7.6549)\n",
      "Epoch: 9878; D_loss: tensor(0.0038); G_loss: tensor(6.2794)\n",
      "Epoch: 9879; D_loss: tensor(0.0290); G_loss: tensor(9.1563)\n",
      "Epoch: 9880; D_loss: tensor(0.0243); G_loss: tensor(11.2779)\n",
      "Epoch: 9881; D_loss: tensor(0.0159); G_loss: tensor(10.3574)\n",
      "Epoch: 9882; D_loss: tensor(0.0109); G_loss: tensor(6.7049)\n",
      "Epoch: 9883; D_loss: tensor(0.0301); G_loss: tensor(5.9955)\n",
      "Epoch: 9884; D_loss: tensor(0.0593); G_loss: tensor(7.7715)\n",
      "Epoch: 9885; D_loss: tensor(0.0152); G_loss: tensor(8.3951)\n",
      "Epoch: 9886; D_loss: tensor(0.0100); G_loss: tensor(11.8140)\n",
      "Epoch: 9887; D_loss: tensor(0.0175); G_loss: tensor(10.7892)\n",
      "Epoch: 9888; D_loss: tensor(0.0053); G_loss: tensor(7.4391)\n",
      "Epoch: 9889; D_loss: tensor(0.0269); G_loss: tensor(5.1952)\n",
      "Epoch: 9890; D_loss: tensor(0.0373); G_loss: tensor(11.0760)\n",
      "Epoch: 9891; D_loss: tensor(0.0784); G_loss: tensor(11.2771)\n",
      "Epoch: 9892; D_loss: tensor(0.0084); G_loss: tensor(3.4982)\n",
      "Epoch: 9893; D_loss: tensor(0.0202); G_loss: tensor(7.3215)\n",
      "Epoch: 9894; D_loss: tensor(0.0033); G_loss: tensor(13.8642)\n",
      "Epoch: 9895; D_loss: tensor(0.0735); G_loss: tensor(12.9106)\n",
      "Epoch: 9896; D_loss: tensor(0.0532); G_loss: tensor(8.5163)\n",
      "Epoch: 9897; D_loss: tensor(0.0849); G_loss: tensor(5.4743)\n",
      "Epoch: 9898; D_loss: tensor(0.0760); G_loss: tensor(10.3846)\n",
      "Epoch: 9899; D_loss: tensor(0.0051); G_loss: tensor(12.1407)\n",
      "Epoch: 9900; D_loss: tensor(0.0160); G_loss: tensor(11.7138)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9901; D_loss: tensor(0.0182); G_loss: tensor(6.6036)\n",
      "Epoch: 9902; D_loss: tensor(0.0347); G_loss: tensor(7.8380)\n",
      "Epoch: 9903; D_loss: tensor(0.0061); G_loss: tensor(10.6481)\n",
      "Epoch: 9904; D_loss: tensor(0.0023); G_loss: tensor(16.0646)\n",
      "Epoch: 9905; D_loss: tensor(0.0160); G_loss: tensor(4.8133)\n",
      "Epoch: 9906; D_loss: tensor(0.0183); G_loss: tensor(5.9661)\n",
      "Epoch: 9907; D_loss: tensor(0.0180); G_loss: tensor(13.4850)\n",
      "Epoch: 9908; D_loss: tensor(0.1528); G_loss: tensor(14.8865)\n",
      "Epoch: 9909; D_loss: tensor(0.0029); G_loss: tensor(10.5173)\n",
      "Epoch: 9910; D_loss: tensor(0.0261); G_loss: tensor(5.5696)\n",
      "Epoch: 9911; D_loss: tensor(0.0318); G_loss: tensor(8.2942)\n",
      "Epoch: 9912; D_loss: tensor(0.0504); G_loss: tensor(12.8781)\n",
      "Epoch: 9913; D_loss: tensor(0.0731); G_loss: tensor(5.5552)\n",
      "Epoch: 9914; D_loss: tensor(0.1169); G_loss: tensor(6.5888)\n",
      "Epoch: 9915; D_loss: tensor(0.1324); G_loss: tensor(12.2531)\n",
      "Epoch: 9916; D_loss: tensor(0.0108); G_loss: tensor(9.8709)\n",
      "Epoch: 9917; D_loss: tensor(0.0054); G_loss: tensor(8.0571)\n",
      "Epoch: 9918; D_loss: tensor(0.0067); G_loss: tensor(11.3574)\n",
      "Epoch: 9919; D_loss: tensor(0.0010); G_loss: tensor(12.5823)\n",
      "Epoch: 9920; D_loss: tensor(0.0124); G_loss: tensor(15.6332)\n",
      "Epoch: 9921; D_loss: tensor(0.0015); G_loss: tensor(13.1566)\n",
      "Epoch: 9922; D_loss: tensor(0.0071); G_loss: tensor(13.3373)\n",
      "Epoch: 9923; D_loss: tensor(0.0373); G_loss: tensor(10.4051)\n",
      "Epoch: 9924; D_loss: tensor(0.0034); G_loss: tensor(9.4128)\n",
      "Epoch: 9925; D_loss: tensor(0.0039); G_loss: tensor(7.7542)\n",
      "Epoch: 9926; D_loss: tensor(0.0025); G_loss: tensor(11.8427)\n",
      "Epoch: 9927; D_loss: tensor(0.0055); G_loss: tensor(12.0513)\n",
      "Epoch: 9928; D_loss: tensor(0.0008); G_loss: tensor(10.9551)\n",
      "Epoch: 9929; D_loss: tensor(0.0011); G_loss: tensor(9.9085)\n",
      "Epoch: 9930; D_loss: tensor(0.0066); G_loss: tensor(7.2183)\n",
      "Epoch: 9931; D_loss: tensor(0.0445); G_loss: tensor(5.3645)\n",
      "Epoch: 9932; D_loss: tensor(0.0059); G_loss: tensor(7.9571)\n",
      "Epoch: 9933; D_loss: tensor(0.0058); G_loss: tensor(11.0077)\n",
      "Epoch: 9934; D_loss: tensor(0.0179); G_loss: tensor(10.9895)\n",
      "Epoch: 9935; D_loss: tensor(0.0205); G_loss: tensor(8.6807)\n",
      "Epoch: 9936; D_loss: tensor(0.0177); G_loss: tensor(7.9106)\n",
      "Epoch: 9937; D_loss: tensor(0.0300); G_loss: tensor(4.5837)\n",
      "Epoch: 9938; D_loss: tensor(0.0096); G_loss: tensor(8.7100)\n",
      "Epoch: 9939; D_loss: tensor(0.0165); G_loss: tensor(10.5848)\n",
      "Epoch: 9940; D_loss: tensor(0.0325); G_loss: tensor(11.1341)\n",
      "Epoch: 9941; D_loss: tensor(0.0032); G_loss: tensor(9.9511)\n",
      "Epoch: 9942; D_loss: tensor(0.0133); G_loss: tensor(8.4540)\n",
      "Epoch: 9943; D_loss: tensor(0.0109); G_loss: tensor(8.0886)\n",
      "Epoch: 9944; D_loss: tensor(0.0751); G_loss: tensor(9.5791)\n",
      "Epoch: 9945; D_loss: tensor(0.0148); G_loss: tensor(7.0611)\n",
      "Epoch: 9946; D_loss: tensor(0.0037); G_loss: tensor(6.1800)\n",
      "Epoch: 9947; D_loss: tensor(0.0055); G_loss: tensor(7.6151)\n",
      "Epoch: 9948; D_loss: tensor(0.0717); G_loss: tensor(9.9547)\n",
      "Epoch: 9949; D_loss: tensor(0.0028); G_loss: tensor(9.2962)\n",
      "Epoch: 9950; D_loss: tensor(0.0013); G_loss: tensor(10.1498)\n",
      "Epoch: 9951; D_loss: tensor(0.0201); G_loss: tensor(8.5541)\n",
      "Epoch: 9952; D_loss: tensor(0.1029); G_loss: tensor(7.1491)\n",
      "Epoch: 9953; D_loss: tensor(0.1065); G_loss: tensor(3.9393)\n",
      "Epoch: 9954; D_loss: tensor(0.0089); G_loss: tensor(5.0948)\n",
      "Epoch: 9955; D_loss: tensor(0.0226); G_loss: tensor(11.2881)\n",
      "Epoch: 9956; D_loss: tensor(0.0090); G_loss: tensor(6.4600)\n",
      "Epoch: 9957; D_loss: tensor(0.0386); G_loss: tensor(3.8080)\n",
      "Epoch: 9958; D_loss: tensor(0.0681); G_loss: tensor(13.3504)\n",
      "Epoch: 9959; D_loss: tensor(0.0539); G_loss: tensor(2.9321)\n",
      "Epoch: 9960; D_loss: tensor(0.0339); G_loss: tensor(23.1227)\n",
      "Epoch: 9961; D_loss: tensor(0.1438); G_loss: tensor(1.1341)\n",
      "Epoch: 9962; D_loss: tensor(0.0106); G_loss: tensor(16.3682)\n",
      "Epoch: 9963; D_loss: tensor(1.0358); G_loss: tensor(6.8190)\n",
      "Epoch: 9964; D_loss: tensor(0.5192); G_loss: tensor(4.2002)\n",
      "Epoch: 9965; D_loss: tensor(0.0254); G_loss: tensor(11.2168)\n",
      "Epoch: 9966; D_loss: tensor(0.0224); G_loss: tensor(8.1197)\n",
      "Epoch: 9967; D_loss: tensor(0.5461); G_loss: tensor(6.1899)\n",
      "Epoch: 9968; D_loss: tensor(0.0021); G_loss: tensor(9.9181)\n",
      "Epoch: 9969; D_loss: tensor(0.0080); G_loss: tensor(11.3777)\n",
      "Epoch: 9970; D_loss: tensor(0.0608); G_loss: tensor(11.8189)\n",
      "Epoch: 9971; D_loss: tensor(0.0037); G_loss: tensor(10.2347)\n",
      "Epoch: 9972; D_loss: tensor(0.0279); G_loss: tensor(8.4633)\n",
      "Epoch: 9973; D_loss: tensor(0.0253); G_loss: tensor(7.2700)\n",
      "Epoch: 9974; D_loss: tensor(0.0189); G_loss: tensor(6.9420)\n",
      "Epoch: 9975; D_loss: tensor(0.0312); G_loss: tensor(8.0978)\n",
      "Epoch: 9976; D_loss: tensor(0.0180); G_loss: tensor(10.5530)\n",
      "Epoch: 9977; D_loss: tensor(0.0036); G_loss: tensor(9.7707)\n",
      "Epoch: 9978; D_loss: tensor(0.0111); G_loss: tensor(8.2364)\n",
      "Epoch: 9979; D_loss: tensor(0.0320); G_loss: tensor(7.0036)\n",
      "Epoch: 9980; D_loss: tensor(0.0408); G_loss: tensor(7.7086)\n",
      "Epoch: 9981; D_loss: tensor(0.0162); G_loss: tensor(9.2548)\n",
      "Epoch: 9982; D_loss: tensor(0.0268); G_loss: tensor(6.7996)\n",
      "Epoch: 9983; D_loss: tensor(0.0361); G_loss: tensor(7.3758)\n",
      "Epoch: 9984; D_loss: tensor(0.0840); G_loss: tensor(9.4279)\n",
      "Epoch: 9985; D_loss: tensor(0.0183); G_loss: tensor(10.9280)\n",
      "Epoch: 9986; D_loss: tensor(0.0983); G_loss: tensor(9.5918)\n",
      "Epoch: 9987; D_loss: tensor(0.0073); G_loss: tensor(8.1094)\n",
      "Epoch: 9988; D_loss: tensor(0.0155); G_loss: tensor(10.0223)\n",
      "Epoch: 9989; D_loss: tensor(0.0144); G_loss: tensor(8.5560)\n",
      "Epoch: 9990; D_loss: tensor(0.0154); G_loss: tensor(7.3056)\n",
      "Epoch: 9991; D_loss: tensor(0.0773); G_loss: tensor(7.0593)\n",
      "Epoch: 9992; D_loss: tensor(0.0463); G_loss: tensor(10.3398)\n",
      "Epoch: 9993; D_loss: tensor(0.0099); G_loss: tensor(15.7582)\n",
      "Epoch: 9994; D_loss: tensor(0.0557); G_loss: tensor(10.2444)\n",
      "Epoch: 9995; D_loss: tensor(0.0784); G_loss: tensor(5.0906)\n",
      "Epoch: 9996; D_loss: tensor(0.0142); G_loss: tensor(8.2997)\n",
      "Epoch: 9997; D_loss: tensor(0.0497); G_loss: tensor(8.5460)\n",
      "Epoch: 9998; D_loss: tensor(0.0117); G_loss: tensor(11.4297)\n",
      "Epoch: 9999; D_loss: tensor(0.0193); G_loss: tensor(11.6743)\n",
      "Epoch: 10000; D_loss: tensor(0.0077); G_loss: tensor(10.3114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10001; D_loss: tensor(0.0034); G_loss: tensor(9.0457)\n",
      "Epoch: 10002; D_loss: tensor(0.0125); G_loss: tensor(8.2108)\n",
      "Epoch: 10003; D_loss: tensor(0.0500); G_loss: tensor(8.3928)\n",
      "Epoch: 10004; D_loss: tensor(0.0067); G_loss: tensor(9.6420)\n",
      "Epoch: 10005; D_loss: tensor(0.0289); G_loss: tensor(8.1551)\n",
      "Epoch: 10006; D_loss: tensor(0.0023); G_loss: tensor(9.7733)\n",
      "Epoch: 10007; D_loss: tensor(0.0154); G_loss: tensor(7.6666)\n",
      "Epoch: 10008; D_loss: tensor(0.0333); G_loss: tensor(7.8009)\n",
      "Epoch: 10009; D_loss: tensor(0.0619); G_loss: tensor(10.3135)\n",
      "Epoch: 10010; D_loss: tensor(0.0030); G_loss: tensor(5.2188)\n",
      "Epoch: 10011; D_loss: tensor(0.0165); G_loss: tensor(8.7847)\n",
      "Epoch: 10012; D_loss: tensor(0.0073); G_loss: tensor(7.9518)\n",
      "Epoch: 10013; D_loss: tensor(0.0080); G_loss: tensor(10.3568)\n",
      "Epoch: 10014; D_loss: tensor(0.0040); G_loss: tensor(10.3520)\n",
      "Epoch: 10015; D_loss: tensor(0.0037); G_loss: tensor(9.5463)\n",
      "Epoch: 10016; D_loss: tensor(0.0116); G_loss: tensor(8.1500)\n",
      "Epoch: 10017; D_loss: tensor(0.0199); G_loss: tensor(7.9507)\n",
      "Epoch: 10018; D_loss: tensor(0.0024); G_loss: tensor(8.5888)\n",
      "Epoch: 10019; D_loss: tensor(0.0387); G_loss: tensor(7.5781)\n",
      "Epoch: 10020; D_loss: tensor(0.0283); G_loss: tensor(7.9476)\n",
      "Epoch: 10021; D_loss: tensor(0.0103); G_loss: tensor(9.7417)\n",
      "Epoch: 10022; D_loss: tensor(0.0269); G_loss: tensor(8.5292)\n",
      "Epoch: 10023; D_loss: tensor(0.0125); G_loss: tensor(5.4696)\n",
      "Epoch: 10024; D_loss: tensor(0.0224); G_loss: tensor(8.6636)\n",
      "Epoch: 10025; D_loss: tensor(0.0307); G_loss: tensor(9.8196)\n",
      "Epoch: 10026; D_loss: tensor(0.0051); G_loss: tensor(8.5197)\n",
      "Epoch: 10027; D_loss: tensor(0.0112); G_loss: tensor(6.4798)\n",
      "Epoch: 10028; D_loss: tensor(0.0080); G_loss: tensor(6.5936)\n",
      "Epoch: 10029; D_loss: tensor(0.0145); G_loss: tensor(8.8833)\n",
      "Epoch: 10030; D_loss: tensor(0.0214); G_loss: tensor(11.8202)\n",
      "Epoch: 10031; D_loss: tensor(0.0105); G_loss: tensor(9.9563)\n",
      "Epoch: 10032; D_loss: tensor(0.0827); G_loss: tensor(9.2343)\n",
      "Epoch: 10033; D_loss: tensor(0.0120); G_loss: tensor(3.7526)\n",
      "Epoch: 10034; D_loss: tensor(0.0179); G_loss: tensor(6.2216)\n",
      "Epoch: 10035; D_loss: tensor(0.0049); G_loss: tensor(9.6920)\n",
      "Epoch: 10036; D_loss: tensor(0.0136); G_loss: tensor(7.3070)\n",
      "Epoch: 10037; D_loss: tensor(0.0154); G_loss: tensor(6.0972)\n",
      "Epoch: 10038; D_loss: tensor(0.0046); G_loss: tensor(7.4003)\n",
      "Epoch: 10039; D_loss: tensor(0.0290); G_loss: tensor(12.5816)\n",
      "Epoch: 10040; D_loss: tensor(0.0141); G_loss: tensor(8.8972)\n",
      "Epoch: 10041; D_loss: tensor(0.1293); G_loss: tensor(5.6326)\n",
      "Epoch: 10042; D_loss: tensor(0.0187); G_loss: tensor(8.6952)\n",
      "Epoch: 10043; D_loss: tensor(0.0240); G_loss: tensor(11.1755)\n",
      "Epoch: 10044; D_loss: tensor(0.0598); G_loss: tensor(10.2929)\n",
      "Epoch: 10045; D_loss: tensor(0.0255); G_loss: tensor(6.5446)\n",
      "Epoch: 10046; D_loss: tensor(0.1182); G_loss: tensor(6.4854)\n",
      "Epoch: 10047; D_loss: tensor(0.0270); G_loss: tensor(8.9456)\n",
      "Epoch: 10048; D_loss: tensor(0.1082); G_loss: tensor(8.7980)\n",
      "Epoch: 10049; D_loss: tensor(0.0101); G_loss: tensor(6.6943)\n",
      "Epoch: 10050; D_loss: tensor(0.0047); G_loss: tensor(10.1433)\n",
      "Epoch: 10051; D_loss: tensor(0.0099); G_loss: tensor(12.8256)\n",
      "Epoch: 10052; D_loss: tensor(0.0420); G_loss: tensor(11.3116)\n",
      "Epoch: 10053; D_loss: tensor(0.0156); G_loss: tensor(6.9086)\n",
      "Epoch: 10054; D_loss: tensor(0.0219); G_loss: tensor(9.7626)\n",
      "Epoch: 10055; D_loss: tensor(0.0019); G_loss: tensor(11.0409)\n",
      "Epoch: 10056; D_loss: tensor(0.1171); G_loss: tensor(11.4267)\n",
      "Epoch: 10057; D_loss: tensor(0.0011); G_loss: tensor(7.8263)\n",
      "Epoch: 10058; D_loss: tensor(0.0128); G_loss: tensor(7.1893)\n",
      "Epoch: 10059; D_loss: tensor(0.0137); G_loss: tensor(7.4706)\n",
      "Epoch: 10060; D_loss: tensor(0.0504); G_loss: tensor(10.0274)\n",
      "Epoch: 10061; D_loss: tensor(0.0604); G_loss: tensor(8.1218)\n",
      "Epoch: 10062; D_loss: tensor(0.0157); G_loss: tensor(8.2733)\n",
      "Epoch: 10063; D_loss: tensor(0.0350); G_loss: tensor(7.0153)\n",
      "Epoch: 10064; D_loss: tensor(0.0272); G_loss: tensor(7.3547)\n",
      "Epoch: 10065; D_loss: tensor(0.0331); G_loss: tensor(8.0812)\n",
      "Epoch: 10066; D_loss: tensor(0.0873); G_loss: tensor(6.7676)\n",
      "Epoch: 10067; D_loss: tensor(0.0205); G_loss: tensor(5.5371)\n",
      "Epoch: 10068; D_loss: tensor(0.0111); G_loss: tensor(7.7736)\n",
      "Epoch: 10069; D_loss: tensor(0.0132); G_loss: tensor(9.9221)\n",
      "Epoch: 10070; D_loss: tensor(0.0492); G_loss: tensor(11.5514)\n",
      "Epoch: 10071; D_loss: tensor(0.0048); G_loss: tensor(9.5198)\n",
      "Epoch: 10072; D_loss: tensor(0.0058); G_loss: tensor(7.2588)\n",
      "Epoch: 10073; D_loss: tensor(0.0131); G_loss: tensor(7.1719)\n",
      "Epoch: 10074; D_loss: tensor(0.0128); G_loss: tensor(8.0602)\n",
      "Epoch: 10075; D_loss: tensor(0.0085); G_loss: tensor(8.9360)\n",
      "Epoch: 10076; D_loss: tensor(0.0034); G_loss: tensor(9.9027)\n",
      "Epoch: 10077; D_loss: tensor(0.0043); G_loss: tensor(9.4735)\n",
      "Epoch: 10078; D_loss: tensor(0.0088); G_loss: tensor(8.6248)\n",
      "Epoch: 10079; D_loss: tensor(0.0118); G_loss: tensor(7.8098)\n",
      "Epoch: 10080; D_loss: tensor(0.0149); G_loss: tensor(7.9613)\n",
      "Epoch: 10081; D_loss: tensor(0.0184); G_loss: tensor(10.4451)\n",
      "Epoch: 10082; D_loss: tensor(0.0068); G_loss: tensor(9.4342)\n",
      "Epoch: 10083; D_loss: tensor(0.3728); G_loss: tensor(5.4590)\n",
      "Epoch: 10084; D_loss: tensor(0.1003); G_loss: tensor(10.4588)\n",
      "Epoch: 10085; D_loss: tensor(0.0290); G_loss: tensor(6.4626)\n",
      "Epoch: 10086; D_loss: tensor(0.0247); G_loss: tensor(5.6737)\n",
      "Epoch: 10087; D_loss: tensor(0.0284); G_loss: tensor(9.6463)\n",
      "Epoch: 10088; D_loss: tensor(0.0225); G_loss: tensor(12.7867)\n",
      "Epoch: 10089; D_loss: tensor(0.0080); G_loss: tensor(11.2340)\n",
      "Epoch: 10090; D_loss: tensor(0.0312); G_loss: tensor(6.0001)\n",
      "Epoch: 10091; D_loss: tensor(0.0778); G_loss: tensor(5.4492)\n",
      "Epoch: 10092; D_loss: tensor(0.0416); G_loss: tensor(10.4966)\n",
      "Epoch: 10093; D_loss: tensor(0.0602); G_loss: tensor(10.3912)\n",
      "Epoch: 10094; D_loss: tensor(0.0257); G_loss: tensor(8.5065)\n",
      "Epoch: 10095; D_loss: tensor(0.0064); G_loss: tensor(5.0796)\n",
      "Epoch: 10096; D_loss: tensor(0.0286); G_loss: tensor(5.3955)\n",
      "Epoch: 10097; D_loss: tensor(0.0201); G_loss: tensor(7.2498)\n",
      "Epoch: 10098; D_loss: tensor(0.0123); G_loss: tensor(7.3179)\n",
      "Epoch: 10099; D_loss: tensor(0.0175); G_loss: tensor(6.6933)\n",
      "Epoch: 10100; D_loss: tensor(0.0274); G_loss: tensor(9.2836)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10101; D_loss: tensor(0.0073); G_loss: tensor(5.1980)\n",
      "Epoch: 10102; D_loss: tensor(0.0550); G_loss: tensor(4.5866)\n",
      "Epoch: 10103; D_loss: tensor(0.0103); G_loss: tensor(8.9858)\n",
      "Epoch: 10104; D_loss: tensor(0.0007); G_loss: tensor(10.6595)\n",
      "Epoch: 10105; D_loss: tensor(0.0048); G_loss: tensor(10.1566)\n",
      "Epoch: 10106; D_loss: tensor(0.0164); G_loss: tensor(9.4155)\n",
      "Epoch: 10107; D_loss: tensor(0.0083); G_loss: tensor(10.8055)\n",
      "Epoch: 10108; D_loss: tensor(0.0072); G_loss: tensor(8.6553)\n",
      "Epoch: 10109; D_loss: tensor(0.0030); G_loss: tensor(7.6695)\n",
      "Epoch: 10110; D_loss: tensor(0.0312); G_loss: tensor(8.7498)\n",
      "Epoch: 10111; D_loss: tensor(0.0052); G_loss: tensor(8.1798)\n",
      "Epoch: 10112; D_loss: tensor(0.0096); G_loss: tensor(8.5942)\n",
      "Epoch: 10113; D_loss: tensor(0.0350); G_loss: tensor(8.0751)\n",
      "Epoch: 10114; D_loss: tensor(0.0079); G_loss: tensor(9.8276)\n",
      "Epoch: 10115; D_loss: tensor(0.0204); G_loss: tensor(6.6136)\n",
      "Epoch: 10116; D_loss: tensor(0.0227); G_loss: tensor(6.2716)\n",
      "Epoch: 10117; D_loss: tensor(0.0184); G_loss: tensor(6.7909)\n",
      "Epoch: 10118; D_loss: tensor(0.0087); G_loss: tensor(9.0920)\n",
      "Epoch: 10119; D_loss: tensor(0.0105); G_loss: tensor(8.3303)\n",
      "Epoch: 10120; D_loss: tensor(0.0133); G_loss: tensor(8.4042)\n",
      "Epoch: 10121; D_loss: tensor(0.0035); G_loss: tensor(7.1903)\n",
      "Epoch: 10122; D_loss: tensor(0.0050); G_loss: tensor(8.5707)\n",
      "Epoch: 10123; D_loss: tensor(0.0041); G_loss: tensor(7.0463)\n",
      "Epoch: 10124; D_loss: tensor(0.0161); G_loss: tensor(6.9453)\n",
      "Epoch: 10125; D_loss: tensor(0.0046); G_loss: tensor(11.9190)\n",
      "Epoch: 10126; D_loss: tensor(0.0749); G_loss: tensor(9.5471)\n",
      "Epoch: 10127; D_loss: tensor(0.0395); G_loss: tensor(6.7877)\n",
      "Epoch: 10128; D_loss: tensor(0.0097); G_loss: tensor(6.5298)\n",
      "Epoch: 10129; D_loss: tensor(0.0163); G_loss: tensor(9.5957)\n",
      "Epoch: 10130; D_loss: tensor(0.0314); G_loss: tensor(8.4391)\n",
      "Epoch: 10131; D_loss: tensor(0.0052); G_loss: tensor(9.3671)\n",
      "Epoch: 10132; D_loss: tensor(0.1281); G_loss: tensor(7.1525)\n",
      "Epoch: 10133; D_loss: tensor(0.0225); G_loss: tensor(3.9273)\n",
      "Epoch: 10134; D_loss: tensor(0.0106); G_loss: tensor(5.1112)\n",
      "Epoch: 10135; D_loss: tensor(0.0116); G_loss: tensor(8.1192)\n",
      "Epoch: 10136; D_loss: tensor(0.0025); G_loss: tensor(8.7442)\n",
      "Epoch: 10137; D_loss: tensor(0.0069); G_loss: tensor(7.8889)\n",
      "Epoch: 10138; D_loss: tensor(0.0114); G_loss: tensor(7.0318)\n",
      "Epoch: 10139; D_loss: tensor(0.0170); G_loss: tensor(11.6265)\n",
      "Epoch: 10140; D_loss: tensor(0.0030); G_loss: tensor(9.0854)\n",
      "Epoch: 10141; D_loss: tensor(0.0170); G_loss: tensor(8.9488)\n",
      "Epoch: 10142; D_loss: tensor(0.0058); G_loss: tensor(8.2907)\n",
      "Epoch: 10143; D_loss: tensor(0.0617); G_loss: tensor(3.4813)\n",
      "Epoch: 10144; D_loss: tensor(0.0441); G_loss: tensor(8.0142)\n",
      "Epoch: 10145; D_loss: tensor(0.0326); G_loss: tensor(9.3046)\n",
      "Epoch: 10146; D_loss: tensor(0.0767); G_loss: tensor(12.0744)\n",
      "Epoch: 10147; D_loss: tensor(0.0212); G_loss: tensor(7.1164)\n",
      "Epoch: 10148; D_loss: tensor(0.0472); G_loss: tensor(5.7435)\n",
      "Epoch: 10149; D_loss: tensor(0.0413); G_loss: tensor(8.7093)\n",
      "Epoch: 10150; D_loss: tensor(0.0081); G_loss: tensor(8.0490)\n",
      "Epoch: 10151; D_loss: tensor(0.0190); G_loss: tensor(9.3369)\n",
      "Epoch: 10152; D_loss: tensor(0.0387); G_loss: tensor(10.5295)\n",
      "Epoch: 10153; D_loss: tensor(0.0078); G_loss: tensor(9.3633)\n",
      "Epoch: 10154; D_loss: tensor(0.0197); G_loss: tensor(9.0230)\n",
      "Epoch: 10155; D_loss: tensor(0.0456); G_loss: tensor(8.8721)\n",
      "Epoch: 10156; D_loss: tensor(0.0207); G_loss: tensor(11.4609)\n",
      "Epoch: 10157; D_loss: tensor(0.0070); G_loss: tensor(9.5673)\n",
      "Epoch: 10158; D_loss: tensor(0.0022); G_loss: tensor(9.9579)\n",
      "Epoch: 10159; D_loss: tensor(0.0255); G_loss: tensor(9.8006)\n",
      "Epoch: 10160; D_loss: tensor(0.0017); G_loss: tensor(9.1349)\n",
      "Epoch: 10161; D_loss: tensor(0.0150); G_loss: tensor(8.8487)\n",
      "Epoch: 10162; D_loss: tensor(0.0118); G_loss: tensor(9.8526)\n",
      "Epoch: 10163; D_loss: tensor(0.0369); G_loss: tensor(5.7445)\n",
      "Epoch: 10164; D_loss: tensor(0.0979); G_loss: tensor(12.3903)\n",
      "Epoch: 10165; D_loss: tensor(0.1369); G_loss: tensor(1.9842)\n",
      "Epoch: 10166; D_loss: tensor(1.5078); G_loss: tensor(11.7378)\n",
      "Epoch: 10167; D_loss: tensor(0.0529); G_loss: tensor(5.9277)\n",
      "Epoch: 10168; D_loss: tensor(0.0117); G_loss: tensor(10.4925)\n",
      "Epoch: 10169; D_loss: tensor(0.0080); G_loss: tensor(1.4249)\n",
      "Epoch: 10170; D_loss: tensor(0.0468); G_loss: tensor(16.0443)\n",
      "Epoch: 10171; D_loss: tensor(0.4846); G_loss: tensor(12.3359)\n",
      "Epoch: 10172; D_loss: tensor(0.0471); G_loss: tensor(2.0468)\n",
      "Epoch: 10173; D_loss: tensor(0.0156); G_loss: tensor(11.3850)\n",
      "Epoch: 10174; D_loss: tensor(1.6518); G_loss: tensor(14.1950)\n",
      "Epoch: 10175; D_loss: tensor(0.0578); G_loss: tensor(2.3733)\n",
      "Epoch: 10176; D_loss: tensor(0.2679); G_loss: tensor(8.1356)\n",
      "Epoch: 10177; D_loss: tensor(0.0344); G_loss: tensor(16.9454)\n",
      "Epoch: 10178; D_loss: tensor(0.1213); G_loss: tensor(10.4042)\n",
      "Epoch: 10179; D_loss: tensor(0.1668); G_loss: tensor(5.1837)\n",
      "Epoch: 10180; D_loss: tensor(0.3244); G_loss: tensor(8.2744)\n",
      "Epoch: 10181; D_loss: tensor(0.0104); G_loss: tensor(18.5717)\n",
      "Epoch: 10182; D_loss: tensor(0.0732); G_loss: tensor(15.6826)\n",
      "Epoch: 10183; D_loss: tensor(0.1196); G_loss: tensor(6.8075)\n",
      "Epoch: 10184; D_loss: tensor(0.0108); G_loss: tensor(7.0482)\n",
      "Epoch: 10185; D_loss: tensor(0.0198); G_loss: tensor(13.0991)\n",
      "Epoch: 10186; D_loss: tensor(0.0308); G_loss: tensor(12.0159)\n",
      "Epoch: 10187; D_loss: tensor(0.0049); G_loss: tensor(10.8423)\n",
      "Epoch: 10188; D_loss: tensor(0.0204); G_loss: tensor(11.2158)\n",
      "Epoch: 10189; D_loss: tensor(0.0381); G_loss: tensor(10.1879)\n",
      "Epoch: 10190; D_loss: tensor(0.0313); G_loss: tensor(6.6685)\n",
      "Epoch: 10191; D_loss: tensor(0.0092); G_loss: tensor(8.0399)\n",
      "Epoch: 10192; D_loss: tensor(0.0154); G_loss: tensor(8.2249)\n",
      "Epoch: 10193; D_loss: tensor(0.0509); G_loss: tensor(7.5426)\n",
      "Epoch: 10194; D_loss: tensor(0.0309); G_loss: tensor(9.1680)\n",
      "Epoch: 10195; D_loss: tensor(0.0144); G_loss: tensor(12.1278)\n",
      "Epoch: 10196; D_loss: tensor(0.0948); G_loss: tensor(8.6942)\n",
      "Epoch: 10197; D_loss: tensor(0.0624); G_loss: tensor(8.7652)\n",
      "Epoch: 10198; D_loss: tensor(0.0528); G_loss: tensor(6.5049)\n",
      "Epoch: 10199; D_loss: tensor(0.0490); G_loss: tensor(8.9433)\n",
      "Epoch: 10200; D_loss: tensor(0.0200); G_loss: tensor(9.2850)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10201; D_loss: tensor(0.0339); G_loss: tensor(8.7791)\n",
      "Epoch: 10202; D_loss: tensor(0.0046); G_loss: tensor(8.3428)\n",
      "Epoch: 10203; D_loss: tensor(0.0021); G_loss: tensor(8.2814)\n",
      "Epoch: 10204; D_loss: tensor(0.0271); G_loss: tensor(6.8108)\n",
      "Epoch: 10205; D_loss: tensor(0.0105); G_loss: tensor(9.8424)\n",
      "Epoch: 10206; D_loss: tensor(0.0217); G_loss: tensor(9.8143)\n",
      "Epoch: 10207; D_loss: tensor(0.0192); G_loss: tensor(7.3073)\n",
      "Epoch: 10208; D_loss: tensor(0.0653); G_loss: tensor(7.6466)\n",
      "Epoch: 10209; D_loss: tensor(0.0081); G_loss: tensor(9.9164)\n",
      "Epoch: 10210; D_loss: tensor(0.0504); G_loss: tensor(10.5287)\n",
      "Epoch: 10211; D_loss: tensor(0.0208); G_loss: tensor(9.3785)\n",
      "Epoch: 10212; D_loss: tensor(0.0114); G_loss: tensor(7.7400)\n",
      "Epoch: 10213; D_loss: tensor(0.0074); G_loss: tensor(11.0541)\n",
      "Epoch: 10214; D_loss: tensor(0.0039); G_loss: tensor(9.2234)\n",
      "Epoch: 10215; D_loss: tensor(0.0019); G_loss: tensor(9.2068)\n",
      "Epoch: 10216; D_loss: tensor(0.0261); G_loss: tensor(8.8986)\n",
      "Epoch: 10217; D_loss: tensor(0.1541); G_loss: tensor(4.8654)\n",
      "Epoch: 10218; D_loss: tensor(0.1175); G_loss: tensor(7.1675)\n",
      "Epoch: 10219; D_loss: tensor(0.0085); G_loss: tensor(11.4752)\n",
      "Epoch: 10220; D_loss: tensor(0.2726); G_loss: tensor(7.7739)\n",
      "Epoch: 10221; D_loss: tensor(0.0479); G_loss: tensor(5.8628)\n",
      "Epoch: 10222; D_loss: tensor(0.0701); G_loss: tensor(5.2697)\n",
      "Epoch: 10223; D_loss: tensor(0.0080); G_loss: tensor(10.2589)\n",
      "Epoch: 10224; D_loss: tensor(0.0091); G_loss: tensor(12.1572)\n",
      "Epoch: 10225; D_loss: tensor(0.0086); G_loss: tensor(10.1402)\n",
      "Epoch: 10226; D_loss: tensor(0.0231); G_loss: tensor(6.6018)\n",
      "Epoch: 10227; D_loss: tensor(0.0426); G_loss: tensor(6.3400)\n",
      "Epoch: 10228; D_loss: tensor(0.0116); G_loss: tensor(4.8758)\n",
      "Epoch: 10229; D_loss: tensor(0.0067); G_loss: tensor(9.1462)\n",
      "Epoch: 10230; D_loss: tensor(0.0029); G_loss: tensor(10.1922)\n",
      "Epoch: 10231; D_loss: tensor(0.0129); G_loss: tensor(10.4953)\n",
      "Epoch: 10232; D_loss: tensor(0.0188); G_loss: tensor(7.3835)\n",
      "Epoch: 10233; D_loss: tensor(0.0065); G_loss: tensor(7.3523)\n",
      "Epoch: 10234; D_loss: tensor(0.0089); G_loss: tensor(7.9691)\n",
      "Epoch: 10235; D_loss: tensor(0.0216); G_loss: tensor(9.2399)\n",
      "Epoch: 10236; D_loss: tensor(0.0689); G_loss: tensor(9.6437)\n",
      "Epoch: 10237; D_loss: tensor(0.0031); G_loss: tensor(9.3538)\n",
      "Epoch: 10238; D_loss: tensor(0.0041); G_loss: tensor(5.9756)\n",
      "Epoch: 10239; D_loss: tensor(0.0485); G_loss: tensor(8.2864)\n",
      "Epoch: 10240; D_loss: tensor(0.1024); G_loss: tensor(7.0346)\n",
      "Epoch: 10241; D_loss: tensor(0.0101); G_loss: tensor(8.2665)\n",
      "Epoch: 10242; D_loss: tensor(0.0551); G_loss: tensor(6.6932)\n",
      "Epoch: 10243; D_loss: tensor(0.1170); G_loss: tensor(6.6658)\n",
      "Epoch: 10244; D_loss: tensor(0.0078); G_loss: tensor(10.8625)\n",
      "Epoch: 10245; D_loss: tensor(0.2816); G_loss: tensor(12.4149)\n",
      "Epoch: 10246; D_loss: tensor(0.0038); G_loss: tensor(7.3331)\n",
      "Epoch: 10247; D_loss: tensor(0.0230); G_loss: tensor(8.1268)\n",
      "Epoch: 10248; D_loss: tensor(0.0051); G_loss: tensor(12.0978)\n",
      "Epoch: 10249; D_loss: tensor(0.0403); G_loss: tensor(12.1032)\n",
      "Epoch: 10250; D_loss: tensor(0.0040); G_loss: tensor(10.5048)\n",
      "Epoch: 10251; D_loss: tensor(0.0051); G_loss: tensor(7.5812)\n",
      "Epoch: 10252; D_loss: tensor(0.0035); G_loss: tensor(9.9183)\n",
      "Epoch: 10253; D_loss: tensor(0.0098); G_loss: tensor(11.6722)\n",
      "Epoch: 10254; D_loss: tensor(0.0557); G_loss: tensor(14.4491)\n",
      "Epoch: 10255; D_loss: tensor(0.0154); G_loss: tensor(8.5417)\n",
      "Epoch: 10256; D_loss: tensor(0.0037); G_loss: tensor(11.5288)\n",
      "Epoch: 10257; D_loss: tensor(0.0048); G_loss: tensor(8.3502)\n",
      "Epoch: 10258; D_loss: tensor(0.0156); G_loss: tensor(7.2793)\n",
      "Epoch: 10259; D_loss: tensor(0.0058); G_loss: tensor(6.7446)\n",
      "Epoch: 10260; D_loss: tensor(0.0094); G_loss: tensor(8.3026)\n",
      "Epoch: 10261; D_loss: tensor(0.0291); G_loss: tensor(8.6729)\n",
      "Epoch: 10262; D_loss: tensor(0.0146); G_loss: tensor(9.4687)\n",
      "Epoch: 10263; D_loss: tensor(0.0025); G_loss: tensor(11.3854)\n",
      "Epoch: 10264; D_loss: tensor(0.0178); G_loss: tensor(9.2085)\n",
      "Epoch: 10265; D_loss: tensor(0.0258); G_loss: tensor(8.0378)\n",
      "Epoch: 10266; D_loss: tensor(0.0094); G_loss: tensor(7.4348)\n",
      "Epoch: 10267; D_loss: tensor(0.0182); G_loss: tensor(8.7705)\n",
      "Epoch: 10268; D_loss: tensor(0.0064); G_loss: tensor(8.0389)\n",
      "Epoch: 10269; D_loss: tensor(0.0110); G_loss: tensor(8.0287)\n",
      "Epoch: 10270; D_loss: tensor(0.0127); G_loss: tensor(8.8275)\n",
      "Epoch: 10271; D_loss: tensor(0.0042); G_loss: tensor(4.0299)\n",
      "Epoch: 10272; D_loss: tensor(0.1942); G_loss: tensor(6.1283)\n",
      "Epoch: 10273; D_loss: tensor(0.1390); G_loss: tensor(10.9786)\n",
      "Epoch: 10274; D_loss: tensor(0.0169); G_loss: tensor(7.9180)\n",
      "Epoch: 10275; D_loss: tensor(0.0590); G_loss: tensor(10.9193)\n",
      "Epoch: 10276; D_loss: tensor(0.0162); G_loss: tensor(7.8093)\n",
      "Epoch: 10277; D_loss: tensor(0.0573); G_loss: tensor(5.1057)\n",
      "Epoch: 10278; D_loss: tensor(0.0151); G_loss: tensor(9.9014)\n",
      "Epoch: 10279; D_loss: tensor(0.0289); G_loss: tensor(11.5378)\n",
      "Epoch: 10280; D_loss: tensor(0.1221); G_loss: tensor(9.8191)\n",
      "Epoch: 10281; D_loss: tensor(0.0036); G_loss: tensor(9.4401)\n",
      "Epoch: 10282; D_loss: tensor(0.0321); G_loss: tensor(8.6203)\n",
      "Epoch: 10283; D_loss: tensor(0.0122); G_loss: tensor(10.4212)\n",
      "Epoch: 10284; D_loss: tensor(0.0086); G_loss: tensor(7.8461)\n",
      "Epoch: 10285; D_loss: tensor(0.0499); G_loss: tensor(8.6952)\n",
      "Epoch: 10286; D_loss: tensor(0.0155); G_loss: tensor(8.9125)\n",
      "Epoch: 10287; D_loss: tensor(0.0079); G_loss: tensor(7.0304)\n",
      "Epoch: 10288; D_loss: tensor(0.0309); G_loss: tensor(8.0200)\n",
      "Epoch: 10289; D_loss: tensor(0.0202); G_loss: tensor(8.0305)\n",
      "Epoch: 10290; D_loss: tensor(0.0027); G_loss: tensor(12.0703)\n",
      "Epoch: 10291; D_loss: tensor(0.0066); G_loss: tensor(8.4965)\n",
      "Epoch: 10292; D_loss: tensor(0.0803); G_loss: tensor(5.8750)\n",
      "Epoch: 10293; D_loss: tensor(0.0073); G_loss: tensor(11.8656)\n",
      "Epoch: 10294; D_loss: tensor(0.0121); G_loss: tensor(8.3008)\n",
      "Epoch: 10295; D_loss: tensor(0.0471); G_loss: tensor(7.0082)\n",
      "Epoch: 10296; D_loss: tensor(0.0215); G_loss: tensor(8.3878)\n",
      "Epoch: 10297; D_loss: tensor(0.0043); G_loss: tensor(13.5262)\n",
      "Epoch: 10298; D_loss: tensor(0.0798); G_loss: tensor(10.7752)\n",
      "Epoch: 10299; D_loss: tensor(0.0325); G_loss: tensor(9.0300)\n",
      "Epoch: 10300; D_loss: tensor(0.0161); G_loss: tensor(12.0463)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10301; D_loss: tensor(0.0120); G_loss: tensor(10.8972)\n",
      "Epoch: 10302; D_loss: tensor(0.0251); G_loss: tensor(10.1764)\n",
      "Epoch: 10303; D_loss: tensor(0.0234); G_loss: tensor(10.4773)\n",
      "Epoch: 10304; D_loss: tensor(0.0194); G_loss: tensor(6.9965)\n",
      "Epoch: 10305; D_loss: tensor(0.0436); G_loss: tensor(5.7609)\n",
      "Epoch: 10306; D_loss: tensor(0.0257); G_loss: tensor(8.8039)\n",
      "Epoch: 10307; D_loss: tensor(0.0264); G_loss: tensor(7.6996)\n",
      "Epoch: 10308; D_loss: tensor(0.0130); G_loss: tensor(6.4588)\n",
      "Epoch: 10309; D_loss: tensor(0.0026); G_loss: tensor(8.1824)\n",
      "Epoch: 10310; D_loss: tensor(0.0063); G_loss: tensor(9.8578)\n",
      "Epoch: 10311; D_loss: tensor(0.0128); G_loss: tensor(9.0343)\n",
      "Epoch: 10312; D_loss: tensor(0.0135); G_loss: tensor(9.8858)\n",
      "Epoch: 10313; D_loss: tensor(0.0059); G_loss: tensor(8.7995)\n",
      "Epoch: 10314; D_loss: tensor(0.0908); G_loss: tensor(7.8515)\n",
      "Epoch: 10315; D_loss: tensor(0.0061); G_loss: tensor(6.7378)\n",
      "Epoch: 10316; D_loss: tensor(0.0062); G_loss: tensor(9.4677)\n",
      "Epoch: 10317; D_loss: tensor(0.0058); G_loss: tensor(7.8860)\n",
      "Epoch: 10318; D_loss: tensor(0.0019); G_loss: tensor(6.0599)\n",
      "Epoch: 10319; D_loss: tensor(0.0041); G_loss: tensor(8.5574)\n",
      "Epoch: 10320; D_loss: tensor(0.0327); G_loss: tensor(9.6245)\n",
      "Epoch: 10321; D_loss: tensor(0.0105); G_loss: tensor(11.0786)\n",
      "Epoch: 10322; D_loss: tensor(0.0018); G_loss: tensor(6.4271)\n",
      "Epoch: 10323; D_loss: tensor(0.0028); G_loss: tensor(8.1212)\n",
      "Epoch: 10324; D_loss: tensor(0.0155); G_loss: tensor(8.2930)\n",
      "Epoch: 10325; D_loss: tensor(0.0132); G_loss: tensor(11.7923)\n",
      "Epoch: 10326; D_loss: tensor(0.0040); G_loss: tensor(11.6082)\n",
      "Epoch: 10327; D_loss: tensor(0.0025); G_loss: tensor(9.4558)\n",
      "Epoch: 10328; D_loss: tensor(0.0113); G_loss: tensor(8.9096)\n",
      "Epoch: 10329; D_loss: tensor(0.0079); G_loss: tensor(8.3597)\n",
      "Epoch: 10330; D_loss: tensor(0.0241); G_loss: tensor(7.7253)\n",
      "Epoch: 10331; D_loss: tensor(0.0041); G_loss: tensor(6.2667)\n",
      "Epoch: 10332; D_loss: tensor(0.0045); G_loss: tensor(6.6135)\n",
      "Epoch: 10333; D_loss: tensor(0.0072); G_loss: tensor(8.8414)\n",
      "Epoch: 10334; D_loss: tensor(0.0416); G_loss: tensor(8.3180)\n",
      "Epoch: 10335; D_loss: tensor(0.0326); G_loss: tensor(6.4928)\n",
      "Epoch: 10336; D_loss: tensor(0.0138); G_loss: tensor(6.2860)\n",
      "Epoch: 10337; D_loss: tensor(0.0127); G_loss: tensor(7.8620)\n",
      "Epoch: 10338; D_loss: tensor(0.0580); G_loss: tensor(7.5387)\n",
      "Epoch: 10339; D_loss: tensor(0.0073); G_loss: tensor(10.1236)\n",
      "Epoch: 10340; D_loss: tensor(0.0030); G_loss: tensor(8.6861)\n",
      "Epoch: 10341; D_loss: tensor(0.0024); G_loss: tensor(9.1236)\n",
      "Epoch: 10342; D_loss: tensor(0.0095); G_loss: tensor(7.3607)\n",
      "Epoch: 10343; D_loss: tensor(0.0070); G_loss: tensor(9.3485)\n",
      "Epoch: 10344; D_loss: tensor(0.0081); G_loss: tensor(10.1336)\n",
      "Epoch: 10345; D_loss: tensor(0.0413); G_loss: tensor(10.3328)\n",
      "Epoch: 10346; D_loss: tensor(0.0036); G_loss: tensor(7.1668)\n",
      "Epoch: 10347; D_loss: tensor(0.0149); G_loss: tensor(8.3259)\n",
      "Epoch: 10348; D_loss: tensor(0.0020); G_loss: tensor(6.8490)\n",
      "Epoch: 10349; D_loss: tensor(0.0073); G_loss: tensor(9.5781)\n",
      "Epoch: 10350; D_loss: tensor(0.0299); G_loss: tensor(8.7506)\n",
      "Epoch: 10351; D_loss: tensor(0.0573); G_loss: tensor(6.5683)\n",
      "Epoch: 10352; D_loss: tensor(0.1270); G_loss: tensor(2.4972)\n",
      "Epoch: 10353; D_loss: tensor(0.0148); G_loss: tensor(13.5372)\n",
      "Epoch: 10354; D_loss: tensor(0.0443); G_loss: tensor(6.7602)\n",
      "Epoch: 10355; D_loss: tensor(0.1651); G_loss: tensor(5.3876)\n",
      "Epoch: 10356; D_loss: tensor(0.0080); G_loss: tensor(11.3588)\n",
      "Epoch: 10357; D_loss: tensor(0.0199); G_loss: tensor(9.0364)\n",
      "Epoch: 10358; D_loss: tensor(0.0294); G_loss: tensor(5.5687)\n",
      "Epoch: 10359; D_loss: tensor(0.0833); G_loss: tensor(7.3762)\n",
      "Epoch: 10360; D_loss: tensor(0.0638); G_loss: tensor(8.4175)\n",
      "Epoch: 10361; D_loss: tensor(0.0180); G_loss: tensor(6.6146)\n",
      "Epoch: 10362; D_loss: tensor(0.1530); G_loss: tensor(8.0154)\n",
      "Epoch: 10363; D_loss: tensor(0.1909); G_loss: tensor(5.9558)\n",
      "Epoch: 10364; D_loss: tensor(0.0263); G_loss: tensor(8.3928)\n",
      "Epoch: 10365; D_loss: tensor(0.0222); G_loss: tensor(8.2631)\n",
      "Epoch: 10366; D_loss: tensor(0.0057); G_loss: tensor(7.8904)\n",
      "Epoch: 10367; D_loss: tensor(0.0279); G_loss: tensor(7.2145)\n",
      "Epoch: 10368; D_loss: tensor(0.0097); G_loss: tensor(9.2730)\n",
      "Epoch: 10369; D_loss: tensor(0.0345); G_loss: tensor(7.8505)\n",
      "Epoch: 10370; D_loss: tensor(0.0054); G_loss: tensor(7.6399)\n",
      "Epoch: 10371; D_loss: tensor(0.0084); G_loss: tensor(7.9212)\n",
      "Epoch: 10372; D_loss: tensor(0.0129); G_loss: tensor(6.4770)\n",
      "Epoch: 10373; D_loss: tensor(0.0030); G_loss: tensor(7.9130)\n",
      "Epoch: 10374; D_loss: tensor(0.0339); G_loss: tensor(9.1384)\n",
      "Epoch: 10375; D_loss: tensor(0.0064); G_loss: tensor(9.5455)\n",
      "Epoch: 10376; D_loss: tensor(0.0311); G_loss: tensor(7.1817)\n",
      "Epoch: 10377; D_loss: tensor(0.0082); G_loss: tensor(8.3866)\n",
      "Epoch: 10378; D_loss: tensor(0.0054); G_loss: tensor(5.7861)\n",
      "Epoch: 10379; D_loss: tensor(0.0339); G_loss: tensor(5.5925)\n",
      "Epoch: 10380; D_loss: tensor(0.1182); G_loss: tensor(7.8233)\n",
      "Epoch: 10381; D_loss: tensor(0.0191); G_loss: tensor(7.5194)\n",
      "Epoch: 10382; D_loss: tensor(0.0033); G_loss: tensor(7.9976)\n",
      "Epoch: 10383; D_loss: tensor(0.0327); G_loss: tensor(7.6776)\n",
      "Epoch: 10384; D_loss: tensor(0.0014); G_loss: tensor(11.4853)\n",
      "Epoch: 10385; D_loss: tensor(0.0043); G_loss: tensor(8.4812)\n",
      "Epoch: 10386; D_loss: tensor(0.0264); G_loss: tensor(11.3697)\n",
      "Epoch: 10387; D_loss: tensor(0.0181); G_loss: tensor(10.0379)\n",
      "Epoch: 10388; D_loss: tensor(0.4969); G_loss: tensor(7.7011)\n",
      "Epoch: 10389; D_loss: tensor(0.5582); G_loss: tensor(8.6131)\n",
      "Epoch: 10390; D_loss: tensor(0.3434); G_loss: tensor(14.0048)\n",
      "Epoch: 10391; D_loss: tensor(0.0156); G_loss: tensor(7.9144)\n",
      "Epoch: 10392; D_loss: tensor(0.0989); G_loss: tensor(6.3329)\n",
      "Epoch: 10393; D_loss: tensor(0.0185); G_loss: tensor(10.2970)\n",
      "Epoch: 10394; D_loss: tensor(0.0603); G_loss: tensor(8.6743)\n",
      "Epoch: 10395; D_loss: tensor(0.0352); G_loss: tensor(6.4643)\n",
      "Epoch: 10396; D_loss: tensor(0.0459); G_loss: tensor(6.9341)\n",
      "Epoch: 10397; D_loss: tensor(0.0437); G_loss: tensor(10.5025)\n",
      "Epoch: 10398; D_loss: tensor(0.1310); G_loss: tensor(13.0959)\n",
      "Epoch: 10399; D_loss: tensor(0.0199); G_loss: tensor(9.3603)\n",
      "Epoch: 10400; D_loss: tensor(0.0131); G_loss: tensor(6.9802)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10401; D_loss: tensor(0.0050); G_loss: tensor(10.5857)\n",
      "Epoch: 10402; D_loss: tensor(0.0102); G_loss: tensor(11.9071)\n",
      "Epoch: 10403; D_loss: tensor(0.0568); G_loss: tensor(8.1617)\n",
      "Epoch: 10404; D_loss: tensor(0.0095); G_loss: tensor(3.2948)\n",
      "Epoch: 10405; D_loss: tensor(0.0239); G_loss: tensor(6.9790)\n",
      "Epoch: 10406; D_loss: tensor(0.0046); G_loss: tensor(9.5720)\n",
      "Epoch: 10407; D_loss: tensor(0.0819); G_loss: tensor(9.7556)\n",
      "Epoch: 10408; D_loss: tensor(0.0050); G_loss: tensor(12.2814)\n",
      "Epoch: 10409; D_loss: tensor(0.0056); G_loss: tensor(10.0444)\n",
      "Epoch: 10410; D_loss: tensor(0.0045); G_loss: tensor(8.1168)\n",
      "Epoch: 10411; D_loss: tensor(0.0078); G_loss: tensor(6.3150)\n",
      "Epoch: 10412; D_loss: tensor(0.0707); G_loss: tensor(7.6323)\n",
      "Epoch: 10413; D_loss: tensor(0.0199); G_loss: tensor(9.0075)\n",
      "Epoch: 10414; D_loss: tensor(0.0048); G_loss: tensor(8.1528)\n",
      "Epoch: 10415; D_loss: tensor(0.0029); G_loss: tensor(9.4048)\n",
      "Epoch: 10416; D_loss: tensor(0.0030); G_loss: tensor(11.9969)\n",
      "Epoch: 10417; D_loss: tensor(0.0149); G_loss: tensor(10.7399)\n",
      "Epoch: 10418; D_loss: tensor(0.0741); G_loss: tensor(10.3427)\n",
      "Epoch: 10419; D_loss: tensor(0.0039); G_loss: tensor(8.4355)\n",
      "Epoch: 10420; D_loss: tensor(0.0459); G_loss: tensor(7.4056)\n",
      "Epoch: 10421; D_loss: tensor(0.0411); G_loss: tensor(7.1948)\n",
      "Epoch: 10422; D_loss: tensor(0.0025); G_loss: tensor(9.5920)\n",
      "Epoch: 10423; D_loss: tensor(0.0071); G_loss: tensor(8.3766)\n",
      "Epoch: 10424; D_loss: tensor(0.0130); G_loss: tensor(8.5358)\n",
      "Epoch: 10425; D_loss: tensor(0.0131); G_loss: tensor(7.9357)\n",
      "Epoch: 10426; D_loss: tensor(0.0410); G_loss: tensor(7.0812)\n",
      "Epoch: 10427; D_loss: tensor(0.0311); G_loss: tensor(6.2492)\n",
      "Epoch: 10428; D_loss: tensor(0.0040); G_loss: tensor(11.1080)\n",
      "Epoch: 10429; D_loss: tensor(0.0028); G_loss: tensor(9.4620)\n",
      "Epoch: 10430; D_loss: tensor(0.0548); G_loss: tensor(7.1599)\n",
      "Epoch: 10431; D_loss: tensor(0.0361); G_loss: tensor(6.2022)\n",
      "Epoch: 10432; D_loss: tensor(0.0033); G_loss: tensor(4.9975)\n",
      "Epoch: 10433; D_loss: tensor(0.0049); G_loss: tensor(9.6630)\n",
      "Epoch: 10434; D_loss: tensor(0.0084); G_loss: tensor(10.0447)\n",
      "Epoch: 10435; D_loss: tensor(0.0068); G_loss: tensor(11.0966)\n",
      "Epoch: 10436; D_loss: tensor(0.2168); G_loss: tensor(4.2393)\n",
      "Epoch: 10437; D_loss: tensor(0.1223); G_loss: tensor(5.6541)\n",
      "Epoch: 10438; D_loss: tensor(0.0508); G_loss: tensor(16.2880)\n",
      "Epoch: 10439; D_loss: tensor(0.0054); G_loss: tensor(5.7183)\n",
      "Epoch: 10440; D_loss: tensor(0.1037); G_loss: tensor(11.4381)\n",
      "Epoch: 10441; D_loss: tensor(0.3416); G_loss: tensor(6.1035)\n",
      "Epoch: 10442; D_loss: tensor(1.6013); G_loss: tensor(8.5096)\n",
      "Epoch: 10443; D_loss: tensor(0.0160); G_loss: tensor(10.3652)\n",
      "Epoch: 10444; D_loss: tensor(0.0693); G_loss: tensor(7.8672)\n",
      "Epoch: 10445; D_loss: tensor(0.0181); G_loss: tensor(8.6112)\n",
      "Epoch: 10446; D_loss: tensor(0.1015); G_loss: tensor(8.5412)\n",
      "Epoch: 10447; D_loss: tensor(0.0539); G_loss: tensor(11.3395)\n",
      "Epoch: 10448; D_loss: tensor(0.0048); G_loss: tensor(11.5709)\n",
      "Epoch: 10449; D_loss: tensor(0.0126); G_loss: tensor(9.0061)\n",
      "Epoch: 10450; D_loss: tensor(0.0243); G_loss: tensor(8.0540)\n",
      "Epoch: 10451; D_loss: tensor(0.0199); G_loss: tensor(8.5558)\n",
      "Epoch: 10452; D_loss: tensor(0.0812); G_loss: tensor(8.2285)\n",
      "Epoch: 10453; D_loss: tensor(0.0082); G_loss: tensor(11.6290)\n",
      "Epoch: 10454; D_loss: tensor(0.1915); G_loss: tensor(8.4654)\n",
      "Epoch: 10455; D_loss: tensor(0.1225); G_loss: tensor(7.0630)\n",
      "Epoch: 10456; D_loss: tensor(0.0655); G_loss: tensor(10.2226)\n",
      "Epoch: 10457; D_loss: tensor(0.0333); G_loss: tensor(10.5414)\n",
      "Epoch: 10458; D_loss: tensor(0.0216); G_loss: tensor(6.6566)\n",
      "Epoch: 10459; D_loss: tensor(0.0223); G_loss: tensor(7.9199)\n",
      "Epoch: 10460; D_loss: tensor(0.0779); G_loss: tensor(8.2136)\n",
      "Epoch: 10461; D_loss: tensor(0.0530); G_loss: tensor(9.8148)\n",
      "Epoch: 10462; D_loss: tensor(0.0493); G_loss: tensor(9.6845)\n",
      "Epoch: 10463; D_loss: tensor(0.0447); G_loss: tensor(8.7917)\n",
      "Epoch: 10464; D_loss: tensor(0.0334); G_loss: tensor(8.3949)\n",
      "Epoch: 10465; D_loss: tensor(0.0250); G_loss: tensor(9.6872)\n",
      "Epoch: 10466; D_loss: tensor(0.0500); G_loss: tensor(7.8166)\n",
      "Epoch: 10467; D_loss: tensor(0.1153); G_loss: tensor(8.0521)\n",
      "Epoch: 10468; D_loss: tensor(0.0272); G_loss: tensor(8.4885)\n",
      "Epoch: 10469; D_loss: tensor(0.0066); G_loss: tensor(10.3730)\n",
      "Epoch: 10470; D_loss: tensor(0.0146); G_loss: tensor(9.6235)\n",
      "Epoch: 10471; D_loss: tensor(0.0022); G_loss: tensor(9.3489)\n",
      "Epoch: 10472; D_loss: tensor(0.0360); G_loss: tensor(10.2357)\n",
      "Epoch: 10473; D_loss: tensor(0.0142); G_loss: tensor(7.6557)\n",
      "Epoch: 10474; D_loss: tensor(0.0098); G_loss: tensor(8.5024)\n",
      "Epoch: 10475; D_loss: tensor(0.0214); G_loss: tensor(7.8065)\n",
      "Epoch: 10476; D_loss: tensor(0.0217); G_loss: tensor(9.8205)\n",
      "Epoch: 10477; D_loss: tensor(0.0173); G_loss: tensor(10.9849)\n",
      "Epoch: 10478; D_loss: tensor(0.0043); G_loss: tensor(9.4284)\n",
      "Epoch: 10479; D_loss: tensor(0.1561); G_loss: tensor(7.5199)\n",
      "Epoch: 10480; D_loss: tensor(0.0026); G_loss: tensor(8.4119)\n",
      "Epoch: 10481; D_loss: tensor(0.0074); G_loss: tensor(9.1569)\n",
      "Epoch: 10482; D_loss: tensor(0.0221); G_loss: tensor(11.2874)\n",
      "Epoch: 10483; D_loss: tensor(0.1549); G_loss: tensor(9.0947)\n",
      "Epoch: 10484; D_loss: tensor(0.0389); G_loss: tensor(6.3707)\n",
      "Epoch: 10485; D_loss: tensor(0.0352); G_loss: tensor(7.4461)\n",
      "Epoch: 10486; D_loss: tensor(0.0105); G_loss: tensor(10.5046)\n",
      "Epoch: 10487; D_loss: tensor(0.0419); G_loss: tensor(9.4685)\n",
      "Epoch: 10488; D_loss: tensor(0.0121); G_loss: tensor(9.9367)\n",
      "Epoch: 10489; D_loss: tensor(0.0036); G_loss: tensor(7.2039)\n",
      "Epoch: 10490; D_loss: tensor(0.0115); G_loss: tensor(11.9016)\n",
      "Epoch: 10491; D_loss: tensor(0.0070); G_loss: tensor(6.5119)\n",
      "Epoch: 10492; D_loss: tensor(0.0414); G_loss: tensor(7.0919)\n",
      "Epoch: 10493; D_loss: tensor(0.0713); G_loss: tensor(6.2481)\n",
      "Epoch: 10494; D_loss: tensor(0.0115); G_loss: tensor(9.6533)\n",
      "Epoch: 10495; D_loss: tensor(0.0106); G_loss: tensor(9.1129)\n",
      "Epoch: 10496; D_loss: tensor(0.0128); G_loss: tensor(7.1399)\n",
      "Epoch: 10497; D_loss: tensor(0.0039); G_loss: tensor(6.0575)\n",
      "Epoch: 10498; D_loss: tensor(0.0066); G_loss: tensor(6.1458)\n",
      "Epoch: 10499; D_loss: tensor(0.0096); G_loss: tensor(5.2710)\n",
      "Epoch: 10500; D_loss: tensor(0.0114); G_loss: tensor(7.8602)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10501; D_loss: tensor(0.0556); G_loss: tensor(7.9986)\n",
      "Epoch: 10502; D_loss: tensor(0.0329); G_loss: tensor(8.2842)\n",
      "Epoch: 10503; D_loss: tensor(0.0110); G_loss: tensor(7.4055)\n",
      "Epoch: 10504; D_loss: tensor(0.0276); G_loss: tensor(6.0614)\n",
      "Epoch: 10505; D_loss: tensor(0.0240); G_loss: tensor(6.6086)\n",
      "Epoch: 10506; D_loss: tensor(0.0080); G_loss: tensor(10.1763)\n",
      "Epoch: 10507; D_loss: tensor(0.0202); G_loss: tensor(10.4717)\n",
      "Epoch: 10508; D_loss: tensor(0.1025); G_loss: tensor(10.2501)\n",
      "Epoch: 10509; D_loss: tensor(0.0026); G_loss: tensor(7.5931)\n",
      "Epoch: 10510; D_loss: tensor(0.0227); G_loss: tensor(6.3363)\n",
      "Epoch: 10511; D_loss: tensor(0.0351); G_loss: tensor(5.3012)\n",
      "Epoch: 10512; D_loss: tensor(0.0355); G_loss: tensor(10.4312)\n",
      "Epoch: 10513; D_loss: tensor(0.0664); G_loss: tensor(10.5192)\n",
      "Epoch: 10514; D_loss: tensor(0.0245); G_loss: tensor(6.6308)\n",
      "Epoch: 10515; D_loss: tensor(0.0143); G_loss: tensor(6.8199)\n",
      "Epoch: 10516; D_loss: tensor(0.0161); G_loss: tensor(6.0766)\n",
      "Epoch: 10517; D_loss: tensor(0.0367); G_loss: tensor(8.8426)\n",
      "Epoch: 10518; D_loss: tensor(0.0177); G_loss: tensor(10.1182)\n",
      "Epoch: 10519; D_loss: tensor(0.0265); G_loss: tensor(7.3059)\n",
      "Epoch: 10520; D_loss: tensor(0.0188); G_loss: tensor(7.6898)\n",
      "Epoch: 10521; D_loss: tensor(0.0171); G_loss: tensor(8.5304)\n",
      "Epoch: 10522; D_loss: tensor(0.0072); G_loss: tensor(7.6755)\n",
      "Epoch: 10523; D_loss: tensor(0.0110); G_loss: tensor(7.9612)\n",
      "Epoch: 10524; D_loss: tensor(0.0309); G_loss: tensor(6.8309)\n",
      "Epoch: 10525; D_loss: tensor(0.0022); G_loss: tensor(7.0620)\n",
      "Epoch: 10526; D_loss: tensor(0.0057); G_loss: tensor(8.0597)\n",
      "Epoch: 10527; D_loss: tensor(0.0145); G_loss: tensor(8.7735)\n",
      "Epoch: 10528; D_loss: tensor(0.0038); G_loss: tensor(7.7063)\n",
      "Epoch: 10529; D_loss: tensor(0.0137); G_loss: tensor(5.2449)\n",
      "Epoch: 10530; D_loss: tensor(0.0174); G_loss: tensor(8.2108)\n",
      "Epoch: 10531; D_loss: tensor(0.0056); G_loss: tensor(7.9349)\n",
      "Epoch: 10532; D_loss: tensor(0.0342); G_loss: tensor(8.0783)\n",
      "Epoch: 10533; D_loss: tensor(0.0071); G_loss: tensor(6.9108)\n",
      "Epoch: 10534; D_loss: tensor(0.0126); G_loss: tensor(6.9630)\n",
      "Epoch: 10535; D_loss: tensor(0.0228); G_loss: tensor(8.1118)\n",
      "Epoch: 10536; D_loss: tensor(0.0214); G_loss: tensor(8.4153)\n",
      "Epoch: 10537; D_loss: tensor(0.0146); G_loss: tensor(7.3086)\n",
      "Epoch: 10538; D_loss: tensor(0.0187); G_loss: tensor(8.1929)\n",
      "Epoch: 10539; D_loss: tensor(0.0132); G_loss: tensor(8.1583)\n",
      "Epoch: 10540; D_loss: tensor(0.0153); G_loss: tensor(9.0652)\n",
      "Epoch: 10541; D_loss: tensor(0.0341); G_loss: tensor(8.8814)\n",
      "Epoch: 10542; D_loss: tensor(0.0415); G_loss: tensor(8.0978)\n",
      "Epoch: 10543; D_loss: tensor(0.0163); G_loss: tensor(6.8692)\n",
      "Epoch: 10544; D_loss: tensor(0.0263); G_loss: tensor(7.3117)\n",
      "Epoch: 10545; D_loss: tensor(0.0178); G_loss: tensor(8.3145)\n",
      "Epoch: 10546; D_loss: tensor(0.0411); G_loss: tensor(6.8411)\n",
      "Epoch: 10547; D_loss: tensor(0.0192); G_loss: tensor(6.7153)\n",
      "Epoch: 10548; D_loss: tensor(0.0079); G_loss: tensor(10.0582)\n",
      "Epoch: 10549; D_loss: tensor(0.0070); G_loss: tensor(10.9966)\n",
      "Epoch: 10550; D_loss: tensor(0.0220); G_loss: tensor(7.9089)\n",
      "Epoch: 10551; D_loss: tensor(0.0106); G_loss: tensor(8.0793)\n",
      "Epoch: 10552; D_loss: tensor(0.0031); G_loss: tensor(5.9894)\n",
      "Epoch: 10553; D_loss: tensor(0.0092); G_loss: tensor(7.6468)\n",
      "Epoch: 10554; D_loss: tensor(0.0485); G_loss: tensor(7.8228)\n",
      "Epoch: 10555; D_loss: tensor(0.0032); G_loss: tensor(6.8004)\n",
      "Epoch: 10556; D_loss: tensor(0.0155); G_loss: tensor(6.7472)\n",
      "Epoch: 10557; D_loss: tensor(0.0428); G_loss: tensor(9.0761)\n",
      "Epoch: 10558; D_loss: tensor(0.0160); G_loss: tensor(9.5917)\n",
      "Epoch: 10559; D_loss: tensor(0.0067); G_loss: tensor(8.8318)\n",
      "Epoch: 10560; D_loss: tensor(0.0185); G_loss: tensor(8.4499)\n",
      "Epoch: 10561; D_loss: tensor(0.0811); G_loss: tensor(8.6082)\n",
      "Epoch: 10562; D_loss: tensor(0.0073); G_loss: tensor(9.5685)\n",
      "Epoch: 10563; D_loss: tensor(0.0179); G_loss: tensor(8.3450)\n",
      "Epoch: 10564; D_loss: tensor(0.0323); G_loss: tensor(8.0008)\n",
      "Epoch: 10565; D_loss: tensor(0.0062); G_loss: tensor(8.5570)\n",
      "Epoch: 10566; D_loss: tensor(0.0517); G_loss: tensor(9.1713)\n",
      "Epoch: 10567; D_loss: tensor(0.0298); G_loss: tensor(5.9180)\n",
      "Epoch: 10568; D_loss: tensor(0.0545); G_loss: tensor(7.5282)\n",
      "Epoch: 10569; D_loss: tensor(0.0103); G_loss: tensor(12.0847)\n",
      "Epoch: 10570; D_loss: tensor(0.0181); G_loss: tensor(8.6971)\n",
      "Epoch: 10571; D_loss: tensor(0.0210); G_loss: tensor(5.2786)\n",
      "Epoch: 10572; D_loss: tensor(0.0117); G_loss: tensor(7.5718)\n",
      "Epoch: 10573; D_loss: tensor(0.0037); G_loss: tensor(9.8528)\n",
      "Epoch: 10574; D_loss: tensor(0.4141); G_loss: tensor(3.3902)\n",
      "Epoch: 10575; D_loss: tensor(0.0423); G_loss: tensor(12.7972)\n",
      "Epoch: 10576; D_loss: tensor(0.0706); G_loss: tensor(10.1354)\n",
      "Epoch: 10577; D_loss: tensor(0.0315); G_loss: tensor(4.8251)\n",
      "Epoch: 10578; D_loss: tensor(0.0171); G_loss: tensor(8.4800)\n",
      "Epoch: 10579; D_loss: tensor(0.0298); G_loss: tensor(14.2225)\n",
      "Epoch: 10580; D_loss: tensor(0.1236); G_loss: tensor(12.2786)\n",
      "Epoch: 10581; D_loss: tensor(0.0406); G_loss: tensor(7.5906)\n",
      "Epoch: 10582; D_loss: tensor(0.0049); G_loss: tensor(8.6744)\n",
      "Epoch: 10583; D_loss: tensor(0.0449); G_loss: tensor(13.1579)\n",
      "Epoch: 10584; D_loss: tensor(0.0056); G_loss: tensor(11.2249)\n",
      "Epoch: 10585; D_loss: tensor(0.0129); G_loss: tensor(7.8620)\n",
      "Epoch: 10586; D_loss: tensor(0.0022); G_loss: tensor(7.3865)\n",
      "Epoch: 10587; D_loss: tensor(0.0222); G_loss: tensor(7.0255)\n",
      "Epoch: 10588; D_loss: tensor(0.0093); G_loss: tensor(5.5356)\n",
      "Epoch: 10589; D_loss: tensor(0.0081); G_loss: tensor(8.3034)\n",
      "Epoch: 10590; D_loss: tensor(0.0581); G_loss: tensor(6.6677)\n",
      "Epoch: 10591; D_loss: tensor(0.0154); G_loss: tensor(8.3685)\n",
      "Epoch: 10592; D_loss: tensor(0.1549); G_loss: tensor(6.2430)\n",
      "Epoch: 10593; D_loss: tensor(0.0188); G_loss: tensor(7.1830)\n",
      "Epoch: 10594; D_loss: tensor(0.0269); G_loss: tensor(9.0451)\n",
      "Epoch: 10595; D_loss: tensor(0.0343); G_loss: tensor(11.3094)\n",
      "Epoch: 10596; D_loss: tensor(0.0265); G_loss: tensor(10.6227)\n",
      "Epoch: 10597; D_loss: tensor(0.0093); G_loss: tensor(12.7681)\n",
      "Epoch: 10598; D_loss: tensor(0.0097); G_loss: tensor(11.1541)\n",
      "Epoch: 10599; D_loss: tensor(0.0016); G_loss: tensor(14.3270)\n",
      "Epoch: 10600; D_loss: tensor(0.7995); G_loss: tensor(7.5164)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10601; D_loss: tensor(0.0867); G_loss: tensor(7.9217)\n",
      "Epoch: 10602; D_loss: tensor(0.0031); G_loss: tensor(9.6117)\n",
      "Epoch: 10603; D_loss: tensor(0.0021); G_loss: tensor(9.5573)\n",
      "Epoch: 10604; D_loss: tensor(0.0070); G_loss: tensor(8.5129)\n",
      "Epoch: 10605; D_loss: tensor(0.0457); G_loss: tensor(6.2508)\n",
      "Epoch: 10606; D_loss: tensor(0.0089); G_loss: tensor(9.3246)\n",
      "Epoch: 10607; D_loss: tensor(0.0073); G_loss: tensor(10.6990)\n",
      "Epoch: 10608; D_loss: tensor(0.0066); G_loss: tensor(9.7939)\n",
      "Epoch: 10609; D_loss: tensor(0.0087); G_loss: tensor(7.0132)\n",
      "Epoch: 10610; D_loss: tensor(0.0069); G_loss: tensor(9.0048)\n",
      "Epoch: 10611; D_loss: tensor(0.0349); G_loss: tensor(7.1222)\n",
      "Epoch: 10612; D_loss: tensor(0.0092); G_loss: tensor(11.1444)\n",
      "Epoch: 10613; D_loss: tensor(0.0142); G_loss: tensor(7.5910)\n",
      "Epoch: 10614; D_loss: tensor(0.0529); G_loss: tensor(9.7015)\n",
      "Epoch: 10615; D_loss: tensor(0.0209); G_loss: tensor(10.0298)\n",
      "Epoch: 10616; D_loss: tensor(0.0111); G_loss: tensor(8.2852)\n",
      "Epoch: 10617; D_loss: tensor(0.0402); G_loss: tensor(7.8056)\n",
      "Epoch: 10618; D_loss: tensor(0.0838); G_loss: tensor(7.5269)\n",
      "Epoch: 10619; D_loss: tensor(0.0499); G_loss: tensor(9.4146)\n",
      "Epoch: 10620; D_loss: tensor(0.0187); G_loss: tensor(6.2715)\n",
      "Epoch: 10621; D_loss: tensor(0.0348); G_loss: tensor(7.0898)\n",
      "Epoch: 10622; D_loss: tensor(0.0355); G_loss: tensor(6.3083)\n",
      "Epoch: 10623; D_loss: tensor(0.0122); G_loss: tensor(9.4153)\n",
      "Epoch: 10624; D_loss: tensor(0.0105); G_loss: tensor(9.1848)\n",
      "Epoch: 10625; D_loss: tensor(0.0122); G_loss: tensor(8.9846)\n",
      "Epoch: 10626; D_loss: tensor(0.0349); G_loss: tensor(5.7334)\n",
      "Epoch: 10627; D_loss: tensor(0.0117); G_loss: tensor(8.9851)\n",
      "Epoch: 10628; D_loss: tensor(0.0062); G_loss: tensor(12.0521)\n",
      "Epoch: 10629; D_loss: tensor(0.0067); G_loss: tensor(12.9757)\n",
      "Epoch: 10630; D_loss: tensor(0.0147); G_loss: tensor(12.5457)\n",
      "Epoch: 10631; D_loss: tensor(0.0050); G_loss: tensor(11.1326)\n",
      "Epoch: 10632; D_loss: tensor(0.0097); G_loss: tensor(6.1350)\n",
      "Epoch: 10633; D_loss: tensor(0.0174); G_loss: tensor(7.5438)\n",
      "Epoch: 10634; D_loss: tensor(0.0088); G_loss: tensor(8.7812)\n",
      "Epoch: 10635; D_loss: tensor(0.0085); G_loss: tensor(9.6917)\n",
      "Epoch: 10636; D_loss: tensor(0.0451); G_loss: tensor(9.2836)\n",
      "Epoch: 10637; D_loss: tensor(0.0114); G_loss: tensor(5.4822)\n",
      "Epoch: 10638; D_loss: tensor(0.0082); G_loss: tensor(7.3040)\n",
      "Epoch: 10639; D_loss: tensor(0.0481); G_loss: tensor(11.1561)\n",
      "Epoch: 10640; D_loss: tensor(0.0031); G_loss: tensor(7.0285)\n",
      "Epoch: 10641; D_loss: tensor(0.0571); G_loss: tensor(6.6312)\n",
      "Epoch: 10642; D_loss: tensor(0.0872); G_loss: tensor(5.4278)\n",
      "Epoch: 10643; D_loss: tensor(0.0112); G_loss: tensor(9.5694)\n",
      "Epoch: 10644; D_loss: tensor(0.0134); G_loss: tensor(12.2991)\n",
      "Epoch: 10645; D_loss: tensor(0.0024); G_loss: tensor(9.7779)\n",
      "Epoch: 10646; D_loss: tensor(0.0097); G_loss: tensor(8.1626)\n",
      "Epoch: 10647; D_loss: tensor(0.0338); G_loss: tensor(6.3025)\n",
      "Epoch: 10648; D_loss: tensor(0.0026); G_loss: tensor(8.9122)\n",
      "Epoch: 10649; D_loss: tensor(0.0106); G_loss: tensor(9.0579)\n",
      "Epoch: 10650; D_loss: tensor(0.0073); G_loss: tensor(10.1069)\n",
      "Epoch: 10651; D_loss: tensor(0.1806); G_loss: tensor(8.0338)\n",
      "Epoch: 10652; D_loss: tensor(0.1218); G_loss: tensor(13.6617)\n",
      "Epoch: 10653; D_loss: tensor(0.0609); G_loss: tensor(11.3939)\n",
      "Epoch: 10654; D_loss: tensor(0.1114); G_loss: tensor(4.5145)\n",
      "Epoch: 10655; D_loss: tensor(0.0971); G_loss: tensor(7.7214)\n",
      "Epoch: 10656; D_loss: tensor(0.0330); G_loss: tensor(10.5886)\n",
      "Epoch: 10657; D_loss: tensor(0.0212); G_loss: tensor(4.2785)\n",
      "Epoch: 10658; D_loss: tensor(0.1025); G_loss: tensor(6.8063)\n",
      "Epoch: 10659; D_loss: tensor(0.1112); G_loss: tensor(11.0516)\n",
      "Epoch: 10660; D_loss: tensor(0.0211); G_loss: tensor(12.3618)\n",
      "Epoch: 10661; D_loss: tensor(0.1325); G_loss: tensor(9.9947)\n",
      "Epoch: 10662; D_loss: tensor(0.1115); G_loss: tensor(8.1545)\n",
      "Epoch: 10663; D_loss: tensor(0.0208); G_loss: tensor(12.3519)\n",
      "Epoch: 10664; D_loss: tensor(0.1054); G_loss: tensor(12.3836)\n",
      "Epoch: 10665; D_loss: tensor(0.0121); G_loss: tensor(10.1230)\n",
      "Epoch: 10666; D_loss: tensor(0.0164); G_loss: tensor(15.2802)\n",
      "Epoch: 10667; D_loss: tensor(0.3928); G_loss: tensor(15.6576)\n",
      "Epoch: 10668; D_loss: tensor(0.2629); G_loss: tensor(7.6970)\n",
      "Epoch: 10669; D_loss: tensor(0.0410); G_loss: tensor(12.1069)\n",
      "Epoch: 10670; D_loss: tensor(0.0074); G_loss: tensor(10.1338)\n",
      "Epoch: 10671; D_loss: tensor(0.0150); G_loss: tensor(6.8206)\n",
      "Epoch: 10672; D_loss: tensor(0.0188); G_loss: tensor(7.5407)\n",
      "Epoch: 10673; D_loss: tensor(0.1816); G_loss: tensor(10.3370)\n",
      "Epoch: 10674; D_loss: tensor(0.0067); G_loss: tensor(6.7294)\n",
      "Epoch: 10675; D_loss: tensor(0.0184); G_loss: tensor(9.3343)\n",
      "Epoch: 10676; D_loss: tensor(0.0357); G_loss: tensor(8.9266)\n",
      "Epoch: 10677; D_loss: tensor(0.0036); G_loss: tensor(8.4162)\n",
      "Epoch: 10678; D_loss: tensor(0.0032); G_loss: tensor(13.3238)\n",
      "Epoch: 10679; D_loss: tensor(0.0018); G_loss: tensor(10.9829)\n",
      "Epoch: 10680; D_loss: tensor(0.1255); G_loss: tensor(12.8113)\n",
      "Epoch: 10681; D_loss: tensor(0.0050); G_loss: tensor(8.8453)\n",
      "Epoch: 10682; D_loss: tensor(0.0228); G_loss: tensor(9.3340)\n",
      "Epoch: 10683; D_loss: tensor(0.0035); G_loss: tensor(8.1742)\n",
      "Epoch: 10684; D_loss: tensor(0.0056); G_loss: tensor(9.8139)\n",
      "Epoch: 10685; D_loss: tensor(0.0032); G_loss: tensor(14.4534)\n",
      "Epoch: 10686; D_loss: tensor(0.0050); G_loss: tensor(10.6688)\n",
      "Epoch: 10687; D_loss: tensor(0.0054); G_loss: tensor(11.4503)\n",
      "Epoch: 10688; D_loss: tensor(0.0056); G_loss: tensor(10.0712)\n",
      "Epoch: 10689; D_loss: tensor(0.0139); G_loss: tensor(8.2558)\n",
      "Epoch: 10690; D_loss: tensor(0.0264); G_loss: tensor(9.4033)\n",
      "Epoch: 10691; D_loss: tensor(0.0100); G_loss: tensor(7.3586)\n",
      "Epoch: 10692; D_loss: tensor(0.0129); G_loss: tensor(9.7226)\n",
      "Epoch: 10693; D_loss: tensor(0.0161); G_loss: tensor(7.7405)\n",
      "Epoch: 10694; D_loss: tensor(0.0242); G_loss: tensor(8.5395)\n",
      "Epoch: 10695; D_loss: tensor(0.8484); G_loss: tensor(6.0817)\n",
      "Epoch: 10696; D_loss: tensor(0.0052); G_loss: tensor(21.5520)\n",
      "Epoch: 10697; D_loss: tensor(0.0016); G_loss: tensor(15.7665)\n",
      "Epoch: 10698; D_loss: tensor(0.0463); G_loss: tensor(5.4387)\n",
      "Epoch: 10699; D_loss: tensor(0.0056); G_loss: tensor(12.9544)\n",
      "Epoch: 10700; D_loss: tensor(0.0010); G_loss: tensor(20.3290)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10701; D_loss: tensor(0.0522); G_loss: tensor(21.7317)\n",
      "Epoch: 10702; D_loss: tensor(0.0386); G_loss: tensor(16.7765)\n",
      "Epoch: 10703; D_loss: tensor(0.1261); G_loss: tensor(6.4785)\n",
      "Epoch: 10704; D_loss: tensor(0.1918); G_loss: tensor(11.5018)\n",
      "Epoch: 10705; D_loss: tensor(0.0012); G_loss: tensor(15.6453)\n",
      "Epoch: 10706; D_loss: tensor(0.0028); G_loss: tensor(9.1943)\n",
      "Epoch: 10707; D_loss: tensor(0.1209); G_loss: tensor(4.8773)\n",
      "Epoch: 10708; D_loss: tensor(0.0166); G_loss: tensor(16.6685)\n",
      "Epoch: 10709; D_loss: tensor(0.6695); G_loss: tensor(11.2186)\n",
      "Epoch: 10710; D_loss: tensor(0.3231); G_loss: tensor(4.7456)\n",
      "Epoch: 10711; D_loss: tensor(0.0337); G_loss: tensor(12.4892)\n",
      "Epoch: 10712; D_loss: tensor(0.4515); G_loss: tensor(15.4448)\n",
      "Epoch: 10713; D_loss: tensor(0.0283); G_loss: tensor(5.2525)\n",
      "Epoch: 10714; D_loss: tensor(0.8191); G_loss: tensor(5.1284)\n",
      "Epoch: 10715; D_loss: tensor(0.0237); G_loss: tensor(17.5070)\n",
      "Epoch: 10716; D_loss: tensor(0.0029); G_loss: tensor(17.2558)\n",
      "Epoch: 10717; D_loss: tensor(0.0214); G_loss: tensor(5.7985)\n",
      "Epoch: 10718; D_loss: tensor(0.0894); G_loss: tensor(8.1339)\n",
      "Epoch: 10719; D_loss: tensor(0.0178); G_loss: tensor(10.7577)\n",
      "Epoch: 10720; D_loss: tensor(0.0003); G_loss: tensor(16.9895)\n",
      "Epoch: 10721; D_loss: tensor(0.0215); G_loss: tensor(16.4319)\n",
      "Epoch: 10722; D_loss: tensor(0.0455); G_loss: tensor(13.4428)\n",
      "Epoch: 10723; D_loss: tensor(0.0066); G_loss: tensor(14.9461)\n",
      "Epoch: 10724; D_loss: tensor(0.0049); G_loss: tensor(12.8245)\n",
      "Epoch: 10725; D_loss: tensor(0.0101); G_loss: tensor(10.2288)\n",
      "Epoch: 10726; D_loss: tensor(0.0513); G_loss: tensor(8.2773)\n",
      "Epoch: 10727; D_loss: tensor(0.0285); G_loss: tensor(10.9574)\n",
      "Epoch: 10728; D_loss: tensor(0.0948); G_loss: tensor(10.3380)\n",
      "Epoch: 10729; D_loss: tensor(0.0383); G_loss: tensor(9.4390)\n",
      "Epoch: 10730; D_loss: tensor(0.0266); G_loss: tensor(5.0340)\n",
      "Epoch: 10731; D_loss: tensor(0.0402); G_loss: tensor(7.0097)\n",
      "Epoch: 10732; D_loss: tensor(0.0030); G_loss: tensor(8.3974)\n",
      "Epoch: 10733; D_loss: tensor(0.0574); G_loss: tensor(6.6215)\n",
      "Epoch: 10734; D_loss: tensor(0.1107); G_loss: tensor(9.6540)\n",
      "Epoch: 10735; D_loss: tensor(0.0496); G_loss: tensor(10.4632)\n",
      "Epoch: 10736; D_loss: tensor(0.0094); G_loss: tensor(7.2798)\n",
      "Epoch: 10737; D_loss: tensor(0.0098); G_loss: tensor(10.8351)\n",
      "Epoch: 10738; D_loss: tensor(0.0066); G_loss: tensor(13.2102)\n",
      "Epoch: 10739; D_loss: tensor(0.0006); G_loss: tensor(17.8536)\n",
      "Epoch: 10740; D_loss: tensor(0.0188); G_loss: tensor(16.8092)\n",
      "Epoch: 10741; D_loss: tensor(0.0011); G_loss: tensor(12.6618)\n",
      "Epoch: 10742; D_loss: tensor(0.0002); G_loss: tensor(15.9949)\n",
      "Epoch: 10743; D_loss: tensor(0.0029); G_loss: tensor(12.6401)\n",
      "Epoch: 10744; D_loss: tensor(0.0009); G_loss: tensor(15.5408)\n",
      "Epoch: 10745; D_loss: tensor(0.0040); G_loss: tensor(10.6481)\n",
      "Epoch: 10746; D_loss: tensor(0.0184); G_loss: tensor(12.5976)\n",
      "Epoch: 10747; D_loss: tensor(0.0436); G_loss: tensor(12.5292)\n",
      "Epoch: 10748; D_loss: tensor(0.0566); G_loss: tensor(7.7162)\n",
      "Epoch: 10749; D_loss: tensor(0.0376); G_loss: tensor(6.2826)\n",
      "Epoch: 10750; D_loss: tensor(0.0182); G_loss: tensor(8.5058)\n",
      "Epoch: 10751; D_loss: tensor(0.0083); G_loss: tensor(8.7638)\n",
      "Epoch: 10752; D_loss: tensor(0.0074); G_loss: tensor(12.1210)\n",
      "Epoch: 10753; D_loss: tensor(0.0227); G_loss: tensor(13.1504)\n",
      "Epoch: 10754; D_loss: tensor(0.0041); G_loss: tensor(11.3098)\n",
      "Epoch: 10755; D_loss: tensor(0.0166); G_loss: tensor(11.5587)\n",
      "Epoch: 10756; D_loss: tensor(0.0015); G_loss: tensor(10.2678)\n",
      "Epoch: 10757; D_loss: tensor(0.0051); G_loss: tensor(10.7499)\n",
      "Epoch: 10758; D_loss: tensor(0.0059); G_loss: tensor(10.5157)\n",
      "Epoch: 10759; D_loss: tensor(0.0098); G_loss: tensor(10.6302)\n",
      "Epoch: 10760; D_loss: tensor(0.0384); G_loss: tensor(11.2376)\n",
      "Epoch: 10761; D_loss: tensor(0.0181); G_loss: tensor(10.3472)\n",
      "Epoch: 10762; D_loss: tensor(0.0090); G_loss: tensor(9.3707)\n",
      "Epoch: 10763; D_loss: tensor(0.0067); G_loss: tensor(10.9830)\n",
      "Epoch: 10764; D_loss: tensor(0.0058); G_loss: tensor(9.8548)\n",
      "Epoch: 10765; D_loss: tensor(0.0392); G_loss: tensor(9.4952)\n",
      "Epoch: 10766; D_loss: tensor(0.0111); G_loss: tensor(8.2474)\n",
      "Epoch: 10767; D_loss: tensor(0.0280); G_loss: tensor(5.1432)\n",
      "Epoch: 10768; D_loss: tensor(0.0200); G_loss: tensor(7.5323)\n",
      "Epoch: 10769; D_loss: tensor(0.0102); G_loss: tensor(5.7135)\n",
      "Epoch: 10770; D_loss: tensor(0.1428); G_loss: tensor(6.7531)\n",
      "Epoch: 10771; D_loss: tensor(0.0070); G_loss: tensor(13.4707)\n",
      "Epoch: 10772; D_loss: tensor(0.0200); G_loss: tensor(9.8872)\n",
      "Epoch: 10773; D_loss: tensor(0.0108); G_loss: tensor(10.0190)\n",
      "Epoch: 10774; D_loss: tensor(0.0037); G_loss: tensor(8.4290)\n",
      "Epoch: 10775; D_loss: tensor(0.0183); G_loss: tensor(7.2573)\n",
      "Epoch: 10776; D_loss: tensor(0.0269); G_loss: tensor(9.1018)\n",
      "Epoch: 10777; D_loss: tensor(0.0747); G_loss: tensor(8.7878)\n",
      "Epoch: 10778; D_loss: tensor(0.0098); G_loss: tensor(8.5039)\n",
      "Epoch: 10779; D_loss: tensor(0.0257); G_loss: tensor(9.5232)\n",
      "Epoch: 10780; D_loss: tensor(0.0177); G_loss: tensor(5.5211)\n",
      "Epoch: 10781; D_loss: tensor(0.0291); G_loss: tensor(9.5609)\n",
      "Epoch: 10782; D_loss: tensor(0.0142); G_loss: tensor(11.1702)\n",
      "Epoch: 10783; D_loss: tensor(0.0098); G_loss: tensor(7.9262)\n",
      "Epoch: 10784; D_loss: tensor(0.1956); G_loss: tensor(4.9490)\n",
      "Epoch: 10785; D_loss: tensor(0.0161); G_loss: tensor(6.6310)\n",
      "Epoch: 10786; D_loss: tensor(0.1278); G_loss: tensor(8.1488)\n",
      "Epoch: 10787; D_loss: tensor(0.0132); G_loss: tensor(5.3255)\n",
      "Epoch: 10788; D_loss: tensor(0.2583); G_loss: tensor(10.3377)\n",
      "Epoch: 10789; D_loss: tensor(0.0075); G_loss: tensor(13.0245)\n",
      "Epoch: 10790; D_loss: tensor(0.0060); G_loss: tensor(9.0467)\n",
      "Epoch: 10791; D_loss: tensor(0.0938); G_loss: tensor(4.9028)\n",
      "Epoch: 10792; D_loss: tensor(0.0039); G_loss: tensor(8.8226)\n",
      "Epoch: 10793; D_loss: tensor(0.0920); G_loss: tensor(10.9090)\n",
      "Epoch: 10794; D_loss: tensor(0.0057); G_loss: tensor(11.9627)\n",
      "Epoch: 10795; D_loss: tensor(0.0054); G_loss: tensor(10.2969)\n",
      "Epoch: 10796; D_loss: tensor(0.0051); G_loss: tensor(8.4691)\n",
      "Epoch: 10797; D_loss: tensor(0.0072); G_loss: tensor(8.6661)\n",
      "Epoch: 10798; D_loss: tensor(0.0103); G_loss: tensor(7.5474)\n",
      "Epoch: 10799; D_loss: tensor(0.0052); G_loss: tensor(10.0262)\n",
      "Epoch: 10800; D_loss: tensor(0.0121); G_loss: tensor(8.1626)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10801; D_loss: tensor(0.0027); G_loss: tensor(8.1164)\n",
      "Epoch: 10802; D_loss: tensor(0.0225); G_loss: tensor(7.7190)\n",
      "Epoch: 10803; D_loss: tensor(0.0407); G_loss: tensor(7.6140)\n",
      "Epoch: 10804; D_loss: tensor(0.0397); G_loss: tensor(6.5622)\n",
      "Epoch: 10805; D_loss: tensor(0.0504); G_loss: tensor(6.8095)\n",
      "Epoch: 10806; D_loss: tensor(0.0426); G_loss: tensor(9.5072)\n",
      "Epoch: 10807; D_loss: tensor(0.0376); G_loss: tensor(8.1950)\n",
      "Epoch: 10808; D_loss: tensor(0.0182); G_loss: tensor(10.5997)\n",
      "Epoch: 10809; D_loss: tensor(0.0482); G_loss: tensor(8.1196)\n",
      "Epoch: 10810; D_loss: tensor(0.0287); G_loss: tensor(6.6773)\n",
      "Epoch: 10811; D_loss: tensor(0.0125); G_loss: tensor(6.7735)\n",
      "Epoch: 10812; D_loss: tensor(0.0062); G_loss: tensor(8.7215)\n",
      "Epoch: 10813; D_loss: tensor(0.0021); G_loss: tensor(10.9696)\n",
      "Epoch: 10814; D_loss: tensor(0.0071); G_loss: tensor(10.1624)\n",
      "Epoch: 10815; D_loss: tensor(0.0083); G_loss: tensor(10.5195)\n",
      "Epoch: 10816; D_loss: tensor(0.0125); G_loss: tensor(9.6337)\n",
      "Epoch: 10817; D_loss: tensor(0.0307); G_loss: tensor(8.5865)\n",
      "Epoch: 10818; D_loss: tensor(0.0046); G_loss: tensor(6.8099)\n",
      "Epoch: 10819; D_loss: tensor(0.0396); G_loss: tensor(8.5279)\n",
      "Epoch: 10820; D_loss: tensor(0.0087); G_loss: tensor(7.5770)\n",
      "Epoch: 10821; D_loss: tensor(0.0310); G_loss: tensor(6.7990)\n",
      "Epoch: 10822; D_loss: tensor(0.0691); G_loss: tensor(7.5851)\n",
      "Epoch: 10823; D_loss: tensor(0.0580); G_loss: tensor(7.7425)\n",
      "Epoch: 10824; D_loss: tensor(0.0156); G_loss: tensor(11.4762)\n",
      "Epoch: 10825; D_loss: tensor(0.0139); G_loss: tensor(10.2041)\n",
      "Epoch: 10826; D_loss: tensor(0.0295); G_loss: tensor(9.5835)\n",
      "Epoch: 10827; D_loss: tensor(0.0052); G_loss: tensor(8.6233)\n",
      "Epoch: 10828; D_loss: tensor(0.0108); G_loss: tensor(7.9514)\n",
      "Epoch: 10829; D_loss: tensor(0.0184); G_loss: tensor(11.6246)\n",
      "Epoch: 10830; D_loss: tensor(0.0152); G_loss: tensor(10.8291)\n",
      "Epoch: 10831; D_loss: tensor(0.3927); G_loss: tensor(5.9121)\n",
      "Epoch: 10832; D_loss: tensor(0.0832); G_loss: tensor(6.2840)\n",
      "Epoch: 10833; D_loss: tensor(0.0743); G_loss: tensor(9.0066)\n",
      "Epoch: 10834; D_loss: tensor(0.0055); G_loss: tensor(12.3225)\n",
      "Epoch: 10835; D_loss: tensor(0.0502); G_loss: tensor(5.5867)\n",
      "Epoch: 10836; D_loss: tensor(0.0029); G_loss: tensor(11.8211)\n",
      "Epoch: 10837; D_loss: tensor(0.0399); G_loss: tensor(14.5800)\n",
      "Epoch: 10838; D_loss: tensor(0.0169); G_loss: tensor(9.0924)\n",
      "Epoch: 10839; D_loss: tensor(0.0060); G_loss: tensor(7.0943)\n",
      "Epoch: 10840; D_loss: tensor(0.0301); G_loss: tensor(7.7799)\n",
      "Epoch: 10841; D_loss: tensor(0.0038); G_loss: tensor(8.9950)\n",
      "Epoch: 10842; D_loss: tensor(0.0043); G_loss: tensor(10.2435)\n",
      "Epoch: 10843; D_loss: tensor(0.0215); G_loss: tensor(12.1995)\n",
      "Epoch: 10844; D_loss: tensor(0.0478); G_loss: tensor(11.3066)\n",
      "Epoch: 10845; D_loss: tensor(0.0099); G_loss: tensor(8.9772)\n",
      "Epoch: 10846; D_loss: tensor(0.0023); G_loss: tensor(8.2522)\n",
      "Epoch: 10847; D_loss: tensor(0.0067); G_loss: tensor(9.5021)\n",
      "Epoch: 10848; D_loss: tensor(0.0172); G_loss: tensor(8.3665)\n",
      "Epoch: 10849; D_loss: tensor(0.0359); G_loss: tensor(9.9356)\n",
      "Epoch: 10850; D_loss: tensor(0.0226); G_loss: tensor(7.3020)\n",
      "Epoch: 10851; D_loss: tensor(0.0072); G_loss: tensor(9.1790)\n",
      "Epoch: 10852; D_loss: tensor(0.0069); G_loss: tensor(9.1920)\n",
      "Epoch: 10853; D_loss: tensor(0.0734); G_loss: tensor(8.4765)\n",
      "Epoch: 10854; D_loss: tensor(0.0122); G_loss: tensor(4.3634)\n",
      "Epoch: 10855; D_loss: tensor(0.0375); G_loss: tensor(7.6128)\n",
      "Epoch: 10856; D_loss: tensor(0.0263); G_loss: tensor(6.9130)\n",
      "Epoch: 10857; D_loss: tensor(0.0096); G_loss: tensor(6.7871)\n",
      "Epoch: 10858; D_loss: tensor(0.0101); G_loss: tensor(7.4708)\n",
      "Epoch: 10859; D_loss: tensor(0.0139); G_loss: tensor(9.1420)\n",
      "Epoch: 10860; D_loss: tensor(0.0082); G_loss: tensor(10.0501)\n",
      "Epoch: 10861; D_loss: tensor(0.0255); G_loss: tensor(7.8687)\n",
      "Epoch: 10862; D_loss: tensor(0.0084); G_loss: tensor(8.0237)\n",
      "Epoch: 10863; D_loss: tensor(0.1197); G_loss: tensor(12.6851)\n",
      "Epoch: 10864; D_loss: tensor(0.0028); G_loss: tensor(11.4669)\n",
      "Epoch: 10865; D_loss: tensor(0.0041); G_loss: tensor(9.9304)\n",
      "Epoch: 10866; D_loss: tensor(0.0051); G_loss: tensor(8.9698)\n",
      "Epoch: 10867; D_loss: tensor(0.0074); G_loss: tensor(10.1037)\n",
      "Epoch: 10868; D_loss: tensor(0.0149); G_loss: tensor(8.6626)\n",
      "Epoch: 10869; D_loss: tensor(0.0015); G_loss: tensor(9.5636)\n",
      "Epoch: 10870; D_loss: tensor(0.0028); G_loss: tensor(9.5402)\n",
      "Epoch: 10871; D_loss: tensor(0.0060); G_loss: tensor(7.7900)\n",
      "Epoch: 10872; D_loss: tensor(0.4463); G_loss: tensor(11.6350)\n",
      "Epoch: 10873; D_loss: tensor(0.3082); G_loss: tensor(8.6735)\n",
      "Epoch: 10874; D_loss: tensor(0.0333); G_loss: tensor(3.8173)\n",
      "Epoch: 10875; D_loss: tensor(0.0413); G_loss: tensor(7.9848)\n",
      "Epoch: 10876; D_loss: tensor(0.0052); G_loss: tensor(12.0509)\n",
      "Epoch: 10877; D_loss: tensor(0.0248); G_loss: tensor(12.9199)\n",
      "Epoch: 10878; D_loss: tensor(0.0231); G_loss: tensor(6.0302)\n",
      "Epoch: 10879; D_loss: tensor(0.1263); G_loss: tensor(6.6615)\n",
      "Epoch: 10880; D_loss: tensor(0.0119); G_loss: tensor(11.1375)\n",
      "Epoch: 10881; D_loss: tensor(0.0031); G_loss: tensor(11.2517)\n",
      "Epoch: 10882; D_loss: tensor(0.0014); G_loss: tensor(7.4871)\n",
      "Epoch: 10883; D_loss: tensor(0.0050); G_loss: tensor(7.0599)\n",
      "Epoch: 10884; D_loss: tensor(0.0135); G_loss: tensor(8.8906)\n",
      "Epoch: 10885; D_loss: tensor(0.0026); G_loss: tensor(9.8147)\n",
      "Epoch: 10886; D_loss: tensor(0.0147); G_loss: tensor(12.5854)\n",
      "Epoch: 10887; D_loss: tensor(0.0006); G_loss: tensor(10.9829)\n",
      "Epoch: 10888; D_loss: tensor(0.0040); G_loss: tensor(9.9935)\n",
      "Epoch: 10889; D_loss: tensor(0.0195); G_loss: tensor(8.2100)\n",
      "Epoch: 10890; D_loss: tensor(0.0050); G_loss: tensor(9.4908)\n",
      "Epoch: 10891; D_loss: tensor(0.0060); G_loss: tensor(7.0606)\n",
      "Epoch: 10892; D_loss: tensor(0.0318); G_loss: tensor(9.5397)\n",
      "Epoch: 10893; D_loss: tensor(0.0179); G_loss: tensor(8.4502)\n",
      "Epoch: 10894; D_loss: tensor(0.0142); G_loss: tensor(7.3707)\n",
      "Epoch: 10895; D_loss: tensor(0.2595); G_loss: tensor(7.3251)\n",
      "Epoch: 10896; D_loss: tensor(0.0074); G_loss: tensor(13.1828)\n",
      "Epoch: 10897; D_loss: tensor(1.4418); G_loss: tensor(3.2939)\n",
      "Epoch: 10898; D_loss: tensor(0.4905); G_loss: tensor(17.4600)\n",
      "Epoch: 10899; D_loss: tensor(0.2568); G_loss: tensor(11.8479)\n",
      "Epoch: 10900; D_loss: tensor(0.1020); G_loss: tensor(3.6642)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10901; D_loss: tensor(0.0035); G_loss: tensor(17.9520)\n",
      "Epoch: 10902; D_loss: tensor(0.2264); G_loss: tensor(15.9379)\n",
      "Epoch: 10903; D_loss: tensor(0.2897); G_loss: tensor(6.4304)\n",
      "Epoch: 10904; D_loss: tensor(0.0078); G_loss: tensor(12.9326)\n",
      "Epoch: 10905; D_loss: tensor(0.0347); G_loss: tensor(18.6486)\n",
      "Epoch: 10906; D_loss: tensor(0.0664); G_loss: tensor(12.9965)\n",
      "Epoch: 10907; D_loss: tensor(0.0154); G_loss: tensor(6.7724)\n",
      "Epoch: 10908; D_loss: tensor(0.0813); G_loss: tensor(7.6654)\n",
      "Epoch: 10909; D_loss: tensor(0.0149); G_loss: tensor(13.2350)\n",
      "Epoch: 10910; D_loss: tensor(0.2061); G_loss: tensor(13.3537)\n",
      "Epoch: 10911; D_loss: tensor(0.0183); G_loss: tensor(8.2126)\n",
      "Epoch: 10912; D_loss: tensor(0.0103); G_loss: tensor(6.8127)\n",
      "Epoch: 10913; D_loss: tensor(0.0078); G_loss: tensor(8.3074)\n",
      "Epoch: 10914; D_loss: tensor(0.0034); G_loss: tensor(8.9636)\n",
      "Epoch: 10915; D_loss: tensor(0.0030); G_loss: tensor(9.5447)\n",
      "Epoch: 10916; D_loss: tensor(0.0187); G_loss: tensor(11.3444)\n",
      "Epoch: 10917; D_loss: tensor(0.0076); G_loss: tensor(8.9889)\n",
      "Epoch: 10918; D_loss: tensor(0.0499); G_loss: tensor(8.4095)\n",
      "Epoch: 10919; D_loss: tensor(0.0076); G_loss: tensor(8.5106)\n",
      "Epoch: 10920; D_loss: tensor(0.0233); G_loss: tensor(7.8662)\n",
      "Epoch: 10921; D_loss: tensor(0.0120); G_loss: tensor(9.2627)\n",
      "Epoch: 10922; D_loss: tensor(0.0015); G_loss: tensor(9.9330)\n",
      "Epoch: 10923; D_loss: tensor(0.0017); G_loss: tensor(7.5410)\n",
      "Epoch: 10924; D_loss: tensor(0.0016); G_loss: tensor(9.1852)\n",
      "Epoch: 10925; D_loss: tensor(0.0102); G_loss: tensor(9.3378)\n",
      "Epoch: 10926; D_loss: tensor(0.0082); G_loss: tensor(9.6086)\n",
      "Epoch: 10927; D_loss: tensor(0.0093); G_loss: tensor(6.9850)\n",
      "Epoch: 10928; D_loss: tensor(0.0287); G_loss: tensor(10.2137)\n",
      "Epoch: 10929; D_loss: tensor(0.0103); G_loss: tensor(9.8038)\n",
      "Epoch: 10930; D_loss: tensor(0.0107); G_loss: tensor(8.3034)\n",
      "Epoch: 10931; D_loss: tensor(0.0245); G_loss: tensor(7.2860)\n",
      "Epoch: 10932; D_loss: tensor(0.0039); G_loss: tensor(11.0554)\n",
      "Epoch: 10933; D_loss: tensor(0.0869); G_loss: tensor(7.0584)\n",
      "Epoch: 10934; D_loss: tensor(0.0152); G_loss: tensor(9.6343)\n",
      "Epoch: 10935; D_loss: tensor(0.0173); G_loss: tensor(5.1640)\n",
      "Epoch: 10936; D_loss: tensor(0.0156); G_loss: tensor(8.1304)\n",
      "Epoch: 10937; D_loss: tensor(0.0904); G_loss: tensor(10.5996)\n",
      "Epoch: 10938; D_loss: tensor(0.0106); G_loss: tensor(10.0832)\n",
      "Epoch: 10939; D_loss: tensor(0.0255); G_loss: tensor(6.1065)\n",
      "Epoch: 10940; D_loss: tensor(0.0313); G_loss: tensor(9.3497)\n",
      "Epoch: 10941; D_loss: tensor(0.0155); G_loss: tensor(7.1718)\n",
      "Epoch: 10942; D_loss: tensor(0.0393); G_loss: tensor(9.2499)\n",
      "Epoch: 10943; D_loss: tensor(0.0313); G_loss: tensor(8.2586)\n",
      "Epoch: 10944; D_loss: tensor(0.0071); G_loss: tensor(8.3795)\n",
      "Epoch: 10945; D_loss: tensor(0.0432); G_loss: tensor(9.5422)\n",
      "Epoch: 10946; D_loss: tensor(0.0196); G_loss: tensor(8.3755)\n",
      "Epoch: 10947; D_loss: tensor(0.0088); G_loss: tensor(8.0587)\n",
      "Epoch: 10948; D_loss: tensor(0.0030); G_loss: tensor(9.6889)\n",
      "Epoch: 10949; D_loss: tensor(0.0073); G_loss: tensor(9.7308)\n",
      "Epoch: 10950; D_loss: tensor(0.0183); G_loss: tensor(5.8126)\n",
      "Epoch: 10951; D_loss: tensor(0.0079); G_loss: tensor(7.5378)\n",
      "Epoch: 10952; D_loss: tensor(0.0061); G_loss: tensor(8.9808)\n",
      "Epoch: 10953; D_loss: tensor(0.0081); G_loss: tensor(10.1191)\n",
      "Epoch: 10954; D_loss: tensor(0.0474); G_loss: tensor(8.8477)\n",
      "Epoch: 10955; D_loss: tensor(0.0291); G_loss: tensor(5.7604)\n",
      "Epoch: 10956; D_loss: tensor(0.0125); G_loss: tensor(7.6921)\n",
      "Epoch: 10957; D_loss: tensor(0.0069); G_loss: tensor(9.2792)\n",
      "Epoch: 10958; D_loss: tensor(0.0217); G_loss: tensor(8.4216)\n",
      "Epoch: 10959; D_loss: tensor(0.0924); G_loss: tensor(9.3531)\n",
      "Epoch: 10960; D_loss: tensor(0.1078); G_loss: tensor(7.9629)\n",
      "Epoch: 10961; D_loss: tensor(0.0108); G_loss: tensor(10.0467)\n",
      "Epoch: 10962; D_loss: tensor(0.0275); G_loss: tensor(9.6037)\n",
      "Epoch: 10963; D_loss: tensor(0.0375); G_loss: tensor(6.4205)\n",
      "Epoch: 10964; D_loss: tensor(0.0371); G_loss: tensor(7.7571)\n",
      "Epoch: 10965; D_loss: tensor(0.1005); G_loss: tensor(9.6512)\n",
      "Epoch: 10966; D_loss: tensor(0.0020); G_loss: tensor(10.6928)\n",
      "Epoch: 10967; D_loss: tensor(0.0009); G_loss: tensor(12.1601)\n",
      "Epoch: 10968; D_loss: tensor(0.0104); G_loss: tensor(9.4116)\n",
      "Epoch: 10969; D_loss: tensor(0.0042); G_loss: tensor(8.1108)\n",
      "Epoch: 10970; D_loss: tensor(0.0129); G_loss: tensor(6.9131)\n",
      "Epoch: 10971; D_loss: tensor(0.0101); G_loss: tensor(7.0752)\n",
      "Epoch: 10972; D_loss: tensor(0.0035); G_loss: tensor(6.5059)\n",
      "Epoch: 10973; D_loss: tensor(0.0025); G_loss: tensor(10.4017)\n",
      "Epoch: 10974; D_loss: tensor(0.0077); G_loss: tensor(9.2291)\n",
      "Epoch: 10975; D_loss: tensor(0.0223); G_loss: tensor(7.7214)\n",
      "Epoch: 10976; D_loss: tensor(0.0112); G_loss: tensor(9.7272)\n",
      "Epoch: 10977; D_loss: tensor(0.0389); G_loss: tensor(10.9815)\n",
      "Epoch: 10978; D_loss: tensor(0.0034); G_loss: tensor(7.9325)\n",
      "Epoch: 10979; D_loss: tensor(0.0309); G_loss: tensor(8.2088)\n",
      "Epoch: 10980; D_loss: tensor(0.0127); G_loss: tensor(8.9986)\n",
      "Epoch: 10981; D_loss: tensor(0.0035); G_loss: tensor(8.4344)\n",
      "Epoch: 10982; D_loss: tensor(0.0089); G_loss: tensor(7.4937)\n",
      "Epoch: 10983; D_loss: tensor(0.0261); G_loss: tensor(7.3410)\n",
      "Epoch: 10984; D_loss: tensor(0.0022); G_loss: tensor(7.1206)\n",
      "Epoch: 10985; D_loss: tensor(0.0138); G_loss: tensor(7.7438)\n",
      "Epoch: 10986; D_loss: tensor(0.3924); G_loss: tensor(5.6222)\n",
      "Epoch: 10987; D_loss: tensor(0.0150); G_loss: tensor(13.9012)\n",
      "Epoch: 10988; D_loss: tensor(0.0859); G_loss: tensor(10.6274)\n",
      "Epoch: 10989; D_loss: tensor(0.0291); G_loss: tensor(7.6667)\n",
      "Epoch: 10990; D_loss: tensor(0.0185); G_loss: tensor(11.2001)\n",
      "Epoch: 10991; D_loss: tensor(0.2912); G_loss: tensor(16.0468)\n",
      "Epoch: 10992; D_loss: tensor(0.0116); G_loss: tensor(5.4838)\n",
      "Epoch: 10993; D_loss: tensor(0.6063); G_loss: tensor(8.7812)\n",
      "Epoch: 10994; D_loss: tensor(0.0779); G_loss: tensor(3.9647)\n",
      "Epoch: 10995; D_loss: tensor(0.0102); G_loss: tensor(10.5375)\n",
      "Epoch: 10996; D_loss: tensor(0.1048); G_loss: tensor(12.7152)\n",
      "Epoch: 10997; D_loss: tensor(0.0012); G_loss: tensor(9.4381)\n",
      "Epoch: 10998; D_loss: tensor(0.0233); G_loss: tensor(5.1403)\n",
      "Epoch: 10999; D_loss: tensor(0.0351); G_loss: tensor(8.3805)\n",
      "Epoch: 11000; D_loss: tensor(0.0319); G_loss: tensor(8.7638)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11001; D_loss: tensor(0.0215); G_loss: tensor(6.9982)\n",
      "Epoch: 11002; D_loss: tensor(0.0166); G_loss: tensor(7.9600)\n",
      "Epoch: 11003; D_loss: tensor(0.0117); G_loss: tensor(6.7640)\n",
      "Epoch: 11004; D_loss: tensor(0.0035); G_loss: tensor(10.3762)\n",
      "Epoch: 11005; D_loss: tensor(0.0034); G_loss: tensor(10.8145)\n",
      "Epoch: 11006; D_loss: tensor(0.0100); G_loss: tensor(10.1440)\n",
      "Epoch: 11007; D_loss: tensor(0.0471); G_loss: tensor(10.4116)\n",
      "Epoch: 11008; D_loss: tensor(0.0370); G_loss: tensor(6.0073)\n",
      "Epoch: 11009; D_loss: tensor(0.0082); G_loss: tensor(7.5673)\n",
      "Epoch: 11010; D_loss: tensor(0.0078); G_loss: tensor(8.9019)\n",
      "Epoch: 11011; D_loss: tensor(0.0103); G_loss: tensor(11.2448)\n",
      "Epoch: 11012; D_loss: tensor(0.0079); G_loss: tensor(9.1653)\n",
      "Epoch: 11013; D_loss: tensor(0.0157); G_loss: tensor(7.3297)\n",
      "Epoch: 11014; D_loss: tensor(0.0659); G_loss: tensor(5.6403)\n",
      "Epoch: 11015; D_loss: tensor(0.0458); G_loss: tensor(8.3786)\n",
      "Epoch: 11016; D_loss: tensor(0.0320); G_loss: tensor(9.2289)\n",
      "Epoch: 11017; D_loss: tensor(0.0252); G_loss: tensor(8.3799)\n",
      "Epoch: 11018; D_loss: tensor(0.0123); G_loss: tensor(6.8228)\n",
      "Epoch: 11019; D_loss: tensor(0.0077); G_loss: tensor(7.4103)\n",
      "Epoch: 11020; D_loss: tensor(0.0271); G_loss: tensor(9.2045)\n",
      "Epoch: 11021; D_loss: tensor(0.0145); G_loss: tensor(6.8814)\n",
      "Epoch: 11022; D_loss: tensor(0.0165); G_loss: tensor(7.5119)\n",
      "Epoch: 11023; D_loss: tensor(0.0062); G_loss: tensor(8.1683)\n",
      "Epoch: 11024; D_loss: tensor(0.0027); G_loss: tensor(9.2126)\n",
      "Epoch: 11025; D_loss: tensor(0.0197); G_loss: tensor(9.8650)\n",
      "Epoch: 11026; D_loss: tensor(0.0053); G_loss: tensor(10.5289)\n",
      "Epoch: 11027; D_loss: tensor(0.0087); G_loss: tensor(9.0254)\n",
      "Epoch: 11028; D_loss: tensor(0.0134); G_loss: tensor(8.6969)\n",
      "Epoch: 11029; D_loss: tensor(0.0212); G_loss: tensor(8.7824)\n",
      "Epoch: 11030; D_loss: tensor(0.0370); G_loss: tensor(6.3952)\n",
      "Epoch: 11031; D_loss: tensor(0.0254); G_loss: tensor(5.8237)\n",
      "Epoch: 11032; D_loss: tensor(0.0030); G_loss: tensor(9.5018)\n",
      "Epoch: 11033; D_loss: tensor(0.1612); G_loss: tensor(7.8290)\n",
      "Epoch: 11034; D_loss: tensor(0.1447); G_loss: tensor(6.3533)\n",
      "Epoch: 11035; D_loss: tensor(0.0211); G_loss: tensor(8.9103)\n",
      "Epoch: 11036; D_loss: tensor(0.0694); G_loss: tensor(5.8734)\n",
      "Epoch: 11037; D_loss: tensor(0.0078); G_loss: tensor(6.4926)\n",
      "Epoch: 11038; D_loss: tensor(0.0490); G_loss: tensor(8.7231)\n",
      "Epoch: 11039; D_loss: tensor(0.0197); G_loss: tensor(13.3650)\n",
      "Epoch: 11040; D_loss: tensor(0.0125); G_loss: tensor(8.5954)\n",
      "Epoch: 11041; D_loss: tensor(0.0421); G_loss: tensor(8.7207)\n",
      "Epoch: 11042; D_loss: tensor(0.0094); G_loss: tensor(7.8557)\n",
      "Epoch: 11043; D_loss: tensor(0.0509); G_loss: tensor(7.9948)\n",
      "Epoch: 11044; D_loss: tensor(0.0022); G_loss: tensor(11.0186)\n",
      "Epoch: 11045; D_loss: tensor(0.0023); G_loss: tensor(8.6638)\n",
      "Epoch: 11046; D_loss: tensor(0.0362); G_loss: tensor(9.6127)\n",
      "Epoch: 11047; D_loss: tensor(0.0115); G_loss: tensor(9.0141)\n",
      "Epoch: 11048; D_loss: tensor(0.0078); G_loss: tensor(8.3534)\n",
      "Epoch: 11049; D_loss: tensor(0.0143); G_loss: tensor(8.5421)\n",
      "Epoch: 11050; D_loss: tensor(0.0049); G_loss: tensor(9.9995)\n",
      "Epoch: 11051; D_loss: tensor(0.0350); G_loss: tensor(7.2225)\n",
      "Epoch: 11052; D_loss: tensor(0.3508); G_loss: tensor(7.4877)\n",
      "Epoch: 11053; D_loss: tensor(0.6834); G_loss: tensor(7.5559)\n",
      "Epoch: 11054; D_loss: tensor(0.1937); G_loss: tensor(16.3539)\n",
      "Epoch: 11055; D_loss: tensor(0.0457); G_loss: tensor(2.5755)\n",
      "Epoch: 11056; D_loss: tensor(0.0923); G_loss: tensor(8.1888)\n",
      "Epoch: 11057; D_loss: tensor(0.0901); G_loss: tensor(13.7256)\n",
      "Epoch: 11058; D_loss: tensor(0.0405); G_loss: tensor(6.8531)\n",
      "Epoch: 11059; D_loss: tensor(0.1116); G_loss: tensor(11.4733)\n",
      "Epoch: 11060; D_loss: tensor(0.0583); G_loss: tensor(13.7132)\n",
      "Epoch: 11061; D_loss: tensor(0.0622); G_loss: tensor(6.6758)\n",
      "Epoch: 11062; D_loss: tensor(0.0447); G_loss: tensor(8.1757)\n",
      "Epoch: 11063; D_loss: tensor(0.3390); G_loss: tensor(4.5871)\n",
      "Epoch: 11064; D_loss: tensor(0.0370); G_loss: tensor(12.3134)\n",
      "Epoch: 11065; D_loss: tensor(0.0222); G_loss: tensor(5.0405)\n",
      "Epoch: 11066; D_loss: tensor(0.2936); G_loss: tensor(4.2551)\n",
      "Epoch: 11067; D_loss: tensor(0.0418); G_loss: tensor(16.1172)\n",
      "Epoch: 11068; D_loss: tensor(0.0149); G_loss: tensor(3.8059)\n",
      "Epoch: 11069; D_loss: tensor(0.0134); G_loss: tensor(9.9331)\n",
      "Epoch: 11070; D_loss: tensor(0.0912); G_loss: tensor(12.8363)\n",
      "Epoch: 11071; D_loss: tensor(0.0201); G_loss: tensor(13.1361)\n",
      "Epoch: 11072; D_loss: tensor(0.0065); G_loss: tensor(11.9224)\n",
      "Epoch: 11073; D_loss: tensor(0.0103); G_loss: tensor(9.4124)\n",
      "Epoch: 11074; D_loss: tensor(0.0114); G_loss: tensor(9.7923)\n",
      "Epoch: 11075; D_loss: tensor(0.0854); G_loss: tensor(13.8300)\n",
      "Epoch: 11076; D_loss: tensor(0.0318); G_loss: tensor(14.0168)\n",
      "Epoch: 11077; D_loss: tensor(0.0125); G_loss: tensor(12.1177)\n",
      "Epoch: 11078; D_loss: tensor(0.0046); G_loss: tensor(10.3479)\n",
      "Epoch: 11079; D_loss: tensor(0.0091); G_loss: tensor(8.1908)\n",
      "Epoch: 11080; D_loss: tensor(0.0189); G_loss: tensor(10.3432)\n",
      "Epoch: 11081; D_loss: tensor(0.0184); G_loss: tensor(9.9175)\n",
      "Epoch: 11082; D_loss: tensor(0.0068); G_loss: tensor(7.8267)\n",
      "Epoch: 11083; D_loss: tensor(0.0333); G_loss: tensor(10.1368)\n",
      "Epoch: 11084; D_loss: tensor(0.0384); G_loss: tensor(9.4474)\n",
      "Epoch: 11085; D_loss: tensor(0.0842); G_loss: tensor(6.4289)\n",
      "Epoch: 11086; D_loss: tensor(0.0637); G_loss: tensor(4.8062)\n",
      "Epoch: 11087; D_loss: tensor(0.0352); G_loss: tensor(7.5466)\n",
      "Epoch: 11088; D_loss: tensor(0.0175); G_loss: tensor(9.0173)\n",
      "Epoch: 11089; D_loss: tensor(0.0286); G_loss: tensor(10.1994)\n",
      "Epoch: 11090; D_loss: tensor(0.0072); G_loss: tensor(8.9402)\n",
      "Epoch: 11091; D_loss: tensor(0.0131); G_loss: tensor(8.2536)\n",
      "Epoch: 11092; D_loss: tensor(0.0244); G_loss: tensor(4.2098)\n",
      "Epoch: 11093; D_loss: tensor(0.0130); G_loss: tensor(9.3914)\n",
      "Epoch: 11094; D_loss: tensor(0.0076); G_loss: tensor(13.0922)\n",
      "Epoch: 11095; D_loss: tensor(0.0570); G_loss: tensor(10.0809)\n",
      "Epoch: 11096; D_loss: tensor(0.0021); G_loss: tensor(11.9088)\n",
      "Epoch: 11097; D_loss: tensor(0.0019); G_loss: tensor(10.7848)\n",
      "Epoch: 11098; D_loss: tensor(0.0131); G_loss: tensor(10.3579)\n",
      "Epoch: 11099; D_loss: tensor(0.0181); G_loss: tensor(11.4096)\n",
      "Epoch: 11100; D_loss: tensor(0.0648); G_loss: tensor(7.7620)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11101; D_loss: tensor(0.0281); G_loss: tensor(11.5842)\n",
      "Epoch: 11102; D_loss: tensor(0.0366); G_loss: tensor(9.4421)\n",
      "Epoch: 11103; D_loss: tensor(0.0274); G_loss: tensor(7.5492)\n",
      "Epoch: 11104; D_loss: tensor(0.0208); G_loss: tensor(8.6867)\n",
      "Epoch: 11105; D_loss: tensor(0.0129); G_loss: tensor(8.5194)\n",
      "Epoch: 11106; D_loss: tensor(0.0129); G_loss: tensor(7.9567)\n",
      "Epoch: 11107; D_loss: tensor(0.0372); G_loss: tensor(7.7244)\n",
      "Epoch: 11108; D_loss: tensor(0.0284); G_loss: tensor(7.7935)\n",
      "Epoch: 11109; D_loss: tensor(0.0330); G_loss: tensor(5.8533)\n",
      "Epoch: 11110; D_loss: tensor(0.0167); G_loss: tensor(7.8301)\n",
      "Epoch: 11111; D_loss: tensor(0.0133); G_loss: tensor(9.3441)\n",
      "Epoch: 11112; D_loss: tensor(0.1718); G_loss: tensor(11.2184)\n",
      "Epoch: 11113; D_loss: tensor(0.0117); G_loss: tensor(7.5103)\n",
      "Epoch: 11114; D_loss: tensor(0.1312); G_loss: tensor(11.1646)\n",
      "Epoch: 11115; D_loss: tensor(0.0253); G_loss: tensor(16.0011)\n",
      "Epoch: 11116; D_loss: tensor(0.0081); G_loss: tensor(13.8692)\n",
      "Epoch: 11117; D_loss: tensor(0.0033); G_loss: tensor(8.3326)\n",
      "Epoch: 11118; D_loss: tensor(0.3673); G_loss: tensor(6.7267)\n",
      "Epoch: 11119; D_loss: tensor(0.0053); G_loss: tensor(12.3576)\n",
      "Epoch: 11120; D_loss: tensor(0.2344); G_loss: tensor(10.6503)\n",
      "Epoch: 11121; D_loss: tensor(0.0746); G_loss: tensor(6.1460)\n",
      "Epoch: 11122; D_loss: tensor(0.0214); G_loss: tensor(10.7951)\n",
      "Epoch: 11123; D_loss: tensor(0.4685); G_loss: tensor(13.2873)\n",
      "Epoch: 11124; D_loss: tensor(0.0092); G_loss: tensor(7.2346)\n",
      "Epoch: 11125; D_loss: tensor(0.0913); G_loss: tensor(10.2005)\n",
      "Epoch: 11126; D_loss: tensor(0.0011); G_loss: tensor(11.2588)\n",
      "Epoch: 11127; D_loss: tensor(0.0206); G_loss: tensor(11.0822)\n",
      "Epoch: 11128; D_loss: tensor(0.0043); G_loss: tensor(11.6376)\n",
      "Epoch: 11129; D_loss: tensor(0.0230); G_loss: tensor(8.8210)\n",
      "Epoch: 11130; D_loss: tensor(0.0063); G_loss: tensor(6.4741)\n",
      "Epoch: 11131; D_loss: tensor(0.0269); G_loss: tensor(9.4150)\n",
      "Epoch: 11132; D_loss: tensor(0.0064); G_loss: tensor(11.0295)\n",
      "Epoch: 11133; D_loss: tensor(0.0129); G_loss: tensor(12.2181)\n",
      "Epoch: 11134; D_loss: tensor(0.0130); G_loss: tensor(10.2731)\n",
      "Epoch: 11135; D_loss: tensor(0.0078); G_loss: tensor(10.8087)\n",
      "Epoch: 11136; D_loss: tensor(0.0167); G_loss: tensor(7.4991)\n",
      "Epoch: 11137; D_loss: tensor(0.0078); G_loss: tensor(8.7122)\n",
      "Epoch: 11138; D_loss: tensor(0.0007); G_loss: tensor(7.5991)\n",
      "Epoch: 11139; D_loss: tensor(0.0076); G_loss: tensor(8.1154)\n",
      "Epoch: 11140; D_loss: tensor(0.0011); G_loss: tensor(9.5218)\n",
      "Epoch: 11141; D_loss: tensor(0.0106); G_loss: tensor(10.1894)\n",
      "Epoch: 11142; D_loss: tensor(0.0025); G_loss: tensor(7.8002)\n",
      "Epoch: 11143; D_loss: tensor(0.0465); G_loss: tensor(9.4206)\n",
      "Epoch: 11144; D_loss: tensor(0.0013); G_loss: tensor(7.9963)\n",
      "Epoch: 11145; D_loss: tensor(0.0060); G_loss: tensor(8.5245)\n",
      "Epoch: 11146; D_loss: tensor(0.0283); G_loss: tensor(8.1675)\n",
      "Epoch: 11147; D_loss: tensor(0.0135); G_loss: tensor(8.2367)\n",
      "Epoch: 11148; D_loss: tensor(0.0087); G_loss: tensor(8.7497)\n",
      "Epoch: 11149; D_loss: tensor(0.0248); G_loss: tensor(8.3431)\n",
      "Epoch: 11150; D_loss: tensor(0.0103); G_loss: tensor(7.5936)\n",
      "Epoch: 11151; D_loss: tensor(0.0150); G_loss: tensor(6.5930)\n",
      "Epoch: 11152; D_loss: tensor(0.0029); G_loss: tensor(10.3506)\n",
      "Epoch: 11153; D_loss: tensor(0.0218); G_loss: tensor(9.4204)\n",
      "Epoch: 11154; D_loss: tensor(0.0055); G_loss: tensor(6.9855)\n",
      "Epoch: 11155; D_loss: tensor(0.0141); G_loss: tensor(9.1107)\n",
      "Epoch: 11156; D_loss: tensor(0.0202); G_loss: tensor(8.1919)\n",
      "Epoch: 11157; D_loss: tensor(0.0170); G_loss: tensor(6.9029)\n",
      "Epoch: 11158; D_loss: tensor(0.0123); G_loss: tensor(9.8534)\n",
      "Epoch: 11159; D_loss: tensor(0.0203); G_loss: tensor(9.6534)\n",
      "Epoch: 11160; D_loss: tensor(0.0127); G_loss: tensor(4.8578)\n",
      "Epoch: 11161; D_loss: tensor(0.0023); G_loss: tensor(7.4093)\n",
      "Epoch: 11162; D_loss: tensor(0.0425); G_loss: tensor(11.2923)\n",
      "Epoch: 11163; D_loss: tensor(0.0140); G_loss: tensor(11.2047)\n",
      "Epoch: 11164; D_loss: tensor(0.0064); G_loss: tensor(8.9932)\n",
      "Epoch: 11165; D_loss: tensor(0.0069); G_loss: tensor(9.0315)\n",
      "Epoch: 11166; D_loss: tensor(0.0191); G_loss: tensor(8.4610)\n",
      "Epoch: 11167; D_loss: tensor(0.0253); G_loss: tensor(10.1829)\n",
      "Epoch: 11168; D_loss: tensor(0.0157); G_loss: tensor(7.5605)\n",
      "Epoch: 11169; D_loss: tensor(0.0284); G_loss: tensor(5.7121)\n",
      "Epoch: 11170; D_loss: tensor(0.0050); G_loss: tensor(7.6348)\n",
      "Epoch: 11171; D_loss: tensor(0.0027); G_loss: tensor(9.0851)\n",
      "Epoch: 11172; D_loss: tensor(0.0252); G_loss: tensor(8.7787)\n",
      "Epoch: 11173; D_loss: tensor(0.0223); G_loss: tensor(8.3643)\n",
      "Epoch: 11174; D_loss: tensor(0.0227); G_loss: tensor(8.3093)\n",
      "Epoch: 11175; D_loss: tensor(0.0245); G_loss: tensor(6.0317)\n",
      "Epoch: 11176; D_loss: tensor(0.0196); G_loss: tensor(7.7332)\n",
      "Epoch: 11177; D_loss: tensor(0.0355); G_loss: tensor(11.1228)\n",
      "Epoch: 11178; D_loss: tensor(0.0050); G_loss: tensor(8.8608)\n",
      "Epoch: 11179; D_loss: tensor(0.0512); G_loss: tensor(8.5654)\n",
      "Epoch: 11180; D_loss: tensor(0.0024); G_loss: tensor(10.3689)\n",
      "Epoch: 11181; D_loss: tensor(0.0093); G_loss: tensor(9.6534)\n",
      "Epoch: 11182; D_loss: tensor(0.0024); G_loss: tensor(8.5999)\n",
      "Epoch: 11183; D_loss: tensor(0.0028); G_loss: tensor(9.7429)\n",
      "Epoch: 11184; D_loss: tensor(0.0068); G_loss: tensor(6.6510)\n",
      "Epoch: 11185; D_loss: tensor(0.0211); G_loss: tensor(5.5612)\n",
      "Epoch: 11186; D_loss: tensor(0.0130); G_loss: tensor(6.1910)\n",
      "Epoch: 11187; D_loss: tensor(0.0281); G_loss: tensor(6.3771)\n",
      "Epoch: 11188; D_loss: tensor(0.0111); G_loss: tensor(7.7713)\n",
      "Epoch: 11189; D_loss: tensor(0.0840); G_loss: tensor(9.5798)\n",
      "Epoch: 11190; D_loss: tensor(0.0489); G_loss: tensor(5.9670)\n",
      "Epoch: 11191; D_loss: tensor(0.0089); G_loss: tensor(5.7436)\n",
      "Epoch: 11192; D_loss: tensor(0.0035); G_loss: tensor(8.3749)\n",
      "Epoch: 11193; D_loss: tensor(0.0096); G_loss: tensor(10.9895)\n",
      "Epoch: 11194; D_loss: tensor(0.0340); G_loss: tensor(9.1895)\n",
      "Epoch: 11195; D_loss: tensor(0.0129); G_loss: tensor(8.7485)\n",
      "Epoch: 11196; D_loss: tensor(0.0024); G_loss: tensor(8.6316)\n",
      "Epoch: 11197; D_loss: tensor(0.0176); G_loss: tensor(10.1296)\n",
      "Epoch: 11198; D_loss: tensor(0.0088); G_loss: tensor(12.4083)\n",
      "Epoch: 11199; D_loss: tensor(0.0061); G_loss: tensor(10.7263)\n",
      "Epoch: 11200; D_loss: tensor(0.0058); G_loss: tensor(6.2905)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11201; D_loss: tensor(0.0381); G_loss: tensor(8.1254)\n",
      "Epoch: 11202; D_loss: tensor(0.0131); G_loss: tensor(9.9735)\n",
      "Epoch: 11203; D_loss: tensor(0.0776); G_loss: tensor(6.6524)\n",
      "Epoch: 11204; D_loss: tensor(0.2042); G_loss: tensor(7.9224)\n",
      "Epoch: 11205; D_loss: tensor(0.1454); G_loss: tensor(7.9506)\n",
      "Epoch: 11206; D_loss: tensor(0.0770); G_loss: tensor(4.7396)\n",
      "Epoch: 11207; D_loss: tensor(0.0184); G_loss: tensor(7.2321)\n",
      "Epoch: 11208; D_loss: tensor(0.0051); G_loss: tensor(11.0927)\n",
      "Epoch: 11209; D_loss: tensor(0.0524); G_loss: tensor(2.6291)\n",
      "Epoch: 11210; D_loss: tensor(0.0030); G_loss: tensor(14.8484)\n",
      "Epoch: 11211; D_loss: tensor(0.0354); G_loss: tensor(11.3197)\n",
      "Epoch: 11212; D_loss: tensor(0.0688); G_loss: tensor(5.3627)\n",
      "Epoch: 11213; D_loss: tensor(0.1249); G_loss: tensor(11.8745)\n",
      "Epoch: 11214; D_loss: tensor(0.1193); G_loss: tensor(8.1793)\n",
      "Epoch: 11215; D_loss: tensor(0.0451); G_loss: tensor(6.2874)\n",
      "Epoch: 11216; D_loss: tensor(0.0135); G_loss: tensor(11.8040)\n",
      "Epoch: 11217; D_loss: tensor(0.8408); G_loss: tensor(15.4568)\n",
      "Epoch: 11218; D_loss: tensor(0.0186); G_loss: tensor(3.0194)\n",
      "Epoch: 11219; D_loss: tensor(0.0300); G_loss: tensor(13.1961)\n",
      "Epoch: 11220; D_loss: tensor(0.6084); G_loss: tensor(10.6143)\n",
      "Epoch: 11221; D_loss: tensor(0.3779); G_loss: tensor(4.5713)\n",
      "Epoch: 11222; D_loss: tensor(0.0376); G_loss: tensor(11.9925)\n",
      "Epoch: 11223; D_loss: tensor(0.1160); G_loss: tensor(11.6995)\n",
      "Epoch: 11224; D_loss: tensor(0.0133); G_loss: tensor(7.2707)\n",
      "Epoch: 11225; D_loss: tensor(0.0467); G_loss: tensor(7.1804)\n",
      "Epoch: 11226; D_loss: tensor(0.1599); G_loss: tensor(9.4375)\n",
      "Epoch: 11227; D_loss: tensor(0.0220); G_loss: tensor(15.7266)\n",
      "Epoch: 11228; D_loss: tensor(0.0245); G_loss: tensor(16.3594)\n",
      "Epoch: 11229; D_loss: tensor(0.0005); G_loss: tensor(13.7213)\n",
      "Epoch: 11230; D_loss: tensor(0.0022); G_loss: tensor(12.4919)\n",
      "Epoch: 11231; D_loss: tensor(0.0113); G_loss: tensor(11.0215)\n",
      "Epoch: 11232; D_loss: tensor(0.0233); G_loss: tensor(9.1767)\n",
      "Epoch: 11233; D_loss: tensor(0.0071); G_loss: tensor(9.4530)\n",
      "Epoch: 11234; D_loss: tensor(0.0260); G_loss: tensor(10.8295)\n",
      "Epoch: 11235; D_loss: tensor(0.0368); G_loss: tensor(10.6986)\n",
      "Epoch: 11236; D_loss: tensor(0.0116); G_loss: tensor(7.4107)\n",
      "Epoch: 11237; D_loss: tensor(0.0955); G_loss: tensor(7.7182)\n",
      "Epoch: 11238; D_loss: tensor(0.0019); G_loss: tensor(11.7348)\n",
      "Epoch: 11239; D_loss: tensor(0.0286); G_loss: tensor(11.5991)\n",
      "Epoch: 11240; D_loss: tensor(0.0100); G_loss: tensor(8.0489)\n",
      "Epoch: 11241; D_loss: tensor(0.0043); G_loss: tensor(7.5543)\n",
      "Epoch: 11242; D_loss: tensor(0.0142); G_loss: tensor(6.9769)\n",
      "Epoch: 11243; D_loss: tensor(0.0222); G_loss: tensor(7.9787)\n",
      "Epoch: 11244; D_loss: tensor(0.0038); G_loss: tensor(8.9218)\n",
      "Epoch: 11245; D_loss: tensor(0.0079); G_loss: tensor(9.0014)\n",
      "Epoch: 11246; D_loss: tensor(0.0081); G_loss: tensor(9.2800)\n",
      "Epoch: 11247; D_loss: tensor(0.0032); G_loss: tensor(9.5569)\n",
      "Epoch: 11248; D_loss: tensor(0.0481); G_loss: tensor(10.2620)\n",
      "Epoch: 11249; D_loss: tensor(0.0077); G_loss: tensor(8.5588)\n",
      "Epoch: 11250; D_loss: tensor(0.0201); G_loss: tensor(7.4266)\n",
      "Epoch: 11251; D_loss: tensor(0.0118); G_loss: tensor(9.9766)\n",
      "Epoch: 11252; D_loss: tensor(0.0561); G_loss: tensor(8.3325)\n",
      "Epoch: 11253; D_loss: tensor(0.0049); G_loss: tensor(6.6258)\n",
      "Epoch: 11254; D_loss: tensor(0.0153); G_loss: tensor(9.0470)\n",
      "Epoch: 11255; D_loss: tensor(0.0134); G_loss: tensor(7.3894)\n",
      "Epoch: 11256; D_loss: tensor(0.0056); G_loss: tensor(9.6326)\n",
      "Epoch: 11257; D_loss: tensor(0.0122); G_loss: tensor(9.5958)\n",
      "Epoch: 11258; D_loss: tensor(0.0501); G_loss: tensor(7.9857)\n",
      "Epoch: 11259; D_loss: tensor(0.0249); G_loss: tensor(7.8298)\n",
      "Epoch: 11260; D_loss: tensor(0.0226); G_loss: tensor(8.0940)\n",
      "Epoch: 11261; D_loss: tensor(0.0109); G_loss: tensor(7.8252)\n",
      "Epoch: 11262; D_loss: tensor(0.0353); G_loss: tensor(8.5846)\n",
      "Epoch: 11263; D_loss: tensor(0.2707); G_loss: tensor(6.1846)\n",
      "Epoch: 11264; D_loss: tensor(0.0428); G_loss: tensor(11.2308)\n",
      "Epoch: 11265; D_loss: tensor(0.0151); G_loss: tensor(9.2756)\n",
      "Epoch: 11266; D_loss: tensor(0.0021); G_loss: tensor(6.7577)\n",
      "Epoch: 11267; D_loss: tensor(0.0366); G_loss: tensor(6.1574)\n",
      "Epoch: 11268; D_loss: tensor(0.0022); G_loss: tensor(7.6469)\n",
      "Epoch: 11269; D_loss: tensor(0.0033); G_loss: tensor(10.5494)\n",
      "Epoch: 11270; D_loss: tensor(0.0470); G_loss: tensor(12.5200)\n",
      "Epoch: 11271; D_loss: tensor(0.0416); G_loss: tensor(8.6902)\n",
      "Epoch: 11272; D_loss: tensor(0.0142); G_loss: tensor(5.9136)\n",
      "Epoch: 11273; D_loss: tensor(0.0175); G_loss: tensor(7.5557)\n",
      "Epoch: 11274; D_loss: tensor(0.0242); G_loss: tensor(10.8101)\n",
      "Epoch: 11275; D_loss: tensor(0.0768); G_loss: tensor(11.5186)\n",
      "Epoch: 11276; D_loss: tensor(0.0763); G_loss: tensor(5.0228)\n",
      "Epoch: 11277; D_loss: tensor(0.0080); G_loss: tensor(10.8022)\n",
      "Epoch: 11278; D_loss: tensor(0.0170); G_loss: tensor(13.0540)\n",
      "Epoch: 11279; D_loss: tensor(0.2703); G_loss: tensor(8.7634)\n",
      "Epoch: 11280; D_loss: tensor(0.0260); G_loss: tensor(5.3323)\n",
      "Epoch: 11281; D_loss: tensor(0.0272); G_loss: tensor(8.6778)\n",
      "Epoch: 11282; D_loss: tensor(0.0198); G_loss: tensor(13.0367)\n",
      "Epoch: 11283; D_loss: tensor(0.0083); G_loss: tensor(8.5440)\n",
      "Epoch: 11284; D_loss: tensor(0.0142); G_loss: tensor(9.8612)\n",
      "Epoch: 11285; D_loss: tensor(0.0029); G_loss: tensor(7.5199)\n",
      "Epoch: 11286; D_loss: tensor(0.0099); G_loss: tensor(11.3313)\n",
      "Epoch: 11287; D_loss: tensor(0.0061); G_loss: tensor(9.8955)\n",
      "Epoch: 11288; D_loss: tensor(0.0277); G_loss: tensor(14.9847)\n",
      "Epoch: 11289; D_loss: tensor(0.0083); G_loss: tensor(8.2563)\n",
      "Epoch: 11290; D_loss: tensor(0.1111); G_loss: tensor(4.7814)\n",
      "Epoch: 11291; D_loss: tensor(0.0284); G_loss: tensor(8.2721)\n",
      "Epoch: 11292; D_loss: tensor(0.0086); G_loss: tensor(9.5100)\n",
      "Epoch: 11293; D_loss: tensor(0.0249); G_loss: tensor(11.9443)\n",
      "Epoch: 11294; D_loss: tensor(0.0112); G_loss: tensor(6.9571)\n",
      "Epoch: 11295; D_loss: tensor(0.1050); G_loss: tensor(4.3372)\n",
      "Epoch: 11296; D_loss: tensor(0.0157); G_loss: tensor(9.8882)\n",
      "Epoch: 11297; D_loss: tensor(0.0831); G_loss: tensor(11.2938)\n",
      "Epoch: 11298; D_loss: tensor(0.0204); G_loss: tensor(8.2120)\n",
      "Epoch: 11299; D_loss: tensor(0.1223); G_loss: tensor(6.9097)\n",
      "Epoch: 11300; D_loss: tensor(0.0107); G_loss: tensor(8.3912)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11301; D_loss: tensor(0.0245); G_loss: tensor(10.4204)\n",
      "Epoch: 11302; D_loss: tensor(0.0474); G_loss: tensor(11.4739)\n",
      "Epoch: 11303; D_loss: tensor(0.0109); G_loss: tensor(7.4587)\n",
      "Epoch: 11304; D_loss: tensor(0.0709); G_loss: tensor(8.0141)\n",
      "Epoch: 11305; D_loss: tensor(0.0067); G_loss: tensor(8.7126)\n",
      "Epoch: 11306; D_loss: tensor(0.0037); G_loss: tensor(10.2234)\n",
      "Epoch: 11307; D_loss: tensor(0.7027); G_loss: tensor(6.8309)\n",
      "Epoch: 11308; D_loss: tensor(0.0378); G_loss: tensor(9.3675)\n",
      "Epoch: 11309; D_loss: tensor(0.7652); G_loss: tensor(13.2881)\n",
      "Epoch: 11310; D_loss: tensor(0.0038); G_loss: tensor(6.8379)\n",
      "Epoch: 11311; D_loss: tensor(0.0386); G_loss: tensor(9.4229)\n",
      "Epoch: 11312; D_loss: tensor(0.0084); G_loss: tensor(15.3374)\n",
      "Epoch: 11313; D_loss: tensor(0.0529); G_loss: tensor(14.3129)\n",
      "Epoch: 11314; D_loss: tensor(0.0011); G_loss: tensor(5.9493)\n",
      "Epoch: 11315; D_loss: tensor(0.3046); G_loss: tensor(14.3581)\n",
      "Epoch: 11316; D_loss: tensor(0.0668); G_loss: tensor(16.9596)\n",
      "Epoch: 11317; D_loss: tensor(0.0118); G_loss: tensor(9.4319)\n",
      "Epoch: 11318; D_loss: tensor(0.0427); G_loss: tensor(8.6499)\n",
      "Epoch: 11319; D_loss: tensor(0.0438); G_loss: tensor(11.8237)\n",
      "Epoch: 11320; D_loss: tensor(0.1135); G_loss: tensor(13.3767)\n",
      "Epoch: 11321; D_loss: tensor(0.0662); G_loss: tensor(13.5492)\n",
      "Epoch: 11322; D_loss: tensor(0.0017); G_loss: tensor(11.0764)\n",
      "Epoch: 11323; D_loss: tensor(0.0250); G_loss: tensor(6.5228)\n",
      "Epoch: 11324; D_loss: tensor(0.0669); G_loss: tensor(14.4824)\n",
      "Epoch: 11325; D_loss: tensor(0.0035); G_loss: tensor(9.2415)\n",
      "Epoch: 11326; D_loss: tensor(0.1329); G_loss: tensor(5.6573)\n",
      "Epoch: 11327; D_loss: tensor(0.0071); G_loss: tensor(10.3518)\n",
      "Epoch: 11328; D_loss: tensor(0.0014); G_loss: tensor(13.3270)\n",
      "Epoch: 11329; D_loss: tensor(0.0119); G_loss: tensor(14.6066)\n",
      "Epoch: 11330; D_loss: tensor(0.0091); G_loss: tensor(12.2443)\n",
      "Epoch: 11331; D_loss: tensor(0.0479); G_loss: tensor(11.2012)\n",
      "Epoch: 11332; D_loss: tensor(0.0039); G_loss: tensor(14.1525)\n",
      "Epoch: 11333; D_loss: tensor(0.0084); G_loss: tensor(12.1792)\n",
      "Epoch: 11334; D_loss: tensor(0.0096); G_loss: tensor(10.8510)\n",
      "Epoch: 11335; D_loss: tensor(0.0790); G_loss: tensor(10.1085)\n",
      "Epoch: 11336; D_loss: tensor(0.0210); G_loss: tensor(9.4592)\n",
      "Epoch: 11337; D_loss: tensor(0.0055); G_loss: tensor(9.9710)\n",
      "Epoch: 11338; D_loss: tensor(0.0212); G_loss: tensor(12.5407)\n",
      "Epoch: 11339; D_loss: tensor(0.0134); G_loss: tensor(13.2152)\n",
      "Epoch: 11340; D_loss: tensor(0.0004); G_loss: tensor(12.8491)\n",
      "Epoch: 11341; D_loss: tensor(0.0020); G_loss: tensor(12.0566)\n",
      "Epoch: 11342; D_loss: tensor(0.0006); G_loss: tensor(13.1131)\n",
      "Epoch: 11343; D_loss: tensor(0.0310); G_loss: tensor(10.6117)\n",
      "Epoch: 11344; D_loss: tensor(0.0070); G_loss: tensor(7.4595)\n",
      "Epoch: 11345; D_loss: tensor(0.0028); G_loss: tensor(6.4501)\n",
      "Epoch: 11346; D_loss: tensor(0.0100); G_loss: tensor(7.3374)\n",
      "Epoch: 11347; D_loss: tensor(0.0022); G_loss: tensor(9.7002)\n",
      "Epoch: 11348; D_loss: tensor(0.0126); G_loss: tensor(11.0653)\n",
      "Epoch: 11349; D_loss: tensor(0.0057); G_loss: tensor(10.2644)\n",
      "Epoch: 11350; D_loss: tensor(0.0093); G_loss: tensor(11.5425)\n",
      "Epoch: 11351; D_loss: tensor(0.0051); G_loss: tensor(13.4957)\n",
      "Epoch: 11352; D_loss: tensor(0.0088); G_loss: tensor(10.2330)\n",
      "Epoch: 11353; D_loss: tensor(0.0108); G_loss: tensor(6.8578)\n",
      "Epoch: 11354; D_loss: tensor(0.0158); G_loss: tensor(7.5337)\n",
      "Epoch: 11355; D_loss: tensor(0.0439); G_loss: tensor(10.0454)\n",
      "Epoch: 11356; D_loss: tensor(0.0008); G_loss: tensor(9.3512)\n",
      "Epoch: 11357; D_loss: tensor(0.0079); G_loss: tensor(7.9816)\n",
      "Epoch: 11358; D_loss: tensor(0.0247); G_loss: tensor(6.9481)\n",
      "Epoch: 11359; D_loss: tensor(0.0128); G_loss: tensor(8.4132)\n",
      "Epoch: 11360; D_loss: tensor(0.0032); G_loss: tensor(8.0702)\n",
      "Epoch: 11361; D_loss: tensor(0.0376); G_loss: tensor(9.0557)\n",
      "Epoch: 11362; D_loss: tensor(0.0041); G_loss: tensor(8.3500)\n",
      "Epoch: 11363; D_loss: tensor(0.0169); G_loss: tensor(9.6019)\n",
      "Epoch: 11364; D_loss: tensor(0.0458); G_loss: tensor(6.3742)\n",
      "Epoch: 11365; D_loss: tensor(0.0411); G_loss: tensor(6.8435)\n",
      "Epoch: 11366; D_loss: tensor(0.0021); G_loss: tensor(9.6086)\n",
      "Epoch: 11367; D_loss: tensor(0.0118); G_loss: tensor(8.9483)\n",
      "Epoch: 11368; D_loss: tensor(0.0130); G_loss: tensor(9.2679)\n",
      "Epoch: 11369; D_loss: tensor(0.0663); G_loss: tensor(9.8308)\n",
      "Epoch: 11370; D_loss: tensor(0.0056); G_loss: tensor(7.8790)\n",
      "Epoch: 11371; D_loss: tensor(0.0195); G_loss: tensor(9.6782)\n",
      "Epoch: 11372; D_loss: tensor(0.0129); G_loss: tensor(8.8247)\n",
      "Epoch: 11373; D_loss: tensor(0.0204); G_loss: tensor(7.5636)\n",
      "Epoch: 11374; D_loss: tensor(0.0089); G_loss: tensor(8.4394)\n",
      "Epoch: 11375; D_loss: tensor(0.0058); G_loss: tensor(7.8744)\n",
      "Epoch: 11376; D_loss: tensor(0.0141); G_loss: tensor(11.5900)\n",
      "Epoch: 11377; D_loss: tensor(0.0084); G_loss: tensor(8.1437)\n",
      "Epoch: 11378; D_loss: tensor(0.0058); G_loss: tensor(10.8209)\n",
      "Epoch: 11379; D_loss: tensor(0.0064); G_loss: tensor(9.2676)\n",
      "Epoch: 11380; D_loss: tensor(0.0082); G_loss: tensor(9.7398)\n",
      "Epoch: 11381; D_loss: tensor(0.0226); G_loss: tensor(5.4282)\n",
      "Epoch: 11382; D_loss: tensor(0.0165); G_loss: tensor(8.9485)\n",
      "Epoch: 11383; D_loss: tensor(0.0048); G_loss: tensor(6.9019)\n",
      "Epoch: 11384; D_loss: tensor(0.0530); G_loss: tensor(7.3133)\n",
      "Epoch: 11385; D_loss: tensor(0.0339); G_loss: tensor(9.1942)\n",
      "Epoch: 11386; D_loss: tensor(0.0116); G_loss: tensor(10.6983)\n",
      "Epoch: 11387; D_loss: tensor(0.0150); G_loss: tensor(9.9179)\n",
      "Epoch: 11388; D_loss: tensor(0.0710); G_loss: tensor(10.3083)\n",
      "Epoch: 11389; D_loss: tensor(0.0086); G_loss: tensor(6.2506)\n",
      "Epoch: 11390; D_loss: tensor(0.0065); G_loss: tensor(6.6192)\n",
      "Epoch: 11391; D_loss: tensor(0.0035); G_loss: tensor(11.5424)\n",
      "Epoch: 11392; D_loss: tensor(0.0662); G_loss: tensor(12.0467)\n",
      "Epoch: 11393; D_loss: tensor(0.0026); G_loss: tensor(8.6334)\n",
      "Epoch: 11394; D_loss: tensor(0.0276); G_loss: tensor(6.2096)\n",
      "Epoch: 11395; D_loss: tensor(0.0199); G_loss: tensor(7.6649)\n",
      "Epoch: 11396; D_loss: tensor(0.0043); G_loss: tensor(9.9175)\n",
      "Epoch: 11397; D_loss: tensor(0.0376); G_loss: tensor(8.4574)\n",
      "Epoch: 11398; D_loss: tensor(0.0134); G_loss: tensor(5.8168)\n",
      "Epoch: 11399; D_loss: tensor(0.0209); G_loss: tensor(11.2010)\n",
      "Epoch: 11400; D_loss: tensor(0.0233); G_loss: tensor(4.3221)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11401; D_loss: tensor(0.0011); G_loss: tensor(12.7577)\n",
      "Epoch: 11402; D_loss: tensor(0.8188); G_loss: tensor(12.0050)\n",
      "Epoch: 11403; D_loss: tensor(0.4680); G_loss: tensor(2.7350)\n",
      "Epoch: 11404; D_loss: tensor(0.0806); G_loss: tensor(13.4239)\n",
      "Epoch: 11405; D_loss: tensor(0.3472); G_loss: tensor(6.6121)\n",
      "Epoch: 11406; D_loss: tensor(0.4446); G_loss: tensor(5.5568)\n",
      "Epoch: 11407; D_loss: tensor(0.0850); G_loss: tensor(17.9798)\n",
      "Epoch: 11408; D_loss: tensor(0.3795); G_loss: tensor(2.3194)\n",
      "Epoch: 11409; D_loss: tensor(0.0733); G_loss: tensor(14.0660)\n",
      "Epoch: 11410; D_loss: tensor(0.3848); G_loss: tensor(10.1135)\n",
      "Epoch: 11411; D_loss: tensor(0.1626); G_loss: tensor(5.9625)\n",
      "Epoch: 11412; D_loss: tensor(0.1231); G_loss: tensor(9.8919)\n",
      "Epoch: 11413; D_loss: tensor(0.0927); G_loss: tensor(11.6682)\n",
      "Epoch: 11414; D_loss: tensor(0.2303); G_loss: tensor(9.1617)\n",
      "Epoch: 11415; D_loss: tensor(0.3182); G_loss: tensor(2.7217)\n",
      "Epoch: 11416; D_loss: tensor(0.0449); G_loss: tensor(10.7330)\n",
      "Epoch: 11417; D_loss: tensor(0.0490); G_loss: tensor(8.7157)\n",
      "Epoch: 11418; D_loss: tensor(0.1120); G_loss: tensor(8.8080)\n",
      "Epoch: 11419; D_loss: tensor(0.0129); G_loss: tensor(8.0738)\n",
      "Epoch: 11420; D_loss: tensor(0.0387); G_loss: tensor(9.5817)\n",
      "Epoch: 11421; D_loss: tensor(0.0138); G_loss: tensor(8.5275)\n",
      "Epoch: 11422; D_loss: tensor(0.0683); G_loss: tensor(8.2876)\n",
      "Epoch: 11423; D_loss: tensor(0.0231); G_loss: tensor(9.1260)\n",
      "Epoch: 11424; D_loss: tensor(0.0134); G_loss: tensor(9.2415)\n",
      "Epoch: 11425; D_loss: tensor(0.0714); G_loss: tensor(8.3165)\n",
      "Epoch: 11426; D_loss: tensor(0.0325); G_loss: tensor(9.3043)\n",
      "Epoch: 11427; D_loss: tensor(0.0147); G_loss: tensor(11.3543)\n",
      "Epoch: 11428; D_loss: tensor(0.0478); G_loss: tensor(10.2331)\n",
      "Epoch: 11429; D_loss: tensor(0.0351); G_loss: tensor(9.6097)\n",
      "Epoch: 11430; D_loss: tensor(0.0480); G_loss: tensor(8.4663)\n",
      "Epoch: 11431; D_loss: tensor(0.0211); G_loss: tensor(10.4086)\n",
      "Epoch: 11432; D_loss: tensor(0.0183); G_loss: tensor(10.5891)\n",
      "Epoch: 11433; D_loss: tensor(0.0113); G_loss: tensor(8.3901)\n",
      "Epoch: 11434; D_loss: tensor(0.0668); G_loss: tensor(3.9853)\n",
      "Epoch: 11435; D_loss: tensor(0.0347); G_loss: tensor(11.6385)\n",
      "Epoch: 11436; D_loss: tensor(0.0790); G_loss: tensor(13.2108)\n",
      "Epoch: 11437; D_loss: tensor(0.0198); G_loss: tensor(10.0362)\n",
      "Epoch: 11438; D_loss: tensor(0.0114); G_loss: tensor(6.4556)\n",
      "Epoch: 11439; D_loss: tensor(0.0500); G_loss: tensor(8.1883)\n",
      "Epoch: 11440; D_loss: tensor(0.0073); G_loss: tensor(8.2704)\n",
      "Epoch: 11441; D_loss: tensor(0.0022); G_loss: tensor(10.3184)\n",
      "Epoch: 11442; D_loss: tensor(0.0206); G_loss: tensor(8.1982)\n",
      "Epoch: 11443; D_loss: tensor(0.0109); G_loss: tensor(11.1828)\n",
      "Epoch: 11444; D_loss: tensor(0.0517); G_loss: tensor(10.3942)\n",
      "Epoch: 11445; D_loss: tensor(0.0165); G_loss: tensor(7.6094)\n",
      "Epoch: 11446; D_loss: tensor(0.0136); G_loss: tensor(7.4687)\n",
      "Epoch: 11447; D_loss: tensor(0.0233); G_loss: tensor(7.3643)\n",
      "Epoch: 11448; D_loss: tensor(0.0148); G_loss: tensor(8.6050)\n",
      "Epoch: 11449; D_loss: tensor(0.0407); G_loss: tensor(8.9532)\n",
      "Epoch: 11450; D_loss: tensor(0.0821); G_loss: tensor(9.6264)\n",
      "Epoch: 11451; D_loss: tensor(0.0134); G_loss: tensor(7.2837)\n",
      "Epoch: 11452; D_loss: tensor(0.0191); G_loss: tensor(6.2238)\n",
      "Epoch: 11453; D_loss: tensor(0.0328); G_loss: tensor(7.1682)\n",
      "Epoch: 11454; D_loss: tensor(0.0179); G_loss: tensor(8.2560)\n",
      "Epoch: 11455; D_loss: tensor(0.0139); G_loss: tensor(7.7154)\n",
      "Epoch: 11456; D_loss: tensor(0.0552); G_loss: tensor(8.7407)\n",
      "Epoch: 11457; D_loss: tensor(0.0368); G_loss: tensor(6.8344)\n",
      "Epoch: 11458; D_loss: tensor(0.0400); G_loss: tensor(6.5761)\n",
      "Epoch: 11459; D_loss: tensor(0.0116); G_loss: tensor(5.0974)\n",
      "Epoch: 11460; D_loss: tensor(0.0584); G_loss: tensor(8.5157)\n",
      "Epoch: 11461; D_loss: tensor(0.0117); G_loss: tensor(7.2783)\n",
      "Epoch: 11462; D_loss: tensor(0.0136); G_loss: tensor(7.6838)\n",
      "Epoch: 11463; D_loss: tensor(0.0117); G_loss: tensor(3.1450)\n",
      "Epoch: 11464; D_loss: tensor(0.0376); G_loss: tensor(8.1380)\n",
      "Epoch: 11465; D_loss: tensor(0.0232); G_loss: tensor(7.9133)\n",
      "Epoch: 11466; D_loss: tensor(0.0415); G_loss: tensor(9.8934)\n",
      "Epoch: 11467; D_loss: tensor(0.0089); G_loss: tensor(10.7083)\n",
      "Epoch: 11468; D_loss: tensor(0.0088); G_loss: tensor(8.5669)\n",
      "Epoch: 11469; D_loss: tensor(0.0213); G_loss: tensor(6.7335)\n",
      "Epoch: 11470; D_loss: tensor(0.0269); G_loss: tensor(7.1802)\n",
      "Epoch: 11471; D_loss: tensor(0.0345); G_loss: tensor(6.9285)\n",
      "Epoch: 11472; D_loss: tensor(0.0542); G_loss: tensor(7.1853)\n",
      "Epoch: 11473; D_loss: tensor(0.0274); G_loss: tensor(5.1371)\n",
      "Epoch: 11474; D_loss: tensor(0.0381); G_loss: tensor(6.2914)\n",
      "Epoch: 11475; D_loss: tensor(0.0079); G_loss: tensor(6.6282)\n",
      "Epoch: 11476; D_loss: tensor(0.2317); G_loss: tensor(5.6150)\n",
      "Epoch: 11477; D_loss: tensor(0.0320); G_loss: tensor(8.2631)\n",
      "Epoch: 11478; D_loss: tensor(0.4422); G_loss: tensor(6.6449)\n",
      "Epoch: 11479; D_loss: tensor(0.7472); G_loss: tensor(5.8254)\n",
      "Epoch: 11480; D_loss: tensor(0.0218); G_loss: tensor(13.4974)\n",
      "Epoch: 11481; D_loss: tensor(0.0380); G_loss: tensor(6.7115)\n",
      "Epoch: 11482; D_loss: tensor(0.3464); G_loss: tensor(2.6957)\n",
      "Epoch: 11483; D_loss: tensor(0.0097); G_loss: tensor(14.5527)\n",
      "Epoch: 11484; D_loss: tensor(0.1919); G_loss: tensor(8.2749)\n",
      "Epoch: 11485; D_loss: tensor(0.1587); G_loss: tensor(5.2349)\n",
      "Epoch: 11486; D_loss: tensor(0.2199); G_loss: tensor(6.0461)\n",
      "Epoch: 11487; D_loss: tensor(0.0281); G_loss: tensor(13.1978)\n",
      "Epoch: 11488; D_loss: tensor(0.0954); G_loss: tensor(11.8759)\n",
      "Epoch: 11489; D_loss: tensor(0.0028); G_loss: tensor(11.5604)\n",
      "Epoch: 11490; D_loss: tensor(0.0503); G_loss: tensor(9.0609)\n",
      "Epoch: 11491; D_loss: tensor(0.0035); G_loss: tensor(7.6739)\n",
      "Epoch: 11492; D_loss: tensor(0.0477); G_loss: tensor(8.2694)\n",
      "Epoch: 11493; D_loss: tensor(0.0653); G_loss: tensor(11.8660)\n",
      "Epoch: 11494; D_loss: tensor(0.1577); G_loss: tensor(14.1273)\n",
      "Epoch: 11495; D_loss: tensor(0.1418); G_loss: tensor(7.5868)\n",
      "Epoch: 11496; D_loss: tensor(0.0059); G_loss: tensor(4.8164)\n",
      "Epoch: 11497; D_loss: tensor(0.0267); G_loss: tensor(6.7629)\n",
      "Epoch: 11498; D_loss: tensor(0.0734); G_loss: tensor(7.0016)\n",
      "Epoch: 11499; D_loss: tensor(0.0166); G_loss: tensor(8.6595)\n",
      "Epoch: 11500; D_loss: tensor(0.0004); G_loss: tensor(12.4625)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11501; D_loss: tensor(0.0559); G_loss: tensor(9.7358)\n",
      "Epoch: 11502; D_loss: tensor(0.0823); G_loss: tensor(9.7517)\n",
      "Epoch: 11503; D_loss: tensor(0.0121); G_loss: tensor(6.1774)\n",
      "Epoch: 11504; D_loss: tensor(0.0070); G_loss: tensor(6.1293)\n",
      "Epoch: 11505; D_loss: tensor(0.0364); G_loss: tensor(5.2051)\n",
      "Epoch: 11506; D_loss: tensor(0.0179); G_loss: tensor(8.7342)\n",
      "Epoch: 11507; D_loss: tensor(0.0376); G_loss: tensor(7.3621)\n",
      "Epoch: 11508; D_loss: tensor(0.0264); G_loss: tensor(7.6366)\n",
      "Epoch: 11509; D_loss: tensor(0.0311); G_loss: tensor(6.0971)\n",
      "Epoch: 11510; D_loss: tensor(0.0193); G_loss: tensor(5.1845)\n",
      "Epoch: 11511; D_loss: tensor(0.0042); G_loss: tensor(9.4490)\n",
      "Epoch: 11512; D_loss: tensor(0.0328); G_loss: tensor(9.4537)\n",
      "Epoch: 11513; D_loss: tensor(0.0154); G_loss: tensor(8.1798)\n",
      "Epoch: 11514; D_loss: tensor(0.0078); G_loss: tensor(6.6045)\n",
      "Epoch: 11515; D_loss: tensor(0.0835); G_loss: tensor(6.8908)\n",
      "Epoch: 11516; D_loss: tensor(0.0011); G_loss: tensor(9.8271)\n",
      "Epoch: 11517; D_loss: tensor(0.0005); G_loss: tensor(7.8575)\n",
      "Epoch: 11518; D_loss: tensor(0.0441); G_loss: tensor(12.6206)\n",
      "Epoch: 11519; D_loss: tensor(0.0063); G_loss: tensor(8.3152)\n",
      "Epoch: 11520; D_loss: tensor(0.0232); G_loss: tensor(6.4586)\n",
      "Epoch: 11521; D_loss: tensor(0.0464); G_loss: tensor(7.0380)\n",
      "Epoch: 11522; D_loss: tensor(0.0090); G_loss: tensor(7.6844)\n",
      "Epoch: 11523; D_loss: tensor(0.0107); G_loss: tensor(11.5907)\n",
      "Epoch: 11524; D_loss: tensor(0.0090); G_loss: tensor(11.8754)\n",
      "Epoch: 11525; D_loss: tensor(0.0179); G_loss: tensor(9.2484)\n",
      "Epoch: 11526; D_loss: tensor(0.0068); G_loss: tensor(7.7885)\n",
      "Epoch: 11527; D_loss: tensor(0.0030); G_loss: tensor(4.9654)\n",
      "Epoch: 11528; D_loss: tensor(0.0222); G_loss: tensor(8.9962)\n",
      "Epoch: 11529; D_loss: tensor(0.0078); G_loss: tensor(7.9408)\n",
      "Epoch: 11530; D_loss: tensor(0.0021); G_loss: tensor(9.4784)\n",
      "Epoch: 11531; D_loss: tensor(0.1138); G_loss: tensor(6.3174)\n",
      "Epoch: 11532; D_loss: tensor(0.0197); G_loss: tensor(11.5359)\n",
      "Epoch: 11533; D_loss: tensor(0.0021); G_loss: tensor(10.4631)\n",
      "Epoch: 11534; D_loss: tensor(0.0080); G_loss: tensor(7.1495)\n",
      "Epoch: 11535; D_loss: tensor(0.0634); G_loss: tensor(9.7767)\n",
      "Epoch: 11536; D_loss: tensor(0.0829); G_loss: tensor(11.3476)\n",
      "Epoch: 11537; D_loss: tensor(0.0010); G_loss: tensor(10.1209)\n",
      "Epoch: 11538; D_loss: tensor(0.0108); G_loss: tensor(8.4737)\n",
      "Epoch: 11539; D_loss: tensor(0.0160); G_loss: tensor(6.1570)\n",
      "Epoch: 11540; D_loss: tensor(0.0263); G_loss: tensor(5.4035)\n",
      "Epoch: 11541; D_loss: tensor(0.0206); G_loss: tensor(7.4175)\n",
      "Epoch: 11542; D_loss: tensor(0.0048); G_loss: tensor(10.8069)\n",
      "Epoch: 11543; D_loss: tensor(0.0210); G_loss: tensor(9.8188)\n",
      "Epoch: 11544; D_loss: tensor(0.0041); G_loss: tensor(10.9200)\n",
      "Epoch: 11545; D_loss: tensor(0.0177); G_loss: tensor(8.3154)\n",
      "Epoch: 11546; D_loss: tensor(0.0074); G_loss: tensor(8.2156)\n",
      "Epoch: 11547; D_loss: tensor(0.0070); G_loss: tensor(9.0010)\n",
      "Epoch: 11548; D_loss: tensor(0.0111); G_loss: tensor(7.3725)\n",
      "Epoch: 11549; D_loss: tensor(0.0144); G_loss: tensor(8.6894)\n",
      "Epoch: 11550; D_loss: tensor(0.0049); G_loss: tensor(7.8976)\n",
      "Epoch: 11551; D_loss: tensor(0.0140); G_loss: tensor(8.1005)\n",
      "Epoch: 11552; D_loss: tensor(0.0160); G_loss: tensor(6.7151)\n",
      "Epoch: 11553; D_loss: tensor(0.0143); G_loss: tensor(6.0119)\n",
      "Epoch: 11554; D_loss: tensor(0.0105); G_loss: tensor(6.5241)\n",
      "Epoch: 11555; D_loss: tensor(0.0112); G_loss: tensor(7.9499)\n",
      "Epoch: 11556; D_loss: tensor(0.0216); G_loss: tensor(7.9892)\n",
      "Epoch: 11557; D_loss: tensor(0.0133); G_loss: tensor(7.9655)\n",
      "Epoch: 11558; D_loss: tensor(0.0035); G_loss: tensor(11.2794)\n",
      "Epoch: 11559; D_loss: tensor(0.0327); G_loss: tensor(8.9656)\n",
      "Epoch: 11560; D_loss: tensor(0.0080); G_loss: tensor(8.1088)\n",
      "Epoch: 11561; D_loss: tensor(0.0291); G_loss: tensor(6.2444)\n",
      "Epoch: 11562; D_loss: tensor(0.0044); G_loss: tensor(8.5876)\n",
      "Epoch: 11563; D_loss: tensor(0.0153); G_loss: tensor(8.8997)\n",
      "Epoch: 11564; D_loss: tensor(0.0112); G_loss: tensor(9.3481)\n",
      "Epoch: 11565; D_loss: tensor(0.0451); G_loss: tensor(9.2396)\n",
      "Epoch: 11566; D_loss: tensor(0.0048); G_loss: tensor(8.4637)\n",
      "Epoch: 11567; D_loss: tensor(0.0116); G_loss: tensor(7.4453)\n",
      "Epoch: 11568; D_loss: tensor(0.0202); G_loss: tensor(8.6659)\n",
      "Epoch: 11569; D_loss: tensor(0.0253); G_loss: tensor(8.0311)\n",
      "Epoch: 11570; D_loss: tensor(0.0149); G_loss: tensor(8.1422)\n",
      "Epoch: 11571; D_loss: tensor(0.0109); G_loss: tensor(6.3433)\n",
      "Epoch: 11572; D_loss: tensor(0.0559); G_loss: tensor(6.2016)\n",
      "Epoch: 11573; D_loss: tensor(0.0581); G_loss: tensor(8.6906)\n",
      "Epoch: 11574; D_loss: tensor(0.0306); G_loss: tensor(6.2796)\n",
      "Epoch: 11575; D_loss: tensor(0.0582); G_loss: tensor(6.1967)\n",
      "Epoch: 11576; D_loss: tensor(0.0211); G_loss: tensor(8.0131)\n",
      "Epoch: 11577; D_loss: tensor(0.2118); G_loss: tensor(8.9639)\n",
      "Epoch: 11578; D_loss: tensor(0.0279); G_loss: tensor(4.6365)\n",
      "Epoch: 11579; D_loss: tensor(0.0137); G_loss: tensor(7.1975)\n",
      "Epoch: 11580; D_loss: tensor(0.0820); G_loss: tensor(11.7713)\n",
      "Epoch: 11581; D_loss: tensor(0.0487); G_loss: tensor(8.8813)\n",
      "Epoch: 11582; D_loss: tensor(0.0277); G_loss: tensor(6.5709)\n",
      "Epoch: 11583; D_loss: tensor(0.0326); G_loss: tensor(6.4832)\n",
      "Epoch: 11584; D_loss: tensor(0.0082); G_loss: tensor(9.1663)\n",
      "Epoch: 11585; D_loss: tensor(0.0068); G_loss: tensor(10.3056)\n",
      "Epoch: 11586; D_loss: tensor(0.0055); G_loss: tensor(5.7932)\n",
      "Epoch: 11587; D_loss: tensor(0.1602); G_loss: tensor(8.5020)\n",
      "Epoch: 11588; D_loss: tensor(0.1514); G_loss: tensor(12.1798)\n",
      "Epoch: 11589; D_loss: tensor(0.0043); G_loss: tensor(5.9718)\n",
      "Epoch: 11590; D_loss: tensor(0.2303); G_loss: tensor(4.0896)\n",
      "Epoch: 11591; D_loss: tensor(0.1501); G_loss: tensor(11.6206)\n",
      "Epoch: 11592; D_loss: tensor(0.3889); G_loss: tensor(4.5622)\n",
      "Epoch: 11593; D_loss: tensor(0.0791); G_loss: tensor(11.6353)\n",
      "Epoch: 11594; D_loss: tensor(0.0266); G_loss: tensor(9.6621)\n",
      "Epoch: 11595; D_loss: tensor(0.0645); G_loss: tensor(3.3806)\n",
      "Epoch: 11596; D_loss: tensor(0.1517); G_loss: tensor(8.8827)\n",
      "Epoch: 11597; D_loss: tensor(0.1582); G_loss: tensor(17.4586)\n",
      "Epoch: 11598; D_loss: tensor(0.0749); G_loss: tensor(4.2962)\n",
      "Epoch: 11599; D_loss: tensor(0.2117); G_loss: tensor(4.6830)\n",
      "Epoch: 11600; D_loss: tensor(0.0143); G_loss: tensor(15.7994)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11601; D_loss: tensor(0.0060); G_loss: tensor(9.6827)\n",
      "Epoch: 11602; D_loss: tensor(0.0635); G_loss: tensor(3.6625)\n",
      "Epoch: 11603; D_loss: tensor(0.0056); G_loss: tensor(5.8708)\n",
      "Epoch: 11604; D_loss: tensor(0.0049); G_loss: tensor(12.3555)\n",
      "Epoch: 11605; D_loss: tensor(0.0110); G_loss: tensor(11.1121)\n",
      "Epoch: 11606; D_loss: tensor(0.0135); G_loss: tensor(8.7947)\n",
      "Epoch: 11607; D_loss: tensor(0.0387); G_loss: tensor(8.4761)\n",
      "Epoch: 11608; D_loss: tensor(0.0116); G_loss: tensor(10.4517)\n",
      "Epoch: 11609; D_loss: tensor(0.0069); G_loss: tensor(7.8547)\n",
      "Epoch: 11610; D_loss: tensor(0.0485); G_loss: tensor(11.1653)\n",
      "Epoch: 11611; D_loss: tensor(0.0003); G_loss: tensor(11.6355)\n",
      "Epoch: 11612; D_loss: tensor(0.0060); G_loss: tensor(9.5046)\n",
      "Epoch: 11613; D_loss: tensor(0.0082); G_loss: tensor(6.9421)\n",
      "Epoch: 11614; D_loss: tensor(0.0180); G_loss: tensor(8.6390)\n",
      "Epoch: 11615; D_loss: tensor(0.0054); G_loss: tensor(9.9780)\n",
      "Epoch: 11616; D_loss: tensor(0.0601); G_loss: tensor(9.2643)\n",
      "Epoch: 11617; D_loss: tensor(0.0321); G_loss: tensor(12.6158)\n",
      "Epoch: 11618; D_loss: tensor(0.0275); G_loss: tensor(7.0938)\n",
      "Epoch: 11619; D_loss: tensor(0.0221); G_loss: tensor(8.4563)\n",
      "Epoch: 11620; D_loss: tensor(0.0093); G_loss: tensor(9.3967)\n",
      "Epoch: 11621; D_loss: tensor(0.1055); G_loss: tensor(5.8420)\n",
      "Epoch: 11622; D_loss: tensor(0.0106); G_loss: tensor(6.3931)\n",
      "Epoch: 11623; D_loss: tensor(0.0512); G_loss: tensor(4.1701)\n",
      "Epoch: 11624; D_loss: tensor(0.0018); G_loss: tensor(9.9206)\n",
      "Epoch: 11625; D_loss: tensor(0.0200); G_loss: tensor(8.1535)\n",
      "Epoch: 11626; D_loss: tensor(0.0194); G_loss: tensor(7.4581)\n",
      "Epoch: 11627; D_loss: tensor(0.0059); G_loss: tensor(9.6419)\n",
      "Epoch: 11628; D_loss: tensor(0.0463); G_loss: tensor(7.2173)\n",
      "Epoch: 11629; D_loss: tensor(0.0154); G_loss: tensor(9.8158)\n",
      "Epoch: 11630; D_loss: tensor(0.0213); G_loss: tensor(6.4612)\n",
      "Epoch: 11631; D_loss: tensor(0.0150); G_loss: tensor(8.3774)\n",
      "Epoch: 11632; D_loss: tensor(0.0151); G_loss: tensor(9.0639)\n",
      "Epoch: 11633; D_loss: tensor(0.0114); G_loss: tensor(6.9793)\n",
      "Epoch: 11634; D_loss: tensor(0.0196); G_loss: tensor(8.8720)\n",
      "Epoch: 11635; D_loss: tensor(0.0031); G_loss: tensor(8.2089)\n",
      "Epoch: 11636; D_loss: tensor(0.0069); G_loss: tensor(8.6429)\n",
      "Epoch: 11637; D_loss: tensor(0.0526); G_loss: tensor(7.0937)\n",
      "Epoch: 11638; D_loss: tensor(0.0137); G_loss: tensor(7.5692)\n",
      "Epoch: 11639; D_loss: tensor(0.0606); G_loss: tensor(6.6544)\n",
      "Epoch: 11640; D_loss: tensor(0.0204); G_loss: tensor(7.8328)\n",
      "Epoch: 11641; D_loss: tensor(0.1199); G_loss: tensor(6.4952)\n",
      "Epoch: 11642; D_loss: tensor(0.0450); G_loss: tensor(4.7480)\n",
      "Epoch: 11643; D_loss: tensor(0.0701); G_loss: tensor(9.1650)\n",
      "Epoch: 11644; D_loss: tensor(0.0745); G_loss: tensor(11.0512)\n",
      "Epoch: 11645; D_loss: tensor(0.0265); G_loss: tensor(5.4948)\n",
      "Epoch: 11646; D_loss: tensor(0.3515); G_loss: tensor(9.3744)\n",
      "Epoch: 11647; D_loss: tensor(0.6432); G_loss: tensor(11.2288)\n",
      "Epoch: 11648; D_loss: tensor(0.0259); G_loss: tensor(4.7189)\n",
      "Epoch: 11649; D_loss: tensor(0.0722); G_loss: tensor(8.3513)\n",
      "Epoch: 11650; D_loss: tensor(0.0021); G_loss: tensor(16.2671)\n",
      "Epoch: 11651; D_loss: tensor(0.0046); G_loss: tensor(4.8443)\n",
      "Epoch: 11652; D_loss: tensor(0.4205); G_loss: tensor(5.0866)\n",
      "Epoch: 11653; D_loss: tensor(0.0099); G_loss: tensor(16.9282)\n",
      "Epoch: 11654; D_loss: tensor(0.0289); G_loss: tensor(18.8747)\n",
      "Epoch: 11655; D_loss: tensor(0.0018); G_loss: tensor(14.1977)\n",
      "Epoch: 11656; D_loss: tensor(0.2346); G_loss: tensor(8.5268)\n",
      "Epoch: 11657; D_loss: tensor(0.0024); G_loss: tensor(11.5322)\n",
      "Epoch: 11658; D_loss: tensor(0.0016); G_loss: tensor(12.1974)\n",
      "Epoch: 11659; D_loss: tensor(0.0298); G_loss: tensor(13.9644)\n",
      "Epoch: 11660; D_loss: tensor(0.1254); G_loss: tensor(6.4347)\n",
      "Epoch: 11661; D_loss: tensor(0.0424); G_loss: tensor(6.4869)\n",
      "Epoch: 11662; D_loss: tensor(0.0161); G_loss: tensor(9.9630)\n",
      "Epoch: 11663; D_loss: tensor(0.4574); G_loss: tensor(11.1571)\n",
      "Epoch: 11664; D_loss: tensor(0.0531); G_loss: tensor(6.8003)\n",
      "Epoch: 11665; D_loss: tensor(0.0297); G_loss: tensor(5.0223)\n",
      "Epoch: 11666; D_loss: tensor(0.0113); G_loss: tensor(8.1285)\n",
      "Epoch: 11667; D_loss: tensor(0.0135); G_loss: tensor(11.2772)\n",
      "Epoch: 11668; D_loss: tensor(0.0371); G_loss: tensor(11.1639)\n",
      "Epoch: 11669; D_loss: tensor(0.0171); G_loss: tensor(12.5140)\n",
      "Epoch: 11670; D_loss: tensor(0.0143); G_loss: tensor(10.5125)\n",
      "Epoch: 11671; D_loss: tensor(0.0010); G_loss: tensor(9.1819)\n",
      "Epoch: 11672; D_loss: tensor(0.0207); G_loss: tensor(8.4466)\n",
      "Epoch: 11673; D_loss: tensor(0.0110); G_loss: tensor(10.0541)\n",
      "Epoch: 11674; D_loss: tensor(0.0023); G_loss: tensor(9.1920)\n",
      "Epoch: 11675; D_loss: tensor(0.0080); G_loss: tensor(12.0426)\n",
      "Epoch: 11676; D_loss: tensor(0.0204); G_loss: tensor(12.3839)\n",
      "Epoch: 11677; D_loss: tensor(0.0064); G_loss: tensor(13.4369)\n",
      "Epoch: 11678; D_loss: tensor(0.0055); G_loss: tensor(12.2636)\n",
      "Epoch: 11679; D_loss: tensor(0.0042); G_loss: tensor(9.7126)\n",
      "Epoch: 11680; D_loss: tensor(0.0194); G_loss: tensor(9.8665)\n",
      "Epoch: 11681; D_loss: tensor(0.0151); G_loss: tensor(6.9472)\n",
      "Epoch: 11682; D_loss: tensor(0.0251); G_loss: tensor(9.3369)\n",
      "Epoch: 11683; D_loss: tensor(0.0359); G_loss: tensor(9.6156)\n",
      "Epoch: 11684; D_loss: tensor(0.0473); G_loss: tensor(7.4232)\n",
      "Epoch: 11685; D_loss: tensor(0.0138); G_loss: tensor(8.4582)\n",
      "Epoch: 11686; D_loss: tensor(0.0203); G_loss: tensor(9.3519)\n",
      "Epoch: 11687; D_loss: tensor(0.0369); G_loss: tensor(8.8673)\n",
      "Epoch: 11688; D_loss: tensor(0.0069); G_loss: tensor(9.8367)\n",
      "Epoch: 11689; D_loss: tensor(0.0027); G_loss: tensor(11.4195)\n",
      "Epoch: 11690; D_loss: tensor(0.0091); G_loss: tensor(9.1790)\n",
      "Epoch: 11691; D_loss: tensor(0.0124); G_loss: tensor(10.5265)\n",
      "Epoch: 11692; D_loss: tensor(0.0342); G_loss: tensor(10.6837)\n",
      "Epoch: 11693; D_loss: tensor(0.0429); G_loss: tensor(7.3298)\n",
      "Epoch: 11694; D_loss: tensor(0.0069); G_loss: tensor(13.6435)\n",
      "Epoch: 11695; D_loss: tensor(0.1388); G_loss: tensor(15.3751)\n",
      "Epoch: 11696; D_loss: tensor(0.0011); G_loss: tensor(10.3574)\n",
      "Epoch: 11697; D_loss: tensor(0.1750); G_loss: tensor(6.9408)\n",
      "Epoch: 11698; D_loss: tensor(0.0050); G_loss: tensor(12.7924)\n",
      "Epoch: 11699; D_loss: tensor(0.0029); G_loss: tensor(14.0632)\n",
      "Epoch: 11700; D_loss: tensor(0.0625); G_loss: tensor(15.3233)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11701; D_loss: tensor(0.0030); G_loss: tensor(8.8061)\n",
      "Epoch: 11702; D_loss: tensor(0.1419); G_loss: tensor(6.2901)\n",
      "Epoch: 11703; D_loss: tensor(0.0085); G_loss: tensor(9.1864)\n",
      "Epoch: 11704; D_loss: tensor(0.0644); G_loss: tensor(15.0563)\n",
      "Epoch: 11705; D_loss: tensor(0.0343); G_loss: tensor(14.1910)\n",
      "Epoch: 11706; D_loss: tensor(0.0081); G_loss: tensor(12.5526)\n",
      "Epoch: 11707; D_loss: tensor(0.0022); G_loss: tensor(10.2400)\n",
      "Epoch: 11708; D_loss: tensor(0.0088); G_loss: tensor(6.0504)\n",
      "Epoch: 11709; D_loss: tensor(0.0132); G_loss: tensor(6.2240)\n",
      "Epoch: 11710; D_loss: tensor(0.0504); G_loss: tensor(9.3331)\n",
      "Epoch: 11711; D_loss: tensor(0.0150); G_loss: tensor(12.3637)\n",
      "Epoch: 11712; D_loss: tensor(0.0057); G_loss: tensor(10.7739)\n",
      "Epoch: 11713; D_loss: tensor(0.0042); G_loss: tensor(10.6728)\n",
      "Epoch: 11714; D_loss: tensor(0.1212); G_loss: tensor(10.1843)\n",
      "Epoch: 11715; D_loss: tensor(0.0125); G_loss: tensor(7.4230)\n",
      "Epoch: 11716; D_loss: tensor(0.0193); G_loss: tensor(5.4433)\n",
      "Epoch: 11717; D_loss: tensor(0.0083); G_loss: tensor(9.1082)\n",
      "Epoch: 11718; D_loss: tensor(0.0543); G_loss: tensor(10.5260)\n",
      "Epoch: 11719; D_loss: tensor(0.0174); G_loss: tensor(8.4012)\n",
      "Epoch: 11720; D_loss: tensor(0.0098); G_loss: tensor(7.5641)\n",
      "Epoch: 11721; D_loss: tensor(0.0210); G_loss: tensor(8.6181)\n",
      "Epoch: 11722; D_loss: tensor(0.0665); G_loss: tensor(6.4217)\n",
      "Epoch: 11723; D_loss: tensor(0.3623); G_loss: tensor(9.9703)\n",
      "Epoch: 11724; D_loss: tensor(0.0637); G_loss: tensor(3.6003)\n",
      "Epoch: 11725; D_loss: tensor(0.2583); G_loss: tensor(6.3187)\n",
      "Epoch: 11726; D_loss: tensor(0.0137); G_loss: tensor(16.6176)\n",
      "Epoch: 11727; D_loss: tensor(0.0034); G_loss: tensor(7.4411)\n",
      "Epoch: 11728; D_loss: tensor(0.2710); G_loss: tensor(3.3240)\n",
      "Epoch: 11729; D_loss: tensor(0.0147); G_loss: tensor(9.5406)\n",
      "Epoch: 11730; D_loss: tensor(0.0011); G_loss: tensor(10.9660)\n",
      "Epoch: 11731; D_loss: tensor(0.0146); G_loss: tensor(8.2010)\n",
      "Epoch: 11732; D_loss: tensor(0.3522); G_loss: tensor(6.1719)\n",
      "Epoch: 11733; D_loss: tensor(0.0044); G_loss: tensor(14.0476)\n",
      "Epoch: 11734; D_loss: tensor(0.0639); G_loss: tensor(12.0337)\n",
      "Epoch: 11735; D_loss: tensor(0.0051); G_loss: tensor(7.3043)\n",
      "Epoch: 11736; D_loss: tensor(0.2164); G_loss: tensor(5.6032)\n",
      "Epoch: 11737; D_loss: tensor(0.0085); G_loss: tensor(8.3088)\n",
      "Epoch: 11738; D_loss: tensor(0.1256); G_loss: tensor(12.1640)\n",
      "Epoch: 11739; D_loss: tensor(0.0425); G_loss: tensor(9.7437)\n",
      "Epoch: 11740; D_loss: tensor(0.0371); G_loss: tensor(7.3567)\n",
      "Epoch: 11741; D_loss: tensor(0.0366); G_loss: tensor(5.5559)\n",
      "Epoch: 11742; D_loss: tensor(0.0238); G_loss: tensor(8.8160)\n",
      "Epoch: 11743; D_loss: tensor(0.0012); G_loss: tensor(7.6636)\n",
      "Epoch: 11744; D_loss: tensor(0.0885); G_loss: tensor(10.5210)\n",
      "Epoch: 11745; D_loss: tensor(0.0039); G_loss: tensor(7.9234)\n",
      "Epoch: 11746; D_loss: tensor(0.0020); G_loss: tensor(7.6770)\n",
      "Epoch: 11747; D_loss: tensor(0.0055); G_loss: tensor(7.2809)\n",
      "Epoch: 11748; D_loss: tensor(0.0029); G_loss: tensor(9.5071)\n",
      "Epoch: 11749; D_loss: tensor(0.0136); G_loss: tensor(10.4432)\n",
      "Epoch: 11750; D_loss: tensor(0.0030); G_loss: tensor(11.1743)\n",
      "Epoch: 11751; D_loss: tensor(0.0042); G_loss: tensor(10.6344)\n",
      "Epoch: 11752; D_loss: tensor(0.0314); G_loss: tensor(11.1796)\n",
      "Epoch: 11753; D_loss: tensor(0.0104); G_loss: tensor(9.0071)\n",
      "Epoch: 11754; D_loss: tensor(0.0710); G_loss: tensor(9.5127)\n",
      "Epoch: 11755; D_loss: tensor(0.0095); G_loss: tensor(9.1084)\n",
      "Epoch: 11756; D_loss: tensor(0.0165); G_loss: tensor(9.7309)\n",
      "Epoch: 11757; D_loss: tensor(0.0362); G_loss: tensor(9.7720)\n",
      "Epoch: 11758; D_loss: tensor(0.0286); G_loss: tensor(7.5733)\n",
      "Epoch: 11759; D_loss: tensor(0.0143); G_loss: tensor(8.7144)\n",
      "Epoch: 11760; D_loss: tensor(0.0858); G_loss: tensor(6.9324)\n",
      "Epoch: 11761; D_loss: tensor(0.0160); G_loss: tensor(6.5681)\n",
      "Epoch: 11762; D_loss: tensor(0.0143); G_loss: tensor(5.0717)\n",
      "Epoch: 11763; D_loss: tensor(0.0105); G_loss: tensor(8.9076)\n",
      "Epoch: 11764; D_loss: tensor(0.0073); G_loss: tensor(9.9710)\n",
      "Epoch: 11765; D_loss: tensor(0.0062); G_loss: tensor(10.7904)\n",
      "Epoch: 11766; D_loss: tensor(0.2987); G_loss: tensor(8.0655)\n",
      "Epoch: 11767; D_loss: tensor(0.0889); G_loss: tensor(5.0172)\n",
      "Epoch: 11768; D_loss: tensor(0.0086); G_loss: tensor(10.3602)\n",
      "Epoch: 11769; D_loss: tensor(0.0125); G_loss: tensor(16.2055)\n",
      "Epoch: 11770; D_loss: tensor(0.0121); G_loss: tensor(18.6077)\n",
      "Epoch: 11771; D_loss: tensor(0.0028); G_loss: tensor(13.7400)\n",
      "Epoch: 11772; D_loss: tensor(0.0023); G_loss: tensor(10.9366)\n",
      "Epoch: 11773; D_loss: tensor(0.0447); G_loss: tensor(7.4000)\n",
      "Epoch: 11774; D_loss: tensor(0.0935); G_loss: tensor(8.9233)\n",
      "Epoch: 11775; D_loss: tensor(0.0107); G_loss: tensor(12.2287)\n",
      "Epoch: 11776; D_loss: tensor(0.0115); G_loss: tensor(9.0159)\n",
      "Epoch: 11777; D_loss: tensor(0.0235); G_loss: tensor(7.8546)\n",
      "Epoch: 11778; D_loss: tensor(0.0388); G_loss: tensor(9.5719)\n",
      "Epoch: 11779; D_loss: tensor(0.0749); G_loss: tensor(6.8700)\n",
      "Epoch: 11780; D_loss: tensor(0.0124); G_loss: tensor(6.1880)\n",
      "Epoch: 11781; D_loss: tensor(0.0490); G_loss: tensor(5.4341)\n",
      "Epoch: 11782; D_loss: tensor(0.0258); G_loss: tensor(8.1097)\n",
      "Epoch: 11783; D_loss: tensor(0.0069); G_loss: tensor(10.2866)\n",
      "Epoch: 11784; D_loss: tensor(0.0074); G_loss: tensor(11.0728)\n",
      "Epoch: 11785; D_loss: tensor(0.0020); G_loss: tensor(11.1065)\n",
      "Epoch: 11786; D_loss: tensor(0.0005); G_loss: tensor(11.3455)\n",
      "Epoch: 11787; D_loss: tensor(0.0051); G_loss: tensor(10.5574)\n",
      "Epoch: 11788; D_loss: tensor(0.0049); G_loss: tensor(9.4385)\n",
      "Epoch: 11789; D_loss: tensor(0.0152); G_loss: tensor(8.9251)\n",
      "Epoch: 11790; D_loss: tensor(0.0090); G_loss: tensor(9.5212)\n",
      "Epoch: 11791; D_loss: tensor(0.0099); G_loss: tensor(7.1430)\n",
      "Epoch: 11792; D_loss: tensor(0.0427); G_loss: tensor(6.7928)\n",
      "Epoch: 11793; D_loss: tensor(0.0063); G_loss: tensor(8.4953)\n",
      "Epoch: 11794; D_loss: tensor(0.0103); G_loss: tensor(8.3049)\n",
      "Epoch: 11795; D_loss: tensor(0.0732); G_loss: tensor(9.2667)\n",
      "Epoch: 11796; D_loss: tensor(0.0118); G_loss: tensor(7.0912)\n",
      "Epoch: 11797; D_loss: tensor(0.0040); G_loss: tensor(8.3665)\n",
      "Epoch: 11798; D_loss: tensor(0.0296); G_loss: tensor(8.1963)\n",
      "Epoch: 11799; D_loss: tensor(0.0113); G_loss: tensor(8.4630)\n",
      "Epoch: 11800; D_loss: tensor(0.0053); G_loss: tensor(8.0047)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11801; D_loss: tensor(0.0124); G_loss: tensor(10.4316)\n",
      "Epoch: 11802; D_loss: tensor(0.0071); G_loss: tensor(9.8061)\n",
      "Epoch: 11803; D_loss: tensor(0.0185); G_loss: tensor(6.8946)\n",
      "Epoch: 11804; D_loss: tensor(0.0653); G_loss: tensor(7.4659)\n",
      "Epoch: 11805; D_loss: tensor(0.0103); G_loss: tensor(7.5647)\n",
      "Epoch: 11806; D_loss: tensor(0.0466); G_loss: tensor(9.3210)\n",
      "Epoch: 11807; D_loss: tensor(0.0081); G_loss: tensor(6.9943)\n",
      "Epoch: 11808; D_loss: tensor(0.0100); G_loss: tensor(6.6391)\n",
      "Epoch: 11809; D_loss: tensor(0.0083); G_loss: tensor(7.6802)\n",
      "Epoch: 11810; D_loss: tensor(0.0133); G_loss: tensor(9.2444)\n",
      "Epoch: 11811; D_loss: tensor(0.0130); G_loss: tensor(9.7930)\n",
      "Epoch: 11812; D_loss: tensor(0.0086); G_loss: tensor(6.7984)\n",
      "Epoch: 11813; D_loss: tensor(0.0076); G_loss: tensor(7.9129)\n",
      "Epoch: 11814; D_loss: tensor(0.0109); G_loss: tensor(5.6326)\n",
      "Epoch: 11815; D_loss: tensor(0.0081); G_loss: tensor(6.9404)\n",
      "Epoch: 11816; D_loss: tensor(0.0048); G_loss: tensor(5.9534)\n",
      "Epoch: 11817; D_loss: tensor(0.0176); G_loss: tensor(6.6255)\n",
      "Epoch: 11818; D_loss: tensor(0.0180); G_loss: tensor(9.3928)\n",
      "Epoch: 11819; D_loss: tensor(0.0481); G_loss: tensor(9.4033)\n",
      "Epoch: 11820; D_loss: tensor(0.0049); G_loss: tensor(10.2783)\n",
      "Epoch: 11821; D_loss: tensor(0.0205); G_loss: tensor(7.7181)\n",
      "Epoch: 11822; D_loss: tensor(0.0096); G_loss: tensor(8.9604)\n",
      "Epoch: 11823; D_loss: tensor(0.0026); G_loss: tensor(9.1911)\n",
      "Epoch: 11824; D_loss: tensor(0.0054); G_loss: tensor(9.2413)\n",
      "Epoch: 11825; D_loss: tensor(0.0133); G_loss: tensor(10.1538)\n",
      "Epoch: 11826; D_loss: tensor(0.0092); G_loss: tensor(9.2951)\n",
      "Epoch: 11827; D_loss: tensor(0.0131); G_loss: tensor(9.4637)\n",
      "Epoch: 11828; D_loss: tensor(0.0163); G_loss: tensor(8.2662)\n",
      "Epoch: 11829; D_loss: tensor(0.1112); G_loss: tensor(10.0071)\n",
      "Epoch: 11830; D_loss: tensor(0.0173); G_loss: tensor(5.2271)\n",
      "Epoch: 11831; D_loss: tensor(0.4727); G_loss: tensor(13.5952)\n",
      "Epoch: 11832; D_loss: tensor(0.0485); G_loss: tensor(6.8679)\n",
      "Epoch: 11833; D_loss: tensor(0.0153); G_loss: tensor(4.3615)\n",
      "Epoch: 11834; D_loss: tensor(0.0240); G_loss: tensor(8.1295)\n",
      "Epoch: 11835; D_loss: tensor(0.0223); G_loss: tensor(7.8783)\n",
      "Epoch: 11836; D_loss: tensor(0.0050); G_loss: tensor(11.4199)\n",
      "Epoch: 11837; D_loss: tensor(0.0190); G_loss: tensor(10.6635)\n",
      "Epoch: 11838; D_loss: tensor(0.0091); G_loss: tensor(11.9038)\n",
      "Epoch: 11839; D_loss: tensor(0.0059); G_loss: tensor(11.5489)\n",
      "Epoch: 11840; D_loss: tensor(0.0765); G_loss: tensor(9.8094)\n",
      "Epoch: 11841; D_loss: tensor(0.0383); G_loss: tensor(8.4933)\n",
      "Epoch: 11842; D_loss: tensor(0.0073); G_loss: tensor(10.2264)\n",
      "Epoch: 11843; D_loss: tensor(0.0128); G_loss: tensor(6.9543)\n",
      "Epoch: 11844; D_loss: tensor(0.0426); G_loss: tensor(8.2447)\n",
      "Epoch: 11845; D_loss: tensor(0.0213); G_loss: tensor(10.0584)\n",
      "Epoch: 11846; D_loss: tensor(0.0178); G_loss: tensor(9.5685)\n",
      "Epoch: 11847; D_loss: tensor(0.1135); G_loss: tensor(7.0390)\n",
      "Epoch: 11848; D_loss: tensor(0.0076); G_loss: tensor(5.6114)\n",
      "Epoch: 11849; D_loss: tensor(0.0111); G_loss: tensor(6.9400)\n",
      "Epoch: 11850; D_loss: tensor(0.0286); G_loss: tensor(10.0860)\n",
      "Epoch: 11851; D_loss: tensor(0.0383); G_loss: tensor(8.0748)\n",
      "Epoch: 11852; D_loss: tensor(0.0801); G_loss: tensor(3.8903)\n",
      "Epoch: 11853; D_loss: tensor(0.0044); G_loss: tensor(12.7419)\n",
      "Epoch: 11854; D_loss: tensor(0.0435); G_loss: tensor(7.1870)\n",
      "Epoch: 11855; D_loss: tensor(0.0191); G_loss: tensor(4.9900)\n",
      "Epoch: 11856; D_loss: tensor(0.0289); G_loss: tensor(7.0682)\n",
      "Epoch: 11857; D_loss: tensor(0.0135); G_loss: tensor(8.7491)\n",
      "Epoch: 11858; D_loss: tensor(0.0840); G_loss: tensor(9.6855)\n",
      "Epoch: 11859; D_loss: tensor(0.0030); G_loss: tensor(5.8287)\n",
      "Epoch: 11860; D_loss: tensor(0.0337); G_loss: tensor(5.4565)\n",
      "Epoch: 11861; D_loss: tensor(0.0225); G_loss: tensor(11.0311)\n",
      "Epoch: 11862; D_loss: tensor(0.0049); G_loss: tensor(12.9785)\n",
      "Epoch: 11863; D_loss: tensor(0.1392); G_loss: tensor(13.1778)\n",
      "Epoch: 11864; D_loss: tensor(0.0153); G_loss: tensor(8.5446)\n",
      "Epoch: 11865; D_loss: tensor(0.0367); G_loss: tensor(5.6179)\n",
      "Epoch: 11866; D_loss: tensor(0.0074); G_loss: tensor(9.3331)\n",
      "Epoch: 11867; D_loss: tensor(0.0048); G_loss: tensor(10.4554)\n",
      "Epoch: 11868; D_loss: tensor(0.0212); G_loss: tensor(11.2840)\n",
      "Epoch: 11869; D_loss: tensor(0.0127); G_loss: tensor(10.2135)\n",
      "Epoch: 11870; D_loss: tensor(0.0084); G_loss: tensor(10.0740)\n",
      "Epoch: 11871; D_loss: tensor(0.0136); G_loss: tensor(7.6485)\n",
      "Epoch: 11872; D_loss: tensor(0.0421); G_loss: tensor(5.1492)\n",
      "Epoch: 11873; D_loss: tensor(0.0096); G_loss: tensor(8.3835)\n",
      "Epoch: 11874; D_loss: tensor(0.0062); G_loss: tensor(9.2932)\n",
      "Epoch: 11875; D_loss: tensor(0.0105); G_loss: tensor(7.8086)\n",
      "Epoch: 11876; D_loss: tensor(0.0086); G_loss: tensor(7.4301)\n",
      "Epoch: 11877; D_loss: tensor(0.0120); G_loss: tensor(10.7765)\n",
      "Epoch: 11878; D_loss: tensor(0.0589); G_loss: tensor(11.7322)\n",
      "Epoch: 11879; D_loss: tensor(0.0126); G_loss: tensor(9.4197)\n",
      "Epoch: 11880; D_loss: tensor(0.0101); G_loss: tensor(8.6805)\n",
      "Epoch: 11881; D_loss: tensor(0.0051); G_loss: tensor(4.1670)\n",
      "Epoch: 11882; D_loss: tensor(0.0033); G_loss: tensor(9.4071)\n",
      "Epoch: 11883; D_loss: tensor(0.0141); G_loss: tensor(9.7208)\n",
      "Epoch: 11884; D_loss: tensor(0.0723); G_loss: tensor(7.8935)\n",
      "Epoch: 11885; D_loss: tensor(0.0068); G_loss: tensor(6.0014)\n",
      "Epoch: 11886; D_loss: tensor(0.0093); G_loss: tensor(8.2763)\n",
      "Epoch: 11887; D_loss: tensor(0.0375); G_loss: tensor(13.7752)\n",
      "Epoch: 11888; D_loss: tensor(0.0031); G_loss: tensor(11.1930)\n",
      "Epoch: 11889; D_loss: tensor(0.0072); G_loss: tensor(6.3872)\n",
      "Epoch: 11890; D_loss: tensor(0.0060); G_loss: tensor(6.2919)\n",
      "Epoch: 11891; D_loss: tensor(0.0524); G_loss: tensor(8.4656)\n",
      "Epoch: 11892; D_loss: tensor(0.0313); G_loss: tensor(9.5530)\n",
      "Epoch: 11893; D_loss: tensor(0.0279); G_loss: tensor(5.4017)\n",
      "Epoch: 11894; D_loss: tensor(0.0160); G_loss: tensor(5.5157)\n",
      "Epoch: 11895; D_loss: tensor(0.0200); G_loss: tensor(8.1211)\n",
      "Epoch: 11896; D_loss: tensor(0.0021); G_loss: tensor(9.6149)\n",
      "Epoch: 11897; D_loss: tensor(0.0085); G_loss: tensor(10.7109)\n",
      "Epoch: 11898; D_loss: tensor(0.0159); G_loss: tensor(10.2318)\n",
      "Epoch: 11899; D_loss: tensor(0.0224); G_loss: tensor(5.0561)\n",
      "Epoch: 11900; D_loss: tensor(0.0148); G_loss: tensor(9.8926)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11901; D_loss: tensor(0.0375); G_loss: tensor(8.4508)\n",
      "Epoch: 11902; D_loss: tensor(0.0036); G_loss: tensor(7.3766)\n",
      "Epoch: 11903; D_loss: tensor(0.0393); G_loss: tensor(9.5307)\n",
      "Epoch: 11904; D_loss: tensor(0.0425); G_loss: tensor(8.7227)\n",
      "Epoch: 11905; D_loss: tensor(0.0127); G_loss: tensor(6.2816)\n",
      "Epoch: 11906; D_loss: tensor(0.0216); G_loss: tensor(9.7104)\n",
      "Epoch: 11907; D_loss: tensor(0.3080); G_loss: tensor(11.7643)\n",
      "Epoch: 11908; D_loss: tensor(0.0440); G_loss: tensor(4.3898)\n",
      "Epoch: 11909; D_loss: tensor(0.0719); G_loss: tensor(13.2552)\n",
      "Epoch: 11910; D_loss: tensor(0.2587); G_loss: tensor(3.1829)\n",
      "Epoch: 11911; D_loss: tensor(0.0089); G_loss: tensor(10.2501)\n",
      "Epoch: 11912; D_loss: tensor(0.1992); G_loss: tensor(17.3187)\n",
      "Epoch: 11913; D_loss: tensor(0.0784); G_loss: tensor(10.8446)\n",
      "Epoch: 11914; D_loss: tensor(0.0133); G_loss: tensor(8.6714)\n",
      "Epoch: 11915; D_loss: tensor(0.0155); G_loss: tensor(6.5731)\n",
      "Epoch: 11916; D_loss: tensor(0.0057); G_loss: tensor(12.3469)\n",
      "Epoch: 11917; D_loss: tensor(0.0745); G_loss: tensor(14.2474)\n",
      "Epoch: 11918; D_loss: tensor(0.0098); G_loss: tensor(5.0775)\n",
      "Epoch: 11919; D_loss: tensor(0.5487); G_loss: tensor(6.3018)\n",
      "Epoch: 11920; D_loss: tensor(0.1205); G_loss: tensor(16.1976)\n",
      "Epoch: 11921; D_loss: tensor(0.2286); G_loss: tensor(14.1137)\n",
      "Epoch: 11922; D_loss: tensor(0.0678); G_loss: tensor(7.1761)\n",
      "Epoch: 11923; D_loss: tensor(0.0903); G_loss: tensor(11.1556)\n",
      "Epoch: 11924; D_loss: tensor(0.0008); G_loss: tensor(9.8212)\n",
      "Epoch: 11925; D_loss: tensor(0.0092); G_loss: tensor(8.3441)\n",
      "Epoch: 11926; D_loss: tensor(0.0151); G_loss: tensor(14.2365)\n",
      "Epoch: 11927; D_loss: tensor(0.0086); G_loss: tensor(12.4319)\n",
      "Epoch: 11928; D_loss: tensor(0.0030); G_loss: tensor(11.0258)\n",
      "Epoch: 11929; D_loss: tensor(1.1264); G_loss: tensor(4.0439)\n",
      "Epoch: 11930; D_loss: tensor(0.3113); G_loss: tensor(6.9392)\n",
      "Epoch: 11931; D_loss: tensor(0.0009); G_loss: tensor(14.7356)\n",
      "Epoch: 11932; D_loss: tensor(0.0165); G_loss: tensor(13.5430)\n",
      "Epoch: 11933; D_loss: tensor(0.0913); G_loss: tensor(12.6309)\n",
      "Epoch: 11934; D_loss: tensor(0.0165); G_loss: tensor(10.9533)\n",
      "Epoch: 11935; D_loss: tensor(0.0108); G_loss: tensor(12.9815)\n",
      "Epoch: 11936; D_loss: tensor(0.0212); G_loss: tensor(6.8629)\n",
      "Epoch: 11937; D_loss: tensor(0.0872); G_loss: tensor(7.8743)\n",
      "Epoch: 11938; D_loss: tensor(0.0257); G_loss: tensor(9.7773)\n",
      "Epoch: 11939; D_loss: tensor(0.0591); G_loss: tensor(12.6074)\n",
      "Epoch: 11940; D_loss: tensor(0.0648); G_loss: tensor(9.4896)\n",
      "Epoch: 11941; D_loss: tensor(0.0127); G_loss: tensor(7.6126)\n",
      "Epoch: 11942; D_loss: tensor(0.0057); G_loss: tensor(8.7864)\n",
      "Epoch: 11943; D_loss: tensor(0.0128); G_loss: tensor(8.6824)\n",
      "Epoch: 11944; D_loss: tensor(0.0013); G_loss: tensor(8.9743)\n",
      "Epoch: 11945; D_loss: tensor(0.0060); G_loss: tensor(11.8088)\n",
      "Epoch: 11946; D_loss: tensor(0.0620); G_loss: tensor(13.3142)\n",
      "Epoch: 11947; D_loss: tensor(0.0032); G_loss: tensor(13.1584)\n",
      "Epoch: 11948; D_loss: tensor(0.0045); G_loss: tensor(8.4822)\n",
      "Epoch: 11949; D_loss: tensor(0.0112); G_loss: tensor(10.1653)\n",
      "Epoch: 11950; D_loss: tensor(0.0230); G_loss: tensor(10.4834)\n",
      "Epoch: 11951; D_loss: tensor(0.0471); G_loss: tensor(9.4663)\n",
      "Epoch: 11952; D_loss: tensor(0.0104); G_loss: tensor(9.2521)\n",
      "Epoch: 11953; D_loss: tensor(0.0031); G_loss: tensor(8.9551)\n",
      "Epoch: 11954; D_loss: tensor(0.0908); G_loss: tensor(8.2538)\n",
      "Epoch: 11955; D_loss: tensor(0.0074); G_loss: tensor(6.7023)\n",
      "Epoch: 11956; D_loss: tensor(0.0596); G_loss: tensor(9.9849)\n",
      "Epoch: 11957; D_loss: tensor(0.0216); G_loss: tensor(9.5839)\n",
      "Epoch: 11958; D_loss: tensor(0.0047); G_loss: tensor(7.5584)\n",
      "Epoch: 11959; D_loss: tensor(0.0141); G_loss: tensor(9.2689)\n",
      "Epoch: 11960; D_loss: tensor(0.0777); G_loss: tensor(10.0005)\n",
      "Epoch: 11961; D_loss: tensor(0.0006); G_loss: tensor(10.3761)\n",
      "Epoch: 11962; D_loss: tensor(0.0039); G_loss: tensor(6.6183)\n",
      "Epoch: 11963; D_loss: tensor(0.0324); G_loss: tensor(7.9834)\n",
      "Epoch: 11964; D_loss: tensor(0.0054); G_loss: tensor(8.5081)\n",
      "Epoch: 11965; D_loss: tensor(0.0010); G_loss: tensor(11.4528)\n",
      "Epoch: 11966; D_loss: tensor(0.0117); G_loss: tensor(9.9914)\n",
      "Epoch: 11967; D_loss: tensor(0.0216); G_loss: tensor(6.2116)\n",
      "Epoch: 11968; D_loss: tensor(0.0610); G_loss: tensor(5.2064)\n",
      "Epoch: 11969; D_loss: tensor(0.0226); G_loss: tensor(9.4259)\n",
      "Epoch: 11970; D_loss: tensor(0.0408); G_loss: tensor(11.0313)\n",
      "Epoch: 11971; D_loss: tensor(0.0646); G_loss: tensor(10.4710)\n",
      "Epoch: 11972; D_loss: tensor(0.0114); G_loss: tensor(5.4629)\n",
      "Epoch: 11973; D_loss: tensor(0.0137); G_loss: tensor(7.8421)\n",
      "Epoch: 11974; D_loss: tensor(0.0518); G_loss: tensor(8.3915)\n",
      "Epoch: 11975; D_loss: tensor(0.0710); G_loss: tensor(9.2369)\n",
      "Epoch: 11976; D_loss: tensor(0.0070); G_loss: tensor(7.1051)\n",
      "Epoch: 11977; D_loss: tensor(0.0033); G_loss: tensor(6.0477)\n",
      "Epoch: 11978; D_loss: tensor(0.0199); G_loss: tensor(7.0220)\n",
      "Epoch: 11979; D_loss: tensor(0.0068); G_loss: tensor(7.4527)\n",
      "Epoch: 11980; D_loss: tensor(0.0071); G_loss: tensor(8.4789)\n",
      "Epoch: 11981; D_loss: tensor(0.0010); G_loss: tensor(9.0415)\n",
      "Epoch: 11982; D_loss: tensor(0.0135); G_loss: tensor(10.4848)\n",
      "Epoch: 11983; D_loss: tensor(0.0109); G_loss: tensor(9.1857)\n",
      "Epoch: 11984; D_loss: tensor(0.0033); G_loss: tensor(7.7608)\n",
      "Epoch: 11985; D_loss: tensor(0.0354); G_loss: tensor(8.0078)\n",
      "Epoch: 11986; D_loss: tensor(0.0029); G_loss: tensor(9.0386)\n",
      "Epoch: 11987; D_loss: tensor(0.0409); G_loss: tensor(6.5109)\n",
      "Epoch: 11988; D_loss: tensor(0.0087); G_loss: tensor(9.1241)\n",
      "Epoch: 11989; D_loss: tensor(0.0268); G_loss: tensor(5.4258)\n",
      "Epoch: 11990; D_loss: tensor(0.0433); G_loss: tensor(7.6592)\n",
      "Epoch: 11991; D_loss: tensor(0.0225); G_loss: tensor(10.7678)\n",
      "Epoch: 11992; D_loss: tensor(0.0128); G_loss: tensor(9.2142)\n",
      "Epoch: 11993; D_loss: tensor(0.0088); G_loss: tensor(4.2155)\n",
      "Epoch: 11994; D_loss: tensor(0.0143); G_loss: tensor(8.9111)\n",
      "Epoch: 11995; D_loss: tensor(0.0031); G_loss: tensor(7.1250)\n",
      "Epoch: 11996; D_loss: tensor(0.0054); G_loss: tensor(5.3327)\n",
      "Epoch: 11997; D_loss: tensor(0.0315); G_loss: tensor(9.5396)\n",
      "Epoch: 11998; D_loss: tensor(0.0274); G_loss: tensor(6.1778)\n",
      "Epoch: 11999; D_loss: tensor(0.0058); G_loss: tensor(7.1810)\n",
      "Epoch: 12000; D_loss: tensor(0.0496); G_loss: tensor(7.4112)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12001; D_loss: tensor(0.0109); G_loss: tensor(9.8427)\n",
      "Epoch: 12002; D_loss: tensor(0.0502); G_loss: tensor(10.0899)\n",
      "Epoch: 12003; D_loss: tensor(1.4164); G_loss: tensor(7.4318)\n",
      "Epoch: 12004; D_loss: tensor(0.3775); G_loss: tensor(11.9374)\n",
      "Epoch: 12005; D_loss: tensor(0.0202); G_loss: tensor(2.5022)\n",
      "Epoch: 12006; D_loss: tensor(1.7572); G_loss: tensor(6.5166)\n",
      "Epoch: 12007; D_loss: tensor(3.2843); G_loss: tensor(12.8543)\n",
      "Epoch: 12008; D_loss: tensor(0.1965); G_loss: tensor(3.4103)\n",
      "Epoch: 12009; D_loss: tensor(0.0280); G_loss: tensor(12.6612)\n",
      "Epoch: 12010; D_loss: tensor(0.0569); G_loss: tensor(7.0136)\n",
      "Epoch: 12011; D_loss: tensor(0.0824); G_loss: tensor(2.9649)\n",
      "Epoch: 12012; D_loss: tensor(0.0151); G_loss: tensor(7.9717)\n",
      "Epoch: 12013; D_loss: tensor(0.0773); G_loss: tensor(11.9701)\n",
      "Epoch: 12014; D_loss: tensor(0.1310); G_loss: tensor(10.0486)\n",
      "Epoch: 12015; D_loss: tensor(0.0358); G_loss: tensor(7.8915)\n",
      "Epoch: 12016; D_loss: tensor(0.0719); G_loss: tensor(5.9712)\n",
      "Epoch: 12017; D_loss: tensor(0.0253); G_loss: tensor(5.6483)\n",
      "Epoch: 12018; D_loss: tensor(0.0113); G_loss: tensor(9.2616)\n",
      "Epoch: 12019; D_loss: tensor(0.0119); G_loss: tensor(7.5636)\n",
      "Epoch: 12020; D_loss: tensor(0.1307); G_loss: tensor(7.9874)\n",
      "Epoch: 12021; D_loss: tensor(0.0212); G_loss: tensor(8.0936)\n",
      "Epoch: 12022; D_loss: tensor(0.0182); G_loss: tensor(9.7498)\n",
      "Epoch: 12023; D_loss: tensor(0.0559); G_loss: tensor(8.6500)\n",
      "Epoch: 12024; D_loss: tensor(0.1113); G_loss: tensor(11.7645)\n",
      "Epoch: 12025; D_loss: tensor(0.3360); G_loss: tensor(2.6508)\n",
      "Epoch: 12026; D_loss: tensor(0.0244); G_loss: tensor(10.1523)\n",
      "Epoch: 12027; D_loss: tensor(0.1092); G_loss: tensor(15.5715)\n",
      "Epoch: 12028; D_loss: tensor(0.0155); G_loss: tensor(4.1301)\n",
      "Epoch: 12029; D_loss: tensor(0.5506); G_loss: tensor(3.9454)\n",
      "Epoch: 12030; D_loss: tensor(0.0600); G_loss: tensor(14.0534)\n",
      "Epoch: 12031; D_loss: tensor(0.0252); G_loss: tensor(10.5737)\n",
      "Epoch: 12032; D_loss: tensor(0.0164); G_loss: tensor(6.5637)\n",
      "Epoch: 12033; D_loss: tensor(0.0654); G_loss: tensor(11.1126)\n",
      "Epoch: 12034; D_loss: tensor(0.2240); G_loss: tensor(12.0149)\n",
      "Epoch: 12035; D_loss: tensor(0.0171); G_loss: tensor(11.0700)\n",
      "Epoch: 12036; D_loss: tensor(0.0077); G_loss: tensor(11.1744)\n",
      "Epoch: 12037; D_loss: tensor(0.0156); G_loss: tensor(9.6794)\n",
      "Epoch: 12038; D_loss: tensor(0.0178); G_loss: tensor(6.0813)\n",
      "Epoch: 12039; D_loss: tensor(0.0040); G_loss: tensor(11.0607)\n",
      "Epoch: 12040; D_loss: tensor(0.1063); G_loss: tensor(23.0905)\n",
      "Epoch: 12041; D_loss: tensor(0.0192); G_loss: tensor(9.1284)\n",
      "Epoch: 12042; D_loss: tensor(0.0133); G_loss: tensor(8.6148)\n",
      "Epoch: 12043; D_loss: tensor(0.0086); G_loss: tensor(11.2208)\n",
      "Epoch: 12044; D_loss: tensor(0.0164); G_loss: tensor(10.7755)\n",
      "Epoch: 12045; D_loss: tensor(0.0284); G_loss: tensor(11.2652)\n",
      "Epoch: 12046; D_loss: tensor(0.0066); G_loss: tensor(11.2260)\n",
      "Epoch: 12047; D_loss: tensor(0.0474); G_loss: tensor(9.7772)\n",
      "Epoch: 12048; D_loss: tensor(0.0356); G_loss: tensor(9.4591)\n",
      "Epoch: 12049; D_loss: tensor(0.0190); G_loss: tensor(8.9213)\n",
      "Epoch: 12050; D_loss: tensor(0.0081); G_loss: tensor(8.8097)\n",
      "Epoch: 12051; D_loss: tensor(0.0245); G_loss: tensor(11.4960)\n",
      "Epoch: 12052; D_loss: tensor(0.1447); G_loss: tensor(7.2274)\n",
      "Epoch: 12053; D_loss: tensor(0.1145); G_loss: tensor(9.0703)\n",
      "Epoch: 12054; D_loss: tensor(0.0077); G_loss: tensor(7.9506)\n",
      "Epoch: 12055; D_loss: tensor(0.1261); G_loss: tensor(6.3081)\n",
      "Epoch: 12056; D_loss: tensor(0.0160); G_loss: tensor(7.2670)\n",
      "Epoch: 12057; D_loss: tensor(0.1541); G_loss: tensor(5.8056)\n",
      "Epoch: 12058; D_loss: tensor(0.0502); G_loss: tensor(7.9468)\n",
      "Epoch: 12059; D_loss: tensor(0.0163); G_loss: tensor(8.2328)\n",
      "Epoch: 12060; D_loss: tensor(0.0020); G_loss: tensor(13.7640)\n",
      "Epoch: 12061; D_loss: tensor(0.0094); G_loss: tensor(11.7918)\n",
      "Epoch: 12062; D_loss: tensor(0.0030); G_loss: tensor(6.7026)\n",
      "Epoch: 12063; D_loss: tensor(0.2094); G_loss: tensor(6.1779)\n",
      "Epoch: 12064; D_loss: tensor(0.0279); G_loss: tensor(12.4679)\n",
      "Epoch: 12065; D_loss: tensor(0.1404); G_loss: tensor(11.0794)\n",
      "Epoch: 12066; D_loss: tensor(0.0152); G_loss: tensor(6.0417)\n",
      "Epoch: 12067; D_loss: tensor(0.0751); G_loss: tensor(6.5887)\n",
      "Epoch: 12068; D_loss: tensor(0.0143); G_loss: tensor(8.2125)\n",
      "Epoch: 12069; D_loss: tensor(0.0515); G_loss: tensor(8.7505)\n",
      "Epoch: 12070; D_loss: tensor(0.0086); G_loss: tensor(9.4516)\n",
      "Epoch: 12071; D_loss: tensor(0.0179); G_loss: tensor(11.7057)\n",
      "Epoch: 12072; D_loss: tensor(0.0260); G_loss: tensor(10.3152)\n",
      "Epoch: 12073; D_loss: tensor(0.0132); G_loss: tensor(10.0341)\n",
      "Epoch: 12074; D_loss: tensor(0.0281); G_loss: tensor(6.9517)\n",
      "Epoch: 12075; D_loss: tensor(0.0308); G_loss: tensor(6.1639)\n",
      "Epoch: 12076; D_loss: tensor(0.0150); G_loss: tensor(9.5146)\n",
      "Epoch: 12077; D_loss: tensor(0.0072); G_loss: tensor(7.0233)\n",
      "Epoch: 12078; D_loss: tensor(0.0030); G_loss: tensor(9.7291)\n",
      "Epoch: 12079; D_loss: tensor(0.0023); G_loss: tensor(7.7094)\n",
      "Epoch: 12080; D_loss: tensor(0.0198); G_loss: tensor(7.7780)\n",
      "Epoch: 12081; D_loss: tensor(0.0600); G_loss: tensor(7.4875)\n",
      "Epoch: 12082; D_loss: tensor(0.0359); G_loss: tensor(8.5064)\n",
      "Epoch: 12083; D_loss: tensor(0.0065); G_loss: tensor(7.9799)\n",
      "Epoch: 12084; D_loss: tensor(0.0295); G_loss: tensor(8.1465)\n",
      "Epoch: 12085; D_loss: tensor(0.0016); G_loss: tensor(7.9133)\n",
      "Epoch: 12086; D_loss: tensor(0.0061); G_loss: tensor(5.6638)\n",
      "Epoch: 12087; D_loss: tensor(0.0464); G_loss: tensor(8.7509)\n",
      "Epoch: 12088; D_loss: tensor(0.0187); G_loss: tensor(6.9228)\n",
      "Epoch: 12089; D_loss: tensor(0.0204); G_loss: tensor(6.5287)\n",
      "Epoch: 12090; D_loss: tensor(0.0247); G_loss: tensor(8.4197)\n",
      "Epoch: 12091; D_loss: tensor(0.0145); G_loss: tensor(6.6711)\n",
      "Epoch: 12092; D_loss: tensor(0.0389); G_loss: tensor(7.7241)\n",
      "Epoch: 12093; D_loss: tensor(0.0075); G_loss: tensor(9.0630)\n",
      "Epoch: 12094; D_loss: tensor(0.0155); G_loss: tensor(7.5472)\n",
      "Epoch: 12095; D_loss: tensor(0.0056); G_loss: tensor(6.6625)\n",
      "Epoch: 12096; D_loss: tensor(0.0381); G_loss: tensor(7.6454)\n",
      "Epoch: 12097; D_loss: tensor(0.0122); G_loss: tensor(7.3387)\n",
      "Epoch: 12098; D_loss: tensor(0.0379); G_loss: tensor(9.9958)\n",
      "Epoch: 12099; D_loss: tensor(0.0272); G_loss: tensor(8.3522)\n",
      "Epoch: 12100; D_loss: tensor(0.0282); G_loss: tensor(6.4030)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12101; D_loss: tensor(0.0029); G_loss: tensor(7.8702)\n",
      "Epoch: 12102; D_loss: tensor(0.0105); G_loss: tensor(7.0630)\n",
      "Epoch: 12103; D_loss: tensor(0.0078); G_loss: tensor(8.8771)\n",
      "Epoch: 12104; D_loss: tensor(0.0126); G_loss: tensor(10.3407)\n",
      "Epoch: 12105; D_loss: tensor(0.0119); G_loss: tensor(7.4804)\n",
      "Epoch: 12106; D_loss: tensor(0.0042); G_loss: tensor(8.0457)\n",
      "Epoch: 12107; D_loss: tensor(0.0195); G_loss: tensor(8.4042)\n",
      "Epoch: 12108; D_loss: tensor(0.0122); G_loss: tensor(5.2954)\n",
      "Epoch: 12109; D_loss: tensor(0.0042); G_loss: tensor(7.6507)\n",
      "Epoch: 12110; D_loss: tensor(0.0060); G_loss: tensor(6.8392)\n",
      "Epoch: 12111; D_loss: tensor(0.0244); G_loss: tensor(9.7298)\n",
      "Epoch: 12112; D_loss: tensor(0.0123); G_loss: tensor(9.7541)\n",
      "Epoch: 12113; D_loss: tensor(0.0046); G_loss: tensor(5.9838)\n",
      "Epoch: 12114; D_loss: tensor(0.0348); G_loss: tensor(5.3131)\n",
      "Epoch: 12115; D_loss: tensor(0.0257); G_loss: tensor(6.1117)\n",
      "Epoch: 12116; D_loss: tensor(0.0742); G_loss: tensor(5.8518)\n",
      "Epoch: 12117; D_loss: tensor(0.0725); G_loss: tensor(6.2602)\n",
      "Epoch: 12118; D_loss: tensor(0.0181); G_loss: tensor(8.9949)\n",
      "Epoch: 12119; D_loss: tensor(0.0390); G_loss: tensor(5.7521)\n",
      "Epoch: 12120; D_loss: tensor(0.0814); G_loss: tensor(4.9701)\n",
      "Epoch: 12121; D_loss: tensor(0.0226); G_loss: tensor(9.7104)\n",
      "Epoch: 12122; D_loss: tensor(0.0281); G_loss: tensor(8.3741)\n",
      "Epoch: 12123; D_loss: tensor(0.0172); G_loss: tensor(7.4049)\n",
      "Epoch: 12124; D_loss: tensor(0.0183); G_loss: tensor(7.1543)\n",
      "Epoch: 12125; D_loss: tensor(0.0308); G_loss: tensor(8.2817)\n",
      "Epoch: 12126; D_loss: tensor(0.0461); G_loss: tensor(7.4269)\n",
      "Epoch: 12127; D_loss: tensor(0.0470); G_loss: tensor(6.2556)\n",
      "Epoch: 12128; D_loss: tensor(0.0133); G_loss: tensor(7.0425)\n",
      "Epoch: 12129; D_loss: tensor(0.0218); G_loss: tensor(7.4868)\n",
      "Epoch: 12130; D_loss: tensor(0.0135); G_loss: tensor(7.9604)\n",
      "Epoch: 12131; D_loss: tensor(0.0632); G_loss: tensor(8.6114)\n",
      "Epoch: 12132; D_loss: tensor(0.0262); G_loss: tensor(5.5011)\n",
      "Epoch: 12133; D_loss: tensor(0.0356); G_loss: tensor(5.8350)\n",
      "Epoch: 12134; D_loss: tensor(0.0370); G_loss: tensor(5.8622)\n",
      "Epoch: 12135; D_loss: tensor(0.0081); G_loss: tensor(8.7480)\n",
      "Epoch: 12136; D_loss: tensor(0.0190); G_loss: tensor(7.3038)\n",
      "Epoch: 12137; D_loss: tensor(0.0094); G_loss: tensor(5.7962)\n",
      "Epoch: 12138; D_loss: tensor(0.0275); G_loss: tensor(5.4098)\n",
      "Epoch: 12139; D_loss: tensor(0.0128); G_loss: tensor(6.6004)\n",
      "Epoch: 12140; D_loss: tensor(0.0228); G_loss: tensor(8.4723)\n",
      "Epoch: 12141; D_loss: tensor(0.1745); G_loss: tensor(9.8819)\n",
      "Epoch: 12142; D_loss: tensor(0.0121); G_loss: tensor(5.0139)\n",
      "Epoch: 12143; D_loss: tensor(0.1888); G_loss: tensor(6.0798)\n",
      "Epoch: 12144; D_loss: tensor(0.0484); G_loss: tensor(8.6010)\n",
      "Epoch: 12145; D_loss: tensor(0.0583); G_loss: tensor(10.3393)\n",
      "Epoch: 12146; D_loss: tensor(0.0140); G_loss: tensor(4.9807)\n",
      "Epoch: 12147; D_loss: tensor(0.1861); G_loss: tensor(5.9454)\n",
      "Epoch: 12148; D_loss: tensor(0.0085); G_loss: tensor(10.9967)\n",
      "Epoch: 12149; D_loss: tensor(0.0121); G_loss: tensor(11.4109)\n",
      "Epoch: 12150; D_loss: tensor(0.0036); G_loss: tensor(8.4842)\n",
      "Epoch: 12151; D_loss: tensor(0.0170); G_loss: tensor(5.4097)\n",
      "Epoch: 12152; D_loss: tensor(0.0133); G_loss: tensor(10.6156)\n",
      "Epoch: 12153; D_loss: tensor(0.0035); G_loss: tensor(11.4424)\n",
      "Epoch: 12154; D_loss: tensor(0.0060); G_loss: tensor(10.1772)\n",
      "Epoch: 12155; D_loss: tensor(0.0170); G_loss: tensor(10.1110)\n",
      "Epoch: 12156; D_loss: tensor(0.0190); G_loss: tensor(9.0230)\n",
      "Epoch: 12157; D_loss: tensor(0.0354); G_loss: tensor(5.3996)\n",
      "Epoch: 12158; D_loss: tensor(0.0722); G_loss: tensor(9.9213)\n",
      "Epoch: 12159; D_loss: tensor(0.0300); G_loss: tensor(9.4785)\n",
      "Epoch: 12160; D_loss: tensor(0.0721); G_loss: tensor(8.5468)\n",
      "Epoch: 12161; D_loss: tensor(0.0342); G_loss: tensor(7.0281)\n",
      "Epoch: 12162; D_loss: tensor(0.0551); G_loss: tensor(7.3409)\n",
      "Epoch: 12163; D_loss: tensor(0.0094); G_loss: tensor(10.0862)\n",
      "Epoch: 12164; D_loss: tensor(0.0148); G_loss: tensor(8.8281)\n",
      "Epoch: 12165; D_loss: tensor(0.0021); G_loss: tensor(10.3351)\n",
      "Epoch: 12166; D_loss: tensor(0.0075); G_loss: tensor(8.7190)\n",
      "Epoch: 12167; D_loss: tensor(0.0024); G_loss: tensor(8.4883)\n",
      "Epoch: 12168; D_loss: tensor(0.0079); G_loss: tensor(8.5118)\n",
      "Epoch: 12169; D_loss: tensor(0.0060); G_loss: tensor(7.4106)\n",
      "Epoch: 12170; D_loss: tensor(0.0241); G_loss: tensor(7.7967)\n",
      "Epoch: 12171; D_loss: tensor(0.0125); G_loss: tensor(6.8847)\n",
      "Epoch: 12172; D_loss: tensor(0.0137); G_loss: tensor(9.5511)\n",
      "Epoch: 12173; D_loss: tensor(0.0040); G_loss: tensor(9.5994)\n",
      "Epoch: 12174; D_loss: tensor(0.0043); G_loss: tensor(9.3479)\n",
      "Epoch: 12175; D_loss: tensor(0.0297); G_loss: tensor(9.1634)\n",
      "Epoch: 12176; D_loss: tensor(0.0427); G_loss: tensor(7.2241)\n",
      "Epoch: 12177; D_loss: tensor(0.0074); G_loss: tensor(8.7882)\n",
      "Epoch: 12178; D_loss: tensor(0.0092); G_loss: tensor(7.6089)\n",
      "Epoch: 12179; D_loss: tensor(0.0093); G_loss: tensor(7.8298)\n",
      "Epoch: 12180; D_loss: tensor(0.0048); G_loss: tensor(9.5189)\n",
      "Epoch: 12181; D_loss: tensor(0.0706); G_loss: tensor(7.8649)\n",
      "Epoch: 12182; D_loss: tensor(0.0718); G_loss: tensor(7.5536)\n",
      "Epoch: 12183; D_loss: tensor(0.0291); G_loss: tensor(8.7009)\n",
      "Epoch: 12184; D_loss: tensor(0.0218); G_loss: tensor(10.2456)\n",
      "Epoch: 12185; D_loss: tensor(0.0184); G_loss: tensor(8.4021)\n",
      "Epoch: 12186; D_loss: tensor(0.0041); G_loss: tensor(8.2850)\n",
      "Epoch: 12187; D_loss: tensor(0.0142); G_loss: tensor(8.0829)\n",
      "Epoch: 12188; D_loss: tensor(0.0309); G_loss: tensor(8.6171)\n",
      "Epoch: 12189; D_loss: tensor(0.0542); G_loss: tensor(8.0524)\n",
      "Epoch: 12190; D_loss: tensor(0.0299); G_loss: tensor(8.0017)\n",
      "Epoch: 12191; D_loss: tensor(0.0182); G_loss: tensor(7.1717)\n",
      "Epoch: 12192; D_loss: tensor(0.0703); G_loss: tensor(5.7322)\n",
      "Epoch: 12193; D_loss: tensor(0.0185); G_loss: tensor(6.4422)\n",
      "Epoch: 12194; D_loss: tensor(0.0639); G_loss: tensor(9.6207)\n",
      "Epoch: 12195; D_loss: tensor(0.1429); G_loss: tensor(6.5455)\n",
      "Epoch: 12196; D_loss: tensor(0.0183); G_loss: tensor(3.1735)\n",
      "Epoch: 12197; D_loss: tensor(0.1981); G_loss: tensor(8.8182)\n",
      "Epoch: 12198; D_loss: tensor(0.0453); G_loss: tensor(13.0783)\n",
      "Epoch: 12199; D_loss: tensor(0.0070); G_loss: tensor(11.0753)\n",
      "Epoch: 12200; D_loss: tensor(0.0112); G_loss: tensor(6.5606)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12201; D_loss: tensor(0.0290); G_loss: tensor(6.2999)\n",
      "Epoch: 12202; D_loss: tensor(0.0150); G_loss: tensor(10.0499)\n",
      "Epoch: 12203; D_loss: tensor(0.0376); G_loss: tensor(11.9797)\n",
      "Epoch: 12204; D_loss: tensor(0.0051); G_loss: tensor(10.8281)\n",
      "Epoch: 12205; D_loss: tensor(0.0187); G_loss: tensor(7.4565)\n",
      "Epoch: 12206; D_loss: tensor(0.0767); G_loss: tensor(6.5471)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-f581e2eaf388>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mfakex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mrealy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfakey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrealx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfakex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mD_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrealy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfakey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mD_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e86483f1f3c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, label)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_expand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_expand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:84: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:85: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    }
   ],
   "source": [
    "num_images = 1000\n",
    "for j in range(10):\n",
    "    for i in range(num_images):\n",
    "        load_state()\n",
    "        plt_single_gen_with_fixed_noise(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
